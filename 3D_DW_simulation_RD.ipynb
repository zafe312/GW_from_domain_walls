{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3D_DW_simulation_RD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqc7+HWhIs0oGnVnKY1yp4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zafe312/GW_from_domain_walls/blob/main/3D_DW_simulation_RD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U9zjj6cWIMLQ",
        "outputId": "a5405526-55e1-4237-9fbe-ca01c874ccf4"
      },
      "source": [
        "#!/usr/bin/env python\n",
        "\"\"\"\n",
        "3D cosmological evolution equation solved by finite differences.\n",
        "\"\"\"\n",
        "import time, sys\n",
        "import numpy as np\n",
        "import os, psutil # for checking memory uses\n",
        "import h5py\n",
        "\n",
        "def mem():\n",
        "  print(f' Memory in use is {int(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2)} mb \\n') # gives mb of memory uses\n",
        "\n",
        "def solver(I, V, lam, eta, a0, Lx, Ly, Lz, Nx, Ny, Nz, dt, ti, T,\n",
        "           user_action=None, version='scalar'):\n",
        "    print(f'\\nLattice size is {(Lx,Ly,Lz)} with {(Nx,Ny,Nz)} = {(Nx)*(Ny)*(Nz)} lattice points.')\n",
        "    print(f'ti = {ti}, tf = {T}, dt = {dt}, Nt = {int(round(T/float(dt)))}\\n')\n",
        "    print('Initializing and performing 1st step...')\n",
        "    \n",
        "    if version == 'cython':\n",
        "        try:\n",
        "            #import pyximport; pyximport.install()\n",
        "            import wave2D_u0_loop_cy as compiled_loops\n",
        "            advance = compiled_loops.advance\n",
        "        except ImportError as e:\n",
        "            print ('No module wave2D_u0_loop_cy. Run make_wave2D.sh!')\n",
        "            print (e)\n",
        "            sys.exit(1)\n",
        "    elif version == 'f77':\n",
        "        try:\n",
        "            import wave2D_u0_loop_f77 as compiled_loops\n",
        "            advance = compiled_loops.advance\n",
        "        except ImportError:\n",
        "            print ('No module wave2D_u0_loop_f77. Run make_wave2D.sh!')\n",
        "            sys.exit(1)\n",
        "    elif version == 'c_f2py':\n",
        "        try:\n",
        "            import wave2D_u0_loop_c_f2py as compiled_loops\n",
        "            advance = compiled_loops.advance\n",
        "        except ImportError:\n",
        "            print ('No module wave2D_u0_loop_c_f2py. Run make_wave2D.sh!')\n",
        "            sys.exit(1)\n",
        "    elif version == 'c_cy':\n",
        "        try:\n",
        "            import wave2D_u0_loop_c_cy as compiled_loops\n",
        "            advance = compiled_loops.advance_cwrap\n",
        "        except ImportError as e:\n",
        "            print ('No module wave2D_u0_loop_c_cy. Run make_wave2D.sh!')\n",
        "            print (e)\n",
        "            sys.exit(1)\n",
        "    elif version == 'vectorized':\n",
        "        advance = advance_vectorized\n",
        "    elif version == 'scalar':\n",
        "        advance = advance_scalar\n",
        "\n",
        "    x = np.linspace(0, Lx, Nx, endpoint=False)  # mesh points in x dir\n",
        "    y = np.linspace(0, Ly, Ny, endpoint=False)  # mesh points in y dir\n",
        "    z = np.linspace(0, Lz, Nz, endpoint=False)  # mesh points in y dir\n",
        "    dx = x[1] - x[0]\n",
        "    dy = y[1] - y[0]\n",
        "    dz = z[1] - z[0]\n",
        "    \n",
        "    Bx = dt**2/(a0*dx)**2\n",
        "    By = dt**2/(a0*dy)**2\n",
        "    Bz = dt**2/(a0*dz)**2\n",
        "\n",
        "    xv = x[:,np.newaxis,np.newaxis]          # for vectorized function evaluations\n",
        "    yv = y[np.newaxis,:,np.newaxis]\n",
        "    zv = z[np.newaxis,np.newaxis,:]\n",
        "\n",
        "    stability_limit = (float(a0))*(1/np.sqrt(1/dx**2 + 1/dy**2))\n",
        "    if dt <= 0:                # max time step?\n",
        "        safety_factor = -dt    # use negative dt as safety factor\n",
        "        dt = safety_factor*stability_limit\n",
        "    elif dt > stability_limit:\n",
        "        raise ValueError('error: dt=%g exceeds the stability limit %g' % \\\n",
        "              (dt, stability_limit))\n",
        "        \n",
        "    Nt = int(round(T/float(dt)))\n",
        "    t = np.linspace(ti, ti+Nt*dt, Nt)    # mesh points in time\n",
        "    dt2 = dt**2\n",
        "\n",
        "    # Allow f and V to be None or 0\n",
        "    if V is None or V == 0:\n",
        "        V = (lambda x, y, z: 0) if version == 'scalar' else \\\n",
        "            lambda x, y, z: np.zeros((x.shape[0], y.shape[1], z.shape[2]))\n",
        "\n",
        "\n",
        "    order = 'Fortran' if version == 'f77' else 'C'\n",
        "    u   = np.zeros((Nx,Ny,Nz), order=order)   # solution array\n",
        "    u[:,:,:]   = -1\n",
        "    u_1 = np.zeros((Nx,Ny,Nz), order=order)   # solution at t-dt\n",
        "    u_1[:,:,:] = -1\n",
        "    u_2 = np.zeros((Nx,Ny,Nz), order=order)   # solution at t-2*dt\n",
        "    u_2[:,:,:] = -1\n",
        "    #f_a = np.zeros((Nx+1,Ny+1,Nz+1), order=order)   # for compiled loops\n",
        "\n",
        "    Ix = range(0, u.shape[0])\n",
        "    Iy = range(0, u.shape[1])\n",
        "    Iz = range(0, u.shape[2])\n",
        "    It = range(0, t.shape[0])\n",
        "\n",
        "    import time; t0 = time.process_time()          # for measuring CPU time\n",
        "\n",
        "    # Load initial condition into u_1\n",
        "    if version == 'scalar':\n",
        "        for i in Ix:\n",
        "            for j in Iy:\n",
        "                u_1[i,j] = I(x[i], y[j])\n",
        "    else: # use vectorized version\n",
        "        u_1[:,:,:] = I(xv, yv, zv)\n",
        "\n",
        "    if user_action is not None:\n",
        "        user_action(u_1, x, xv, y, yv, z, zv, t, 0)\n",
        "\n",
        "    # Special formula for first time step\n",
        "    n = 0\n",
        "    # First step requires a special formula, use either the scalar\n",
        "    # or vectorized version (the impact of more efficient loops than\n",
        "    # in advance_vectorized is small as this is only one step)\n",
        "    if version == 'scalar':\n",
        "        u = advance_scalar(\n",
        "            u, u_1, u_2, f, x, y, t, n,\n",
        "            Cx2, Cy2, dt2, V, step1=True)\n",
        "\n",
        "    else:\n",
        "        V_a = V(xv, yv, zv)\n",
        "        u = advance_vectorized(\n",
        "            u, u_1, u_2, lam, n, eta, Bx, By, Bz, ti, dt2, V=V_a, step1=True)\n",
        "\n",
        "    if user_action is not None:\n",
        "        user_action(u, x, xv, y, yv, z, zv, t, 1)\n",
        "\n",
        "    # Update data structures for next step\n",
        "    #u_2[:] = u_1;  u_1[:] = u  # safe, but slower\n",
        "    u_2, u_1, u = u_1, u, u_2\n",
        "    \n",
        "    print('Entering loop...')\n",
        "    for n in It[1:-1]:\n",
        "        iter_t0 = time.process_time() # check iteration time\n",
        "        \n",
        "        if version == 'scalar':\n",
        "            # use f(x,y,t) function\n",
        "            u = advance(u, u_1, u_2, f, x, y, t, n, Cx2, Cy2, dt2)\n",
        "        else:\n",
        "            u = advance(u, u_1, u_2, lam, n, eta, Bx, By, Bz, ti, dt2)\n",
        "\n",
        "        if version == 'f77':\n",
        "            for a in 'u', 'u_1', 'u_2', 'f_a':\n",
        "                if not isfortran(eval(a)):\n",
        "                    print ('%s: not Fortran storage!' % a)\n",
        "\n",
        "        if user_action is not None:\n",
        "            if user_action(u, x, xv, y, yv, z, zv, t, n+1):\n",
        "                break\n",
        "\n",
        "        # Update data structures for next step\n",
        "        #u_2[:] = u_1;  u_1[:] = u  # safe, but slower\n",
        "        u_2, u_1, u = u_1, u, u_2\n",
        "        \n",
        "        iter_t1 = time.process_time()\n",
        "        iter_t = iter_t1 - iter_t0\n",
        "        print(f'n = {n} iteration done in {round(iter_t,3)} sec.')\n",
        "\n",
        "    # Important to set u = u_1 if u is to be returned!\n",
        "    t1 = time.process_time()\n",
        "    # dt might be computed in this function so return the value\n",
        "    return dt, t1 - t0\n",
        "\n",
        "\n",
        "\n",
        "def advance_scalar(u, u_1, u_2, f, x, y, t, n, Cx2, Cy2, dt2,\n",
        "                   V=None, step1=False):\n",
        "    Ix = range(0, u.shape[0]);  Iy = range(0, u.shape[1])\n",
        "    if step1:\n",
        "        dt = np.sqrt(dt2)  # save\n",
        "        Cx2 = 0.5*Cx2;  Cy2 = 0.5*Cy2; dt2 = 0.5*dt2  # redefine\n",
        "        D1 = 1;  D2 = 0\n",
        "    else:\n",
        "        D1 = 2;  D2 = 1\n",
        "    for i in Ix[1:-1]:\n",
        "        for j in Iy[1:-1]:\n",
        "            u_xx = u_1[i-1,j] - 2*u_1[i,j] + u_1[i+1,j]\n",
        "            u_yy = u_1[i,j-1] - 2*u_1[i,j] + u_1[i,j+1]\n",
        "            u[i,j] = D1*u_1[i,j] - D2*u_2[i,j] + \\\n",
        "                     Cx2*u_xx + Cy2*u_yy + dt2*f(x[i], y[j], t[n])\n",
        "            if step1:\n",
        "                u[i,j] += dt*V(x[i], y[j])\n",
        "    # Boundary condition u=0\n",
        "    j = Iy[0]\n",
        "    for i in Ix: u[i,j] = 0\n",
        "    j = Iy[-1]\n",
        "    for i in Ix: u[i,j] = 0\n",
        "    i = Ix[0]\n",
        "    for j in Iy: u[i,j] = 0\n",
        "    i = Ix[-1]\n",
        "    for j in Iy: u[i,j] = 0\n",
        "    return u\n",
        "\n",
        "def advance_vectorized(u, u_1, u_2, lam, n, eta, Bx, By, Bz, ti, dt2,\n",
        "                       V=None, step1=False):\n",
        "    dt = np.sqrt(dt2)  # save\n",
        "    Bx = Bx/(n*dt+ti); By = By/(n*dt+ti); Bz = Bz/(n*dt+ti)\n",
        "    A = dt/(2*(ti+n*dt))\n",
        "\n",
        "    u_xx = u_1[:-2,1:-1,1:-1] - 2*u_1[1:-1,1:-1,1:-1] + u_1[2:,1:-1,1:-1]\n",
        "    u_yy = u_1[1:-1,:-2,1:-1] - 2*u_1[1:-1,1:-1,1:-1] + u_1[1:-1,2:,1:-1]\n",
        "    u_zz = u_1[1:-1,1:-1,:-2] - 2*u_1[1:-1,1:-1,1:-1] + u_1[1:-1,1:-1,2:]\n",
        "    \n",
        "    if step1:\n",
        "        u[1:-1,1:-1,1:-1] = (1 - ((lam*dt2)/2)*(u_1[1:-1,1:-1,1:-1]*u_1[1:-1,1:-1,1:-1] - \\\n",
        "                       eta**2))*u_1[1:-1,1:-1,1:-1] - ((3/2)*A-1)*dt*V[1:-1,1:-1,1:-1] + \\\n",
        "                       Bx*u_xx/2 + By*u_yy/2 + Bz*u_zz/2\n",
        "    else:\n",
        "        u[1:-1,1:-1,1:-1] = ((2 - lam*dt2*(u_1[1:-1,1:-1,1:-1]*u_1[1:-1,1:-1,1:-1] - \\\n",
        "                       eta**2))*u_1[1:-1,1:-1,1:-1] + ((3/2)*A-1)*u_2[1:-1,1:-1,1:-1] + \\\n",
        "                       Bx*u_xx + By*u_yy + Bz*u_zz)/(1+(3/2)*A)\n",
        "\n",
        "    # Boundary condition u=0\n",
        "    Bxx = np.sqrt(Bx/3)\n",
        "    Byy = np.sqrt(By/3)\n",
        "    Bzz = np.sqrt(Bz/3)\n",
        "    tol_bc = 1e-4\n",
        "\n",
        "    k = 0\n",
        "    u[:,:,k] = -1\n",
        "#     if abs(u[:,:,u.shape[2]-1].max()+1) > tol_bc:\n",
        "#         u[:,:,k] = u[:,:,u.shape[2]-1]\n",
        "#     else:\n",
        "#         u[:,:,k] = -1\n",
        "    k = u.shape[2] - 1\n",
        "    u[:,:,k] = -1\n",
        "#     u[0,0,k] = u_1[0,0,k] - Bxx*(u_1[0,0,k] - u_1[1,0,k]) - Byy*(u_1[0,0,k] - u_1[0,1,k]) - Bzz*(u_1[0,0,k] - u_1[0,0,k-1])\n",
        "#     u[0,1:,k] = u_1[0,1:,k] - Bxx*(u_1[0,1:,k] - u_1[1,1:,k]) - Byy*(u_1[0,1:,k] - u_1[0,:-1,k]) - Bzz*(u_1[0,1:,k] - u_1[0,1:,k-1])\n",
        "#     u[1:,0,k] = u_1[1:,0,k] - Bxx*(u_1[1:,0,k] - u_1[:-1,0,k]) - Byy*(u_1[1:,0,k] - u_1[1:,1,k]) - Bzz*(u_1[1:,0,k] - u_1[1:,0,k-1])\n",
        "#     u[1:,1:,k] = u_1[1:,1:,k] - Bxx*(u_1[1:,1:,k] - u_1[:-1,1:,k]) - Byy*(u_1[1:,1:,k] - u_1[1:,:-1,k]) - Bzz*(u_1[1:,1:,k] - u_1[1:,1:,k-1])\n",
        "\n",
        "    j = 0\n",
        "    u[:,j,:] = -1\n",
        "#     if abs(u[:,u.shape[1]-1,:].max()+1) > tol_bc:\n",
        "#         u[:,j,:] = u[:,u.shape[1]-1,:]\n",
        "#     else:\n",
        "#         u[:,j,:] = -1.0\n",
        "    j = u.shape[1]-1\n",
        "    u[:,j,:] = -1\n",
        "#     u[0,j,0] = u_1[0,j,0] - Bxx*(u_1[0,j,0] - u_1[1,j,0]) - Byy*(u_1[0,j,0] - u_1[0,j-1,0]) - Bzz*(u_1[0,j,0] - u_1[0,j,1])\n",
        "#     u[0,j,1:] = u_1[0,j,1:] - Bxx*(u_1[0,j,1:] - u_1[1,j,1:]) - Byy*(u_1[0,j,1:] - u_1[0,j-1,1:]) - Bzz*(u_1[0,j,1:] - u_1[0,j,:-1])\n",
        "#     u[1:,j,0] = u_1[1:,j,0] - Bxx*(u_1[1:,j,0] - u_1[:-1,j,0]) - Byy*(u_1[1:,j,0] - u_1[1:,j-1,0]) - Bzz*(u_1[1:,j,0] - u_1[1:,j,1])\n",
        "#     u[1:,j,1:] = u_1[1:,j,1:] - Bxx*(u_1[1:,j,1:] - u_1[:-1,j,1:]) - Byy*(u_1[1:,j,1:] - u_1[1:,j-1,1:]) - Bzz*(u_1[1:,j,1:] - u_1[1:,j,:-1])\n",
        "    \n",
        "    i = 0\n",
        "    u[i,:,:] = -1\n",
        "#     if abs(u[u.shape[0]-1,:,:].max()+1) > tol_bc:\n",
        "#         u[i,:,:] = u[u.shape[0]-1,:,:]\n",
        "#     else:\n",
        "#         u[i,:,:] = -1.0\n",
        "    i = u.shape[0] - 1\n",
        "    u[i,:,:] = -1\n",
        "#     u[i,0,0] = u_1[i,0,0] - Bxx*(u_1[i,0,0] - u_1[i-1,0,0]) - Byy*(u_1[i,0,0] - u_1[i,1,0]) - Bzz*(u_1[i,0,0] - u_1[i,0,1])\n",
        "#     u[i,0,1:] = u_1[i,0,1:] - Bxx*(u_1[i,0,1:] - u_1[i-1,0,1:]) - Byy*(u_1[i,0,1:] - u_1[i,1,1:]) - Bzz*(u_1[i,0,1:] - u_1[i,0,:-1])\n",
        "#     u[i,1:,0] = u_1[i,1:,0] - Bxx*(u_1[i,1:,0] - u_1[i-1,1:,0]) - Byy*(u_1[i,1:,0] - u_1[i,:-1,0]) - Bzz*(u_1[i,1:,0] - u_1[i,1:,1])\n",
        "#     u[i,1:,1:] = u_1[i,1:,1:] - Bxx*(u_1[i,1:,1:] - u_1[i-1,1:,1:]) - Byy*(u_1[i,1:,1:] - u_1[i,:-1,1:]) - Bzz*(u_1[i,1:,1:] - u_1[i,1:,:-1])\n",
        "    return u\n",
        "\n",
        "def quadratic(Nx, Ny, version):\n",
        "    \"\"\"Exact discrete solution of the scheme.\"\"\"\n",
        "\n",
        "    def exact_solution(x, y, t):\n",
        "        return x*(Lx - x)*y*(Ly - y)*(1 + 0.5*t)\n",
        "\n",
        "    def I(x, y):\n",
        "        return exact_solution(x, y, 0)\n",
        "\n",
        "    def V(x, y):\n",
        "        return 0.5*exact_solution(x, y, 0)\n",
        "\n",
        "    def f(x, y, t):\n",
        "        return 2*c**2*(1 + 0.5*t)*(y*(Ly - y) + x*(Lx - x))\n",
        "\n",
        "    Lx = 5;  Ly = 2\n",
        "    c = 1.5\n",
        "    dt = -1 # use longest possible steps\n",
        "    T = 18\n",
        "\n",
        "    def assert_no_error(u, x, xv, y, yv, t, n):\n",
        "        u_e = exact_solution(xv, yv, t[n])\n",
        "        diff = abs(u - u_e).max()\n",
        "        tol = 1E-12\n",
        "        msg = 'diff=%g, step %d, time=%g' % (diff, n, t[n])\n",
        "        assert diff < tol, msg\n",
        "\n",
        "    new_dt, cpu = solver(\n",
        "        I, V, f, c, Lx, Ly, Nx, Ny, dt, T,\n",
        "        user_action=assert_no_error, version=version)\n",
        "    return new_dt, cpu\n",
        "\n",
        "\n",
        "def test_quadratic():\n",
        "    # Test a series of meshes where Nx > Ny and Nx < Ny\n",
        "    versions = 'scalar', 'vectorized' # , 'cython', 'f77', 'c_cy', 'c_f2py'\n",
        "    for Nx in range(2, 6, 2):\n",
        "        for Ny in range(2, 6, 2):\n",
        "            for version in versions:\n",
        "                print ('testing', version, 'for %dx%d mesh' % (Nx, Ny))\n",
        "                new_dt, cpu = quadratic(Nx, Ny, version)\n",
        "                print(f'new_dt = {new_dt} and cpu = {cpu}\\n')\n",
        "\n",
        "def run_efficiency(nrefinements=4):\n",
        "    def I(x, y):\n",
        "        return sin(pi*x/Lx)*sin(pi*y/Ly)\n",
        "\n",
        "    Lx = 10;  Ly = 10\n",
        "    c = 1.5\n",
        "    T = 100\n",
        "    versions = ['scalar', 'vectorized', 'cython', 'f77',\n",
        "               'c_f2py', 'c_cy']\n",
        "    print (' '*15, ''.join(['%-13s' % v for v in versions]))\n",
        "    for Nx in 15, 30, 60, 120:\n",
        "        cpu = {}\n",
        "        for version in versions:\n",
        "            dt, cpu_ = solver(I, None, None, c, Lx, Ly, Nx, Nx,\n",
        "                              -1, T, user_action=None,\n",
        "                              version=version)\n",
        "            cpu[version] = cpu_\n",
        "        cpu_min = min(list(cpu.values()))\n",
        "        if cpu_min < 1E-6:\n",
        "            print ('Ignored %dx%d grid (too small execution time)' \\\n",
        "                  % (Nx, Nx))\n",
        "        else:\n",
        "            cpu = {version: cpu[version]/cpu_min for version in cpu}\n",
        "            print ('%-15s' % '%dx%d' % (Nx, Nx),)\n",
        "            print (''.join(['%13.1f' % cpu[version] for version in versions]))\n",
        "\n",
        "def model(plot_method=3, version='vectorized', save_plot=True, T=1):\n",
        "    \"\"\"\n",
        "    Defines initial field config, model parameters, grid parameters and calls solver function.\n",
        "    plot_method=1 applies mesh function, =2 means surf, =0 means no plot.\n",
        "    \"\"\"\n",
        "    # Clean up plot files\n",
        "    import glob, os\n",
        "    for name in glob.glob('tmp_*.png'):\n",
        "        os.remove(name)\n",
        "    for name in glob.glob('field_*.h5'):\n",
        "        os.remove(name)\n",
        "    if glob.glob('geekfile.txt'):\n",
        "        os.remove('geekfile.txt')\n",
        "\n",
        "    # Grid and model parameters\n",
        "    Lx = 50; Ly = 50; Lz = 50;\n",
        "    Nx = 256; Ny = 256; Nz = 256; ti = 1; T = T; dt = 1e-1\n",
        "    lam = 0.1; eta = 1; a0 = 1\n",
        "    Bx = 1; By = 1; Bz = 1\n",
        "\n",
        "    def I(x, y, z):\n",
        "        \"\"\"Initial field configuration.\"\"\"\n",
        "#         return np.exp(-0.5*(x-Lx/2.0)**2 - 0.5*(y-Ly/2.0)**2) # Gaussian peak at the centre\n",
        "        return -np.tanh((np.sqrt((x-Lx/2)**2+(y-Ly/2)**2+(z-Lz/2)**2)-Lx/4)/2) # tanh sphere at the centre\n",
        "        \n",
        "    \n",
        "    def V(x, y, z):\n",
        "        return (y-x-z)*0\n",
        "\n",
        "\n",
        "    def plot_u(u, x, xv, y, yv, z, zv, t, n):\n",
        "        if t[n] == 0:\n",
        "            time.sleep(2)\n",
        "        if plot_method == 1:\n",
        "            mesh(x, y, u, title='t=%g' % t[n], zlim=[-1,1],\n",
        "                 caxis=[-1,1])\n",
        "            \n",
        "        elif plot_method == 2:\n",
        "            import matplotlib.pyplot as plt\n",
        "#             fig, ax = plt.figure()\n",
        "            fig, ax = plt.subplots(figsize=(6,6))\n",
        "            u_surf = ax.contourf(x,y,u)\n",
        "#             plt.xlabel('x')\n",
        "#             plt.ylabel('y')\n",
        "            ax.set_title('Contour Plot')\n",
        "#             plt.colorbar()\n",
        "            #cont_plot(x, y, u)\n",
        "            \n",
        "        elif plot_method == 3:\n",
        "            from mpl_toolkits import mplot3d\n",
        "            import matplotlib.pyplot as plt\n",
        "\n",
        "            fig = plt.figure()\n",
        "            ax = plt.axes(projection='3d')\n",
        "\n",
        "            u_surf = ax.plot_surface(xv[:,:,0], yv[:,:,0], u[:,:,int(Nz/2)],cmap='viridis', edgecolor='none')\n",
        "            title = f'n = {n}, t = {round(ti+n*dt,3)}, tau = {round(2*np.sqrt(ti+n*dt),3)}'\n",
        "            ax.set_title(title)\n",
        "            ax.set_xlabel('x')\n",
        "            ax.set_ylabel('y')\n",
        "            ax.set_zlabel(f'$\\phi(x,y,{round(Nz/2*(zv[0,0,1]-zv[0,0,0]),1)})$')\n",
        "            ax.set_zlim(-2, 2)\n",
        "            \n",
        "        if plot_method > 0:\n",
        "            time.sleep(0) # pause between frames\n",
        "            filename = 'field_%04d.h5' % n\n",
        "            # save array into gz file\n",
        "            #u_reshaped = u.reshape(u.shape[0], -1)\n",
        "            #np.savetxt(filename, u_reshaped) # most time consuming step\n",
        "            def hdf5_write(data,name):\n",
        "                f = h5py.File(name, \"w\")\n",
        "                f.create_dataset('data', data=data)\n",
        "            hdf5_write(u,filename)           \n",
        "            if save_plot:\n",
        "                filename = 'tmp_%04d.png' % n\n",
        "                plt.savefig(filename)  # time consuming!\n",
        "            ax.collections.remove(u_surf)\n",
        "            plt.close('all')\n",
        "            plt.draw()\n",
        "            time.sleep(1)\n",
        "\n",
        "    dt, cpu = solver(I, V, lam, eta, a0, Lx, Ly, Lz, Nx, Ny, Nz, dt, ti, T,\n",
        "                     user_action=plot_u, version=version)\n",
        "    print(f'Total time taken is {cpu/3600} hr')\n",
        "    \n",
        "    # Make video files\n",
        "    fps = 4  # frames per second\n",
        "    codec2ext = dict(flv='flv', libx264='mp4', libvpx='webm',\n",
        "                     libtheora='ogg')  # video formats\n",
        "    filespec = 'tmp_%04d.png'\n",
        "    movie_program = 'ffmpeg'  # or 'avconv'\n",
        "    for codec in codec2ext:\n",
        "        ext = codec2ext[codec]\n",
        "        cmd = '%(movie_program)s -r %(fps)d -i %(filespec)s '\\\n",
        "              '-vcodec %(codec)s movie.%(ext)s' % vars()\n",
        "        os.system(cmd)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #test_quadratic()\n",
        "    mem()\n",
        "    model(T=50)\n",
        "    mem()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Memory in use is 119 mb \n",
            "\n",
            "\n",
            "Lattice size is (50, 50, 50) with (256, 256, 256) = 16777216 lattice points.\n",
            "ti = 1, tf = 50, dt = 0.1, Nt = 500\n",
            "\n",
            "Initializing and performing 1st step...\n",
            "Entering loop...\n",
            "n = 1 iteration done in 1.673 sec.\n",
            "n = 2 iteration done in 1.753 sec.\n",
            "n = 3 iteration done in 1.848 sec.\n",
            "n = 4 iteration done in 2.055 sec.\n",
            "n = 5 iteration done in 1.729 sec.\n",
            "n = 6 iteration done in 1.87 sec.\n",
            "n = 7 iteration done in 1.691 sec.\n",
            "n = 8 iteration done in 1.991 sec.\n",
            "n = 9 iteration done in 1.872 sec.\n",
            "n = 10 iteration done in 1.818 sec.\n",
            "n = 11 iteration done in 1.758 sec.\n",
            "n = 12 iteration done in 2.033 sec.\n",
            "n = 13 iteration done in 1.885 sec.\n",
            "n = 14 iteration done in 1.927 sec.\n",
            "n = 15 iteration done in 1.839 sec.\n",
            "n = 16 iteration done in 2.031 sec.\n",
            "n = 17 iteration done in 1.794 sec.\n",
            "n = 18 iteration done in 2.118 sec.\n",
            "n = 19 iteration done in 1.763 sec.\n",
            "n = 20 iteration done in 1.981 sec.\n",
            "n = 21 iteration done in 1.845 sec.\n",
            "n = 22 iteration done in 1.786 sec.\n",
            "n = 23 iteration done in 1.754 sec.\n",
            "n = 24 iteration done in 1.97 sec.\n",
            "n = 25 iteration done in 1.913 sec.\n",
            "n = 26 iteration done in 1.964 sec.\n",
            "n = 27 iteration done in 1.791 sec.\n",
            "n = 28 iteration done in 1.908 sec.\n",
            "n = 29 iteration done in 1.927 sec.\n",
            "n = 30 iteration done in 1.922 sec.\n",
            "n = 31 iteration done in 1.871 sec.\n",
            "n = 32 iteration done in 1.95 sec.\n",
            "n = 33 iteration done in 1.861 sec.\n",
            "n = 34 iteration done in 1.982 sec.\n",
            "n = 35 iteration done in 2.045 sec.\n",
            "n = 36 iteration done in 1.933 sec.\n",
            "n = 37 iteration done in 1.843 sec.\n",
            "n = 38 iteration done in 1.928 sec.\n",
            "n = 39 iteration done in 1.949 sec.\n",
            "n = 40 iteration done in 1.965 sec.\n",
            "n = 41 iteration done in 1.87 sec.\n",
            "n = 42 iteration done in 2.115 sec.\n",
            "n = 43 iteration done in 1.825 sec.\n",
            "n = 44 iteration done in 1.951 sec.\n",
            "n = 45 iteration done in 1.942 sec.\n",
            "n = 46 iteration done in 1.954 sec.\n",
            "n = 47 iteration done in 1.828 sec.\n",
            "n = 48 iteration done in 1.988 sec.\n",
            "n = 49 iteration done in 1.79 sec.\n",
            "n = 50 iteration done in 2.087 sec.\n",
            "n = 51 iteration done in 1.865 sec.\n",
            "n = 52 iteration done in 1.875 sec.\n",
            "n = 53 iteration done in 1.974 sec.\n",
            "n = 54 iteration done in 1.928 sec.\n",
            "n = 55 iteration done in 1.869 sec.\n",
            "n = 56 iteration done in 1.912 sec.\n",
            "n = 57 iteration done in 1.873 sec.\n",
            "n = 58 iteration done in 2.162 sec.\n",
            "n = 59 iteration done in 1.93 sec.\n",
            "n = 60 iteration done in 1.934 sec.\n",
            "n = 61 iteration done in 1.887 sec.\n",
            "n = 62 iteration done in 1.942 sec.\n",
            "n = 63 iteration done in 1.796 sec.\n",
            "n = 64 iteration done in 1.931 sec.\n",
            "n = 65 iteration done in 1.774 sec.\n",
            "n = 66 iteration done in 2.104 sec.\n",
            "n = 67 iteration done in 1.813 sec.\n",
            "n = 68 iteration done in 1.902 sec.\n",
            "n = 69 iteration done in 1.886 sec.\n",
            "n = 70 iteration done in 1.954 sec.\n",
            "n = 71 iteration done in 1.902 sec.\n",
            "n = 72 iteration done in 1.937 sec.\n",
            "n = 73 iteration done in 1.831 sec.\n",
            "n = 74 iteration done in 1.945 sec.\n",
            "n = 75 iteration done in 1.826 sec.\n",
            "n = 76 iteration done in 2.109 sec.\n",
            "n = 77 iteration done in 1.865 sec.\n",
            "n = 78 iteration done in 1.948 sec.\n",
            "n = 79 iteration done in 1.849 sec.\n",
            "n = 80 iteration done in 1.94 sec.\n",
            "n = 81 iteration done in 1.872 sec.\n",
            "n = 82 iteration done in 1.924 sec.\n",
            "n = 83 iteration done in 1.8 sec.\n",
            "n = 84 iteration done in 1.933 sec.\n",
            "n = 85 iteration done in 1.833 sec.\n",
            "n = 86 iteration done in 2.077 sec.\n",
            "n = 87 iteration done in 1.904 sec.\n",
            "n = 88 iteration done in 2.067 sec.\n",
            "n = 89 iteration done in 1.831 sec.\n",
            "n = 90 iteration done in 1.92 sec.\n",
            "n = 91 iteration done in 1.808 sec.\n",
            "n = 92 iteration done in 1.907 sec.\n",
            "n = 93 iteration done in 1.801 sec.\n",
            "n = 94 iteration done in 1.944 sec.\n",
            "n = 95 iteration done in 1.836 sec.\n",
            "n = 96 iteration done in 1.896 sec.\n",
            "n = 97 iteration done in 2.099 sec.\n",
            "n = 98 iteration done in 1.97 sec.\n",
            "n = 99 iteration done in 1.811 sec.\n",
            "n = 100 iteration done in 1.961 sec.\n",
            "n = 101 iteration done in 1.79 sec.\n",
            "n = 102 iteration done in 1.93 sec.\n",
            "n = 103 iteration done in 1.835 sec.\n",
            "n = 104 iteration done in 1.938 sec.\n",
            "n = 105 iteration done in 1.814 sec.\n",
            "n = 106 iteration done in 1.876 sec.\n",
            "n = 107 iteration done in 1.816 sec.\n",
            "n = 108 iteration done in 1.878 sec.\n",
            "n = 109 iteration done in 2.109 sec.\n",
            "n = 110 iteration done in 1.871 sec.\n",
            "n = 111 iteration done in 1.819 sec.\n",
            "n = 112 iteration done in 1.948 sec.\n",
            "n = 113 iteration done in 1.822 sec.\n",
            "n = 114 iteration done in 1.911 sec.\n",
            "n = 115 iteration done in 1.831 sec.\n",
            "n = 116 iteration done in 1.861 sec.\n",
            "n = 117 iteration done in 1.788 sec.\n",
            "n = 118 iteration done in 3.337 sec.\n",
            "n = 119 iteration done in 3.78 sec.\n",
            "n = 120 iteration done in 2.328 sec.\n",
            "n = 121 iteration done in 2.056 sec.\n",
            "n = 122 iteration done in 2.482 sec.\n",
            "n = 123 iteration done in 2.015 sec.\n",
            "n = 124 iteration done in 2.113 sec.\n",
            "n = 125 iteration done in 2.112 sec.\n",
            "n = 126 iteration done in 2.19 sec.\n",
            "n = 127 iteration done in 2.022 sec.\n",
            "n = 128 iteration done in 2.001 sec.\n",
            "n = 129 iteration done in 2.148 sec.\n",
            "n = 130 iteration done in 2.109 sec.\n",
            "n = 131 iteration done in 1.995 sec.\n",
            "n = 132 iteration done in 1.945 sec.\n",
            "n = 133 iteration done in 1.872 sec.\n",
            "n = 134 iteration done in 2.033 sec.\n",
            "n = 135 iteration done in 1.957 sec.\n",
            "n = 136 iteration done in 2.326 sec.\n",
            "n = 137 iteration done in 1.958 sec.\n",
            "n = 138 iteration done in 1.985 sec.\n",
            "n = 139 iteration done in 1.872 sec.\n",
            "n = 140 iteration done in 1.957 sec.\n",
            "n = 141 iteration done in 1.834 sec.\n",
            "n = 142 iteration done in 1.984 sec.\n",
            "n = 143 iteration done in 1.863 sec.\n",
            "n = 144 iteration done in 1.975 sec.\n",
            "n = 145 iteration done in 1.887 sec.\n",
            "n = 146 iteration done in 1.982 sec.\n",
            "n = 147 iteration done in 1.847 sec.\n",
            "n = 148 iteration done in 2.006 sec.\n",
            "n = 149 iteration done in 1.865 sec.\n",
            "n = 150 iteration done in 1.913 sec.\n",
            "n = 151 iteration done in 2.264 sec.\n",
            "n = 152 iteration done in 1.942 sec.\n",
            "n = 153 iteration done in 1.825 sec.\n",
            "n = 154 iteration done in 1.962 sec.\n",
            "n = 155 iteration done in 1.949 sec.\n",
            "n = 156 iteration done in 1.864 sec.\n",
            "n = 157 iteration done in 1.805 sec.\n",
            "n = 158 iteration done in 1.958 sec.\n",
            "n = 159 iteration done in 1.926 sec.\n",
            "n = 160 iteration done in 1.959 sec.\n",
            "n = 161 iteration done in 1.822 sec.\n",
            "n = 162 iteration done in 1.933 sec.\n",
            "n = 163 iteration done in 1.801 sec.\n",
            "n = 164 iteration done in 1.915 sec.\n",
            "n = 165 iteration done in 1.847 sec.\n",
            "n = 166 iteration done in 1.907 sec.\n",
            "n = 167 iteration done in 1.827 sec.\n",
            "n = 168 iteration done in 2.2 sec.\n",
            "n = 169 iteration done in 1.904 sec.\n",
            "n = 170 iteration done in 1.918 sec.\n",
            "n = 171 iteration done in 1.86 sec.\n",
            "n = 172 iteration done in 1.969 sec.\n",
            "n = 173 iteration done in 1.922 sec.\n",
            "n = 174 iteration done in 1.881 sec.\n",
            "n = 175 iteration done in 1.893 sec.\n",
            "n = 176 iteration done in 1.909 sec.\n",
            "n = 177 iteration done in 1.85 sec.\n",
            "n = 178 iteration done in 1.853 sec.\n",
            "n = 179 iteration done in 1.799 sec.\n",
            "n = 180 iteration done in 1.855 sec.\n",
            "n = 181 iteration done in 1.828 sec.\n",
            "n = 182 iteration done in 1.898 sec.\n",
            "n = 183 iteration done in 1.869 sec.\n",
            "n = 184 iteration done in 1.845 sec.\n",
            "n = 185 iteration done in 2.39 sec.\n",
            "n = 186 iteration done in 1.931 sec.\n",
            "n = 187 iteration done in 1.797 sec.\n",
            "n = 188 iteration done in 1.926 sec.\n",
            "n = 189 iteration done in 1.81 sec.\n",
            "n = 190 iteration done in 1.956 sec.\n",
            "n = 191 iteration done in 1.828 sec.\n",
            "n = 192 iteration done in 1.897 sec.\n",
            "n = 193 iteration done in 1.926 sec.\n",
            "n = 194 iteration done in 1.915 sec.\n",
            "n = 195 iteration done in 1.809 sec.\n",
            "n = 196 iteration done in 1.86 sec.\n",
            "n = 197 iteration done in 1.857 sec.\n",
            "n = 198 iteration done in 1.904 sec.\n",
            "n = 199 iteration done in 1.831 sec.\n",
            "n = 200 iteration done in 1.82 sec.\n",
            "n = 201 iteration done in 1.868 sec.\n",
            "n = 202 iteration done in 1.88 sec.\n",
            "n = 203 iteration done in 1.836 sec.\n",
            "n = 204 iteration done in 1.945 sec.\n",
            "n = 205 iteration done in 2.277 sec.\n",
            "n = 206 iteration done in 1.889 sec.\n",
            "n = 207 iteration done in 1.871 sec.\n",
            "n = 208 iteration done in 1.89 sec.\n",
            "n = 209 iteration done in 1.807 sec.\n",
            "n = 210 iteration done in 1.988 sec.\n",
            "n = 211 iteration done in 1.841 sec.\n",
            "n = 212 iteration done in 1.966 sec.\n",
            "n = 213 iteration done in 1.772 sec.\n",
            "n = 214 iteration done in 1.97 sec.\n",
            "n = 215 iteration done in 1.845 sec.\n",
            "n = 216 iteration done in 1.982 sec.\n",
            "n = 217 iteration done in 1.851 sec.\n",
            "n = 218 iteration done in 1.943 sec.\n",
            "n = 219 iteration done in 1.853 sec.\n",
            "n = 220 iteration done in 1.975 sec.\n",
            "n = 221 iteration done in 1.845 sec.\n",
            "n = 222 iteration done in 1.982 sec.\n",
            "n = 223 iteration done in 1.853 sec.\n",
            "n = 224 iteration done in 1.959 sec.\n",
            "n = 225 iteration done in 1.918 sec.\n",
            "n = 226 iteration done in 2.408 sec.\n",
            "n = 227 iteration done in 1.862 sec.\n",
            "n = 228 iteration done in 1.98 sec.\n",
            "n = 229 iteration done in 1.879 sec.\n",
            "n = 230 iteration done in 2.0 sec.\n",
            "n = 231 iteration done in 1.876 sec.\n",
            "n = 232 iteration done in 1.94 sec.\n",
            "n = 233 iteration done in 1.864 sec.\n",
            "n = 234 iteration done in 1.909 sec.\n",
            "n = 235 iteration done in 1.858 sec.\n",
            "n = 236 iteration done in 1.944 sec.\n",
            "n = 237 iteration done in 1.851 sec.\n",
            "n = 238 iteration done in 1.948 sec.\n",
            "n = 239 iteration done in 1.854 sec.\n",
            "n = 240 iteration done in 1.958 sec.\n",
            "n = 241 iteration done in 1.946 sec.\n",
            "n = 242 iteration done in 1.966 sec.\n",
            "n = 243 iteration done in 1.907 sec.\n",
            "n = 244 iteration done in 1.966 sec.\n",
            "n = 245 iteration done in 2.003 sec.\n",
            "n = 246 iteration done in 1.946 sec.\n",
            "n = 247 iteration done in 1.858 sec.\n",
            "n = 248 iteration done in 2.533 sec.\n",
            "n = 249 iteration done in 1.879 sec.\n",
            "n = 250 iteration done in 1.89 sec.\n",
            "n = 251 iteration done in 1.939 sec.\n",
            "n = 252 iteration done in 1.899 sec.\n",
            "n = 253 iteration done in 1.894 sec.\n",
            "n = 254 iteration done in 1.961 sec.\n",
            "n = 255 iteration done in 1.824 sec.\n",
            "n = 256 iteration done in 1.987 sec.\n",
            "n = 257 iteration done in 1.965 sec.\n",
            "n = 258 iteration done in 1.849 sec.\n",
            "n = 259 iteration done in 1.841 sec.\n",
            "n = 260 iteration done in 1.966 sec.\n",
            "n = 261 iteration done in 1.855 sec.\n",
            "n = 262 iteration done in 1.884 sec.\n",
            "n = 263 iteration done in 1.884 sec.\n",
            "n = 264 iteration done in 1.882 sec.\n",
            "n = 265 iteration done in 1.883 sec.\n",
            "n = 266 iteration done in 1.981 sec.\n",
            "n = 267 iteration done in 1.868 sec.\n",
            "n = 268 iteration done in 1.987 sec.\n",
            "n = 269 iteration done in 1.852 sec.\n",
            "n = 270 iteration done in 1.99 sec.\n",
            "n = 271 iteration done in 1.883 sec.\n",
            "n = 272 iteration done in 1.971 sec.\n",
            "n = 273 iteration done in 2.545 sec.\n",
            "n = 274 iteration done in 1.945 sec.\n",
            "n = 275 iteration done in 1.829 sec.\n",
            "n = 276 iteration done in 1.955 sec.\n",
            "n = 277 iteration done in 1.893 sec.\n",
            "n = 278 iteration done in 1.947 sec.\n",
            "n = 279 iteration done in 1.829 sec.\n",
            "n = 280 iteration done in 1.968 sec.\n",
            "n = 281 iteration done in 1.883 sec.\n",
            "n = 282 iteration done in 1.973 sec.\n",
            "n = 283 iteration done in 1.859 sec.\n",
            "n = 284 iteration done in 1.988 sec.\n",
            "n = 285 iteration done in 1.864 sec.\n",
            "n = 286 iteration done in 1.978 sec.\n",
            "n = 287 iteration done in 1.92 sec.\n",
            "n = 288 iteration done in 1.989 sec.\n",
            "n = 289 iteration done in 1.908 sec.\n",
            "n = 290 iteration done in 2.01 sec.\n",
            "n = 291 iteration done in 1.903 sec.\n",
            "n = 292 iteration done in 1.996 sec.\n",
            "n = 293 iteration done in 1.869 sec.\n",
            "n = 294 iteration done in 1.954 sec.\n",
            "n = 295 iteration done in 1.853 sec.\n",
            "n = 296 iteration done in 2.01 sec.\n",
            "n = 297 iteration done in 1.898 sec.\n",
            "n = 298 iteration done in 1.965 sec.\n",
            "n = 299 iteration done in 1.827 sec.\n",
            "n = 300 iteration done in 2.668 sec.\n",
            "n = 301 iteration done in 1.847 sec.\n",
            "n = 302 iteration done in 1.846 sec.\n",
            "n = 303 iteration done in 1.869 sec.\n",
            "n = 304 iteration done in 1.975 sec.\n",
            "n = 305 iteration done in 1.851 sec.\n",
            "n = 306 iteration done in 1.949 sec.\n",
            "n = 307 iteration done in 1.861 sec.\n",
            "n = 308 iteration done in 1.981 sec.\n",
            "n = 309 iteration done in 1.843 sec.\n",
            "n = 310 iteration done in 1.853 sec.\n",
            "n = 311 iteration done in 1.881 sec.\n",
            "n = 312 iteration done in 1.883 sec.\n",
            "n = 313 iteration done in 1.968 sec.\n",
            "n = 314 iteration done in 1.955 sec.\n",
            "n = 315 iteration done in 1.846 sec.\n",
            "n = 316 iteration done in 1.871 sec.\n",
            "n = 317 iteration done in 1.911 sec.\n",
            "n = 318 iteration done in 1.912 sec.\n",
            "n = 319 iteration done in 1.866 sec.\n",
            "n = 320 iteration done in 1.956 sec.\n",
            "n = 321 iteration done in 1.834 sec.\n",
            "n = 322 iteration done in 1.958 sec.\n",
            "n = 323 iteration done in 1.792 sec.\n",
            "n = 324 iteration done in 1.922 sec.\n",
            "n = 325 iteration done in 1.875 sec.\n",
            "n = 326 iteration done in 1.928 sec.\n",
            "n = 327 iteration done in 1.861 sec.\n",
            "n = 328 iteration done in 1.963 sec.\n",
            "n = 329 iteration done in 2.622 sec.\n",
            "n = 330 iteration done in 1.875 sec.\n",
            "n = 331 iteration done in 1.987 sec.\n",
            "n = 332 iteration done in 1.944 sec.\n",
            "n = 333 iteration done in 1.855 sec.\n",
            "n = 334 iteration done in 1.97 sec.\n",
            "n = 335 iteration done in 1.933 sec.\n",
            "n = 336 iteration done in 1.99 sec.\n",
            "n = 337 iteration done in 1.85 sec.\n",
            "n = 338 iteration done in 1.948 sec.\n",
            "n = 339 iteration done in 1.806 sec.\n",
            "n = 340 iteration done in 1.965 sec.\n",
            "n = 341 iteration done in 4.384 sec.\n",
            "n = 342 iteration done in 3.19 sec.\n",
            "n = 343 iteration done in 2.231 sec.\n",
            "n = 344 iteration done in 2.128 sec.\n",
            "n = 345 iteration done in 2.17 sec.\n",
            "n = 346 iteration done in 2.137 sec.\n",
            "n = 347 iteration done in 2.063 sec.\n",
            "n = 348 iteration done in 2.115 sec.\n",
            "n = 349 iteration done in 2.203 sec.\n",
            "n = 350 iteration done in 2.059 sec.\n",
            "n = 351 iteration done in 2.203 sec.\n",
            "n = 352 iteration done in 2.077 sec.\n",
            "n = 353 iteration done in 2.186 sec.\n",
            "n = 354 iteration done in 1.972 sec.\n",
            "n = 355 iteration done in 1.954 sec.\n",
            "n = 356 iteration done in 1.932 sec.\n",
            "n = 357 iteration done in 1.995 sec.\n",
            "n = 358 iteration done in 1.848 sec.\n",
            "n = 359 iteration done in 1.963 sec.\n",
            "n = 360 iteration done in 1.931 sec.\n",
            "n = 361 iteration done in 2.767 sec.\n",
            "n = 362 iteration done in 1.893 sec.\n",
            "n = 363 iteration done in 2.011 sec.\n",
            "n = 364 iteration done in 1.894 sec.\n",
            "n = 365 iteration done in 1.92 sec.\n",
            "n = 366 iteration done in 1.9 sec.\n",
            "n = 367 iteration done in 1.971 sec.\n",
            "n = 368 iteration done in 1.833 sec.\n",
            "n = 369 iteration done in 1.969 sec.\n",
            "n = 370 iteration done in 1.846 sec.\n",
            "n = 371 iteration done in 1.931 sec.\n",
            "n = 372 iteration done in 1.857 sec.\n",
            "n = 373 iteration done in 1.958 sec.\n",
            "n = 374 iteration done in 1.82 sec.\n",
            "n = 375 iteration done in 2.007 sec.\n",
            "n = 376 iteration done in 1.833 sec.\n",
            "n = 377 iteration done in 1.967 sec.\n",
            "n = 378 iteration done in 1.862 sec.\n",
            "n = 379 iteration done in 1.953 sec.\n",
            "n = 380 iteration done in 1.901 sec.\n",
            "n = 381 iteration done in 2.014 sec.\n",
            "n = 382 iteration done in 1.897 sec.\n",
            "n = 383 iteration done in 1.945 sec.\n",
            "n = 384 iteration done in 1.887 sec.\n",
            "n = 385 iteration done in 1.857 sec.\n",
            "n = 386 iteration done in 1.82 sec.\n",
            "n = 387 iteration done in 1.944 sec.\n",
            "n = 388 iteration done in 1.903 sec.\n",
            "n = 389 iteration done in 1.994 sec.\n",
            "n = 390 iteration done in 1.833 sec.\n",
            "n = 391 iteration done in 1.939 sec.\n",
            "n = 392 iteration done in 1.908 sec.\n",
            "n = 393 iteration done in 1.923 sec.\n",
            "n = 394 iteration done in 1.848 sec.\n",
            "n = 395 iteration done in 2.926 sec.\n",
            "n = 396 iteration done in 1.873 sec.\n",
            "n = 397 iteration done in 1.945 sec.\n",
            "n = 398 iteration done in 1.976 sec.\n",
            "n = 399 iteration done in 1.989 sec.\n",
            "n = 400 iteration done in 1.808 sec.\n",
            "n = 401 iteration done in 1.954 sec.\n",
            "n = 402 iteration done in 1.949 sec.\n",
            "n = 403 iteration done in 1.954 sec.\n",
            "n = 404 iteration done in 1.932 sec.\n",
            "n = 405 iteration done in 1.999 sec.\n",
            "n = 406 iteration done in 1.893 sec.\n",
            "n = 407 iteration done in 1.96 sec.\n",
            "n = 408 iteration done in 1.828 sec.\n",
            "n = 409 iteration done in 1.932 sec.\n",
            "n = 410 iteration done in 1.851 sec.\n",
            "n = 411 iteration done in 1.957 sec.\n",
            "n = 412 iteration done in 1.853 sec.\n",
            "n = 413 iteration done in 1.864 sec.\n",
            "n = 414 iteration done in 1.905 sec.\n",
            "n = 415 iteration done in 1.903 sec.\n",
            "n = 416 iteration done in 1.852 sec.\n",
            "n = 417 iteration done in 1.997 sec.\n",
            "n = 418 iteration done in 1.899 sec.\n",
            "n = 419 iteration done in 1.946 sec.\n",
            "n = 420 iteration done in 1.812 sec.\n",
            "n = 421 iteration done in 1.94 sec.\n",
            "n = 422 iteration done in 1.817 sec.\n",
            "n = 423 iteration done in 1.955 sec.\n",
            "n = 424 iteration done in 1.893 sec.\n",
            "n = 425 iteration done in 1.959 sec.\n",
            "n = 426 iteration done in 1.943 sec.\n",
            "n = 427 iteration done in 1.948 sec.\n",
            "n = 428 iteration done in 1.856 sec.\n",
            "n = 429 iteration done in 1.979 sec.\n",
            "n = 430 iteration done in 1.904 sec.\n",
            "n = 431 iteration done in 1.937 sec.\n",
            "n = 432 iteration done in 2.81 sec.\n",
            "n = 433 iteration done in 1.955 sec.\n",
            "n = 434 iteration done in 1.805 sec.\n",
            "n = 435 iteration done in 1.925 sec.\n",
            "n = 436 iteration done in 1.823 sec.\n",
            "n = 437 iteration done in 1.971 sec.\n",
            "n = 438 iteration done in 1.853 sec.\n",
            "n = 439 iteration done in 1.927 sec.\n",
            "n = 440 iteration done in 1.854 sec.\n",
            "n = 441 iteration done in 1.878 sec.\n",
            "n = 442 iteration done in 1.881 sec.\n",
            "n = 443 iteration done in 1.954 sec.\n",
            "n = 444 iteration done in 1.872 sec.\n",
            "n = 445 iteration done in 1.996 sec.\n",
            "n = 446 iteration done in 1.961 sec.\n",
            "n = 447 iteration done in 2.012 sec.\n",
            "n = 448 iteration done in 1.913 sec.\n",
            "n = 449 iteration done in 1.957 sec.\n",
            "n = 450 iteration done in 1.832 sec.\n",
            "n = 451 iteration done in 1.981 sec.\n",
            "n = 452 iteration done in 1.829 sec.\n",
            "n = 453 iteration done in 1.893 sec.\n",
            "n = 454 iteration done in 1.915 sec.\n",
            "n = 455 iteration done in 2.022 sec.\n",
            "n = 456 iteration done in 1.873 sec.\n",
            "n = 457 iteration done in 1.956 sec.\n",
            "n = 458 iteration done in 1.837 sec.\n",
            "n = 459 iteration done in 1.939 sec.\n",
            "n = 460 iteration done in 1.874 sec.\n",
            "n = 461 iteration done in 1.948 sec.\n",
            "n = 462 iteration done in 1.889 sec.\n",
            "n = 463 iteration done in 1.818 sec.\n",
            "n = 464 iteration done in 1.882 sec.\n",
            "n = 465 iteration done in 1.966 sec.\n",
            "n = 466 iteration done in 1.858 sec.\n",
            "n = 467 iteration done in 1.96 sec.\n",
            "n = 468 iteration done in 1.853 sec.\n",
            "n = 469 iteration done in 1.861 sec.\n",
            "n = 470 iteration done in 1.851 sec.\n",
            "n = 471 iteration done in 1.965 sec.\n",
            "n = 472 iteration done in 2.973 sec.\n",
            "n = 473 iteration done in 1.892 sec.\n",
            "n = 474 iteration done in 1.951 sec.\n",
            "n = 475 iteration done in 2.011 sec.\n",
            "n = 476 iteration done in 1.841 sec.\n",
            "n = 477 iteration done in 1.898 sec.\n",
            "n = 478 iteration done in 1.877 sec.\n",
            "n = 479 iteration done in 1.962 sec.\n",
            "n = 480 iteration done in 1.927 sec.\n",
            "n = 481 iteration done in 1.925 sec.\n",
            "n = 482 iteration done in 1.874 sec.\n",
            "n = 483 iteration done in 1.896 sec.\n",
            "n = 484 iteration done in 1.869 sec.\n",
            "n = 485 iteration done in 1.911 sec.\n",
            "n = 486 iteration done in 1.861 sec.\n",
            "n = 487 iteration done in 1.983 sec.\n",
            "n = 488 iteration done in 1.892 sec.\n",
            "n = 489 iteration done in 1.95 sec.\n",
            "n = 490 iteration done in 1.934 sec.\n",
            "n = 491 iteration done in 1.947 sec.\n",
            "n = 492 iteration done in 1.884 sec.\n",
            "n = 493 iteration done in 1.961 sec.\n",
            "n = 494 iteration done in 1.876 sec.\n",
            "n = 495 iteration done in 1.993 sec.\n",
            "n = 496 iteration done in 1.841 sec.\n",
            "n = 497 iteration done in 1.919 sec.\n",
            "n = 498 iteration done in 1.859 sec.\n",
            "Total time taken is 0.27076967200611113 hr\n",
            " Memory in use is 2205 mb \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LEUp_7dW2qz"
      },
      "source": [
        "## GW **CALCULATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qND-6r8W-yZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9538f49d-8b6a-4610-9e2e-66533a489ac6"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy as sc\n",
        "from scipy.fft import fft2, fftfreq, fftn, ifftn, fftshift\n",
        "from scipy.integrate import simps as simpson\n",
        "import scipy.special as spl\n",
        "import time\n",
        "import os, psutil\n",
        "import h5py\n",
        "import gc\n",
        "\n",
        "def mem():\n",
        "  print(f'Memory in use is {int(psutil.Process(os.getpid()).memory_info().rss / 1024 ** 2)} mb') # gives mb of memory uses\n",
        "mem()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory in use is 139 mb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c4UReuFXFK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b059ec1f-49ed-4bbd-83c0-470f9c0f2a2e"
      },
      "source": [
        "# params\n",
        "Lx = 50\n",
        "Ly = 50\n",
        "Lz = 50\n",
        "Nx = 256\n",
        "Ny = 256\n",
        "Nz = 256\n",
        "dt = 1e-1\n",
        "ti = 1\n",
        "Nt = 500\n",
        "skip_factor = 1\n",
        "reduced_steps = int(Nt/skip_factor)\n",
        "print(reduced_steps)\n",
        "T = ti + (dt*Nt)\n",
        "\n",
        "# Grid\n",
        "x = np.linspace(0, Lx, Nx+1, endpoint=False)  # mesh points in x dir\n",
        "y = np.linspace(0, Ly, Ny+1, endpoint=False)  # mesh points in y dir\n",
        "z = np.linspace(0, Lz, Nz+1, endpoint=False)  # mesh points in z dir\n",
        "dx = x[1] - x[0]\n",
        "dy = y[1] - y[0]\n",
        "dz = z[1] - z[0]\n",
        "\n",
        "# xv = x[:,np.newaxis,np.newaxis]          # for vectorized function evaluations\n",
        "# yv = y[np.newaxis,:,np.newaxis]\n",
        "# zv = z[np.newaxis,np.newaxis,:]\n",
        "xv, yv, zv = np.meshgrid(x,y,z, indexing='ij')\n",
        "\n",
        "# cosmological parameters\n",
        "def a(n):\n",
        "    return np.sqrt(ti + n*dt)\n",
        "\n",
        "def H(n):\n",
        "    return 0.5/a(n)**2\n",
        "\n",
        "eta = 1\n",
        "beta = 1/2\n",
        "alpha = beta/(1-beta)\n",
        "v = alpha - 1/2\n",
        "\n",
        "t = np.linspace(ti, T, Nt)\n",
        "tau = t**(1-beta)/(1-beta)\n",
        "mem()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "Memory in use is 528 mb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vMS7IOVXVL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51fa7180-0334-4a64-cbd2-0a2ce966357a"
      },
      "source": [
        "def FT(n, uxx=0,uxy=0,uxz=0,uyy=0,uyz=0,uzz=0,N=np.nan):\n",
        "    '''\n",
        "        Gives the fourier transform of energy-momentum tensor\n",
        "    '''\n",
        "    if not isinstance(uxx, np.ndarray) or not isinstance(uxy, np.ndarray) or not isinstance(uxz, np.ndarray) or not isinstance(uyy, np.ndarray) or not isinstance(uyz, np.ndarray) or not isinstance(uzz, np.ndarray):\n",
        "        filename = 'field_%04d.h5' % n\n",
        "        #u = np.genfromtxt(filename)\n",
        "        #u = u.reshape(u.shape[0],u.shape[1] // (Nz), Nz)\n",
        "        u = h5py.File(filename, 'r')\n",
        "        #u = np.array(u5['data'])\n",
        "        #u5.close()\n",
        "\n",
        "        ux = np.gradient(u['data'], axis = 0)/dx\n",
        "        uy = np.gradient(u['data'], axis = 1)/dy\n",
        "        uz = np.gradient(u['data'], axis = 2)/dz\n",
        "        u.close()\n",
        "        uxx = ux * ux\n",
        "        uxy = ux * uy\n",
        "        uxz = ux * uz\n",
        "        uyy = uy * uy\n",
        "        uyz = uy * uz\n",
        "        uzz = uz * uz\n",
        "\n",
        "    # Fourier transform\n",
        "    uxx_ft = fftshift(fftn(uxx))\n",
        "    uxy_ft = fftshift(fftn(uxy))\n",
        "    uxz_ft = fftshift(fftn(uxy))\n",
        "    uyy_ft = fftshift(fftn(uyy))\n",
        "    uyz_ft = fftshift(fftn(uyz))\n",
        "    uzz_ft = fftshift(fftn(uzz))\n",
        "    \n",
        "    # Fourier frequencies\n",
        "    if not np.isnan(N):\n",
        "        kx = fftfreq(N,Lx/N)\n",
        "        ky = fftfreq(N,Ly/N)\n",
        "        kz = fftfreq(N,Ly/N)\n",
        "    else:\n",
        "        kx = fftshift(fftfreq(Nx,Lx/(Nx)))\n",
        "        ky = fftshift(fftfreq(Ny,Ly/(Ny)))\n",
        "        kz = fftshift(fftfreq(Nz,Lz/(Nz)))\n",
        "        N = Nz\n",
        "        \n",
        "    kx, ky, kz = np.meshgrid(kx,ky,kz,indexing='ij')\n",
        "    kx = kx*(2*np.pi)\n",
        "    ky = ky*(2*np.pi)\n",
        "    kz = kz*(2*np.pi)\n",
        "\n",
        "    # visualization\n",
        "    def viz():\n",
        "        import matplotlib.cm as cm\n",
        "        f, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2, 3, figsize=(15,8), sharex=False, sharey=False)\n",
        "        #ax1.imshow(uxx, cmap=cm.Reds)\n",
        "        ax1.contourf(uxx[:,:,int(N/2)])\n",
        "        #ax4.imshow(np.real(uxx_ft), cmap=cm.Reds)\n",
        "        ax4.contourf(kx[:,:,int(N/2)],ky[:,:,int(N/2)],np.abs(uxx_ft)[:,:,int(N/2)])\n",
        "        #ax2.imshow(uxy, cmap=cm.Reds)\n",
        "        ax2.contourf(uxy[:,:,int(N/2)])\n",
        "        #ax5.imshow(np.real(uxy_ft), cmap=cm.Reds)\n",
        "        ax5.contourf(kx[:,:,int(N/2)],ky[:,:,int(N/2)],np.abs(uxy_ft)[:,:,int(N/2)])\n",
        "        #ax3.imshow(uyy, cmap=cm.Reds)\n",
        "        ax3.contourf(uyy[:,:,int(N/2)])\n",
        "        #ax6.imshow(np.real(uyy_ft), cmap=cm.Reds)\n",
        "        ax6.contourf(kx[:,:,int(N/2)],ky[:,:,int(N/2)],np.abs(uyy_ft)[:,:,int(N/2)])\n",
        "    #viz()\n",
        "    return uxx_ft, uxy_ft, uxz_ft, uyy_ft, uyz_ft, uzz_ft, kx, ky, kz\n",
        "\n",
        "mem()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory in use is 528 mb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "JdfcBEcfX5kE",
        "outputId": "b587f631-e765-44ab-ec0e-86f9bf7b011c"
      },
      "source": [
        "tft0 = time.process_time()\n",
        "_,_,_,_,_,_,kx,ky,kz = FT(400)\n",
        "tft1 = time.process_time()\n",
        "tft1-tft0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.965726674999985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3gAAAHSCAYAAAC+dmnvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdf7Ae113n+c9Xsu+1sG6ulcRWjGTZRsRywDUYxmUgZGfBEG9wUWuYChMzVZ7MTmoFFKmCgq3dDFQxWXb/gNkJFEsgKUFSCSmGhAEycTEm2OBsZVIZQhSPkyix5VixJEs4tgOKLINyb2yd/eM+fdW31b/7nO7T3e9X1S1dPT/P008/557P8z192pxzAgAAAACM37ahGwAAAAAA8IOABwAAAAATQcADAAAAgIkg4AEAAADARBDwAAAAAGAiCHgAAAAAMBGXDd2ANpa27XA7LntZq/te2HG5tp3/Rqfnv7Dj8s3fX7rCLv6+vPV225df2vz9ZUtfL3y8V2x/oXEb/u6lnaXXP79+Re7lL61tr3zs7WvVz7/968Wn1+i6fbtKvz9V0u9f7fssl1+fft/zlO0LUrv9IZG3X2T3hew+kH6/897Xvt7P57/x7Fedc1f38mSBbL/ySnf5VS9vdV+3VH3KGltvvr/2oU7bpyDW7R+zMe0bRe/v2t+eGn3fJHUbOwGIU9HYaZQBb8dlL9Nrr3lT+wdY6fb852/Zs+X/Zw4sbf5+bv+FLdftvPHs5u937jva7YlreuDkAV2Tc/kLT67Wuv/KsXqF3V1H13Mv33HkdK37h5B9b8qk37cmsu9xVvo9L1JnX7h31ydrtecDZ16be/kDJw9I0pZ9IbsPZN/r7Hu648jpzp+Xuj56+rdO9PNM4Vx+1ct1/U/9fKv7ru3L/zylLZ9st8+GVqftUxDr9o/VGPeLvPf48V/++dH3TZKHsROA6BSNnUYZ8GK2cmzblgDwwpOrmwP+ZMAdKuglj5+nbrjz4fwtewYNeXW0DXd1pN/zIg+cPFC5H6SDWzrsFQW67OPntSutKtyhP6EHwisnLlZRzl3vtwo1xkE8wquzX9yw97lWj338VLhiWtJuwjyAMest4JnZFZI+Lml58bx/7Jz7d2Z2o6QPSnqFpM9Iutc5F/WIYceR01sqRbuOrm8JDGUhT7p08N0l8JWFuvTzz0Hd6l3IcNdEk8BfJ9SlHzMt7/2vW6WdgzH1TWv71ksHnukg1+Q2bUNfDOGuaUgIGQ6woWi/aBvoqh4nxHta9Vnry5j6JwDx6LOCtybpDufcC2Z2uaRPmNmfS/p5Sb/hnPugmb1b0lskvavHdgVRFfLSikJa0cC/TqhLPy8u6hruqqZntlGnmlfnMfLUDXd51bvYq7AeDdo3+QhJVcFu9djGgZZn9+cfQNqmwle33T4G9ckA3sdjpR9jTmFv5YTzXr3Nk7df1H3f7tj9eOn1Dz1zU+7lyeP7fj8jCXmzGjsB8KO3gOecc5KS1SMuX/w4SXdI+peLy98v6e0aYSeVreJJ+SFPqneMltQsyOWZU7irU73rs3JXZ5pmWtOqbtW+UfTe1w13czL2vikb7pIwlyd9XVnYqwoCIaffhX6svMcNGfTqVFV9Ba+q56rTliJ12pjdL6ret6pAV3b7vLAX4v0cuko99v4p+7d5Rl8cAoPq9Rg8M9uujakE3yrptyUdk/Q159yLi5uckpQ7Ujezg5IOStIV23ta9cGDbMiTLh18NwkCdbUNd76m7o3hOLyYdQn3TaZkzj3cJXz1TZet7grf2JT0gL0s2C09+tTm7+uvue6S22fDXvK4bYNHqEDWRlUokDba6zvkNQlT2dvW3e5dAltTVcG/aRBqGu7y7t/n+zmkMY2dqr5sTa5nfACE1WvAc869JOlWM7tK0ocl3dzgvockHZKk1aXdg6+7nD0OT7o4WM6r5EnF0/uKwlid4OerSscxWfXkBfYi6fcmRIjPe56ssve1LNzN7Y+vr77pij3XBeubslPF6oY7aSPULT361Ga489GWsgH98VNXDxbyyoJDH6HAR+iqCth9BrtE03DXx/s/l5AX+9ipyerV6fvM7e8M0KdBVtF0zn3NzD4m6XslXWVmly2+idoraTSf+LyQJ1UHvURVUAg5xbJroKuq/Ey5464K7HnK3ssm4c/HqS4IdsWG6JvKwlLR8T9Nwl2iTbjr67gtH+pWhEKGAt/BK2/7xxbuYjalkCdNZ+yUIOQB4fS5iubVkr6x6KB2SHq9pF+T9DFJb9TGalBvlvSRvtrkQ9I5lQU9Kf/4r7xBeIhFPHxX55jWt6FN0MvjI8hXvcd13rO5/qGNoW9Kh7yqRR3ahLsyRcfiVYmpitf2WK6ioNdG14Vuyh43CVgxhruhqneJssCetGXMIS+G/qlMm+pd3v3n+vcHCKXPCt61kt6/mEu+TdIfOef+zMy+KOmDZvZ/S/rvkt7TY5u8KarmJarCXoKpks3V/QOTtxCOD02mbfp6vjoIdbVF0Tc1CXaSn3DXVQwhr8uxXHnhoE0gKAte2fepTdAbIthJ7cLdEOqEPGm0q6ZG0T/l6Rruso/F3yOMXdFnYoh9u89VND8n6TtzLv+ypNv7akdIZdW8tKKBdyznZytD9S6fj2qsj3BPqGsuZN/UdOplnpDBrk7IiHmaZt1w96bVw5KkD529LfcxfIS8PF1XNB1KmxUzE3UD/UPP3NR5oZW0qpAnjbOa57N/urDjcl/NahzuzhxYqvz7RMjD2NT9HAyxbw9yDN7U5b2JdXaCqs5vqAA4pVAXqoqXJ2Q1tul7wh/NfrglV6uqUff8WkOHuzpiqOKVScJd8nvdkFdXXnWt6fu0emwtmpDXJdyNwRhDnk99DjSzf2sJefnm+JrHzmf1OhQCXk/ahr60LkGrSajpGuj67qiqpsdmFS2CE6s27wd/LMbNR2go0jRI1BnwxxzyPnT2ttIKnuT3WDxpYxvHMIW2Cd8nuK8j2e5Nj4nsWvmbc8jr829D9gvVKX1Z7Bshb1yajjuHQMAbUPrDHHpH6aNjHbJzavNhy9smQ4e+sYVrtFNWvQtVtWtTIfI5NTM7oPYR+OpO8ysKdsljdHHuessN5HVD3tCVuybvcajKXdP3IH37tgvmjPy4vFa2nf+G1PNphAl15dLjFhacGZcm485JH4OHcn2GPZ9i6oh8bMMQf4xCf4MZ03uAbsYc7qqqeFm+Al+2CtT0fnl8DfrLQt6Ygl3Mugb0OVfzMKyicUqf1bx0GxhLdBPb9iPgRahsJ4kh/MW2E+eJKTD7DnVj2P5oLkS4axsi2g7+m4a8tKpBdlUAzKvq1Llt03Y0lbwHbU+T4Fvb97bu+zr0MZdtEPIQm9Ahb+hx0VTEPB6bVcCbwjcVbdrd5IM81u1SJvuaxtSxjeX9YGpJNzGFu1g1CQ7ZABfivHdpRdM007q8Hz5Odt6lYjfmRVWk6a6wifGqMw4JFfJiqBwivNkEvOwOnf3/lHfqKb+2Noq2x1DBb+zvD8cQdFP3xOVLjz4lSVp/zXWlj9c12HWdutelilclGYA3rRDVDXZjGeD3Nb1yCsEu/TshDzFoMtbw+Td1yFA5VmMuDM0i4NXdqaXxvYHwh/e+uTFVQ2PR5Bx4iSTcheYrOIQMeVKYaYB1BvbJa8p7D/O2Xd+VNpRLB76isEfIq2cMqwgCczb5gNe0A+LbCwBt2boVBri8wFO3erf+mut6C3m+9BHyipSFPx+D97KglzbmsNblvWtbae1T6Gm7aIfx1/AYB19qjNtj0gGPb5cAxCIbBuqGu0TV1EzJ73FeY9ZXBabuCevnauigV+c0GnlBjypePVTxmmN7jUuMwe6SfaigidvCN2V8+AACCKnN1L0xmkP4Wdu3Pvpj1bJ8v54xhKWuJ0+fK58D4BgH0zEYYrswDo7D+Vv2XPJT12QreOycwDD4I10u1LnuYhV6qqbPENmlnT5f4xSD8VCnT6hTxUM3bVeq5m9FfxgTj0/X92yyAa8r5iAD8C1kuJvq9Mw+w076uYasyhU9dx/bYmyL4/iUXmmTaZrtMXYCuqkT7s4cWPw9+Iv86ycZ8PimAgiPz1l9oadkxn7Ou7IqXqjQUrbN6wRaX2GvKNC0CQ8ht2FfgXaIkEcVD8BYVI2tNoNdhUkGPADhJd/Sjvk8MUPyVb0b+rx3dYWuPjUJ0clt6772ttNMy4JM3nVtK0ZjOwaw75BHuMNY+fqbyoI441D2HtUNdolJLrLCIBPoT/J543OXL29aZizhbgpWTrjWFdJQldUb9j7XKsC0vd8YMf0RiBuBMA5nDiwVhrtz+y8U3m+SAQ9Avwh39fgMdj7CXczH3lXpEuxC8hHQ5hL0CHn9urDjcgbtI+L77yp/p+OW99ksC3Zl4U6a8BRNytEAhhYigFC187tdV044b0HXdyhLHo8gBJ+KxkYEACAeeeGuKtSlTTbgdUVHB1yUDAj4XLTno3rnM9yNsXpXFeyqtnHIcFwW7qqOAUufZLvqsacW9mJaWbPqfZg6+vl4hHoPKH7EKfue1Al3O288W/qYkw547MhAd3yGuusa7nwHk7GFu67BLn27vG1ZVcWrWsSkS7jL3qZu2Bs66GUXzemy0EvyWkIEPRZYaY6gNyy2+7xlw11e1a4q3EkcgwegAn9s2onx+DBpvuFuLGIOJMsnlzZ/8q7raujQmhZTW3x56QprtBIfX+5NU92/6fzt70fZ56xtuJNmEPB2HDndaCdtentgDvhcDGfO0zJ9h+Sibdl1uwwRBoaY1ri2bz34KRmOn7ra6/ac+7TLPMmqfGWr8yGMqr+lff2drXoe/t4Po+rzmA13d+47Wnjb3gKemV1nZh8zsy+a2RfM7GcXl7/dzE6b2SOLn7tCPH/Rzpp82BjAAvM0dN9UZs7hzrehFqdpEzDqVvGGOnYtL+T5Dn6+Q176p+g2MeqjfyoLelTxwsgbc/Y9Bs17PsbC/WpSvWsS7qR+j8F7UdIvOOceNrMVSZ8xswcX1/2Gc+4/hG4AOy2AHIP3TXk4DUJ19a7u9MyybelrG5UtFvLQMzc1nnp5x+7Ha4WOG/Y+N0gFcW3fevCT14c6Nq9qu0Y2PdNb//TS8sagceVY/nf7Zw4sadfRsBVabDX0uDS9VsXQbZm7supd03An9VjBc8497Zx7ePH7OUmPSuKrIQCDmmLfdO56m3y4q6PqfIF9bqOQFaKYKnkh+J62OSYh+qeyc2jlDTKp4k0bVbth1K3etQl30kDH4JnZDZK+U9KnFhe91cw+Z2bvNbNdQ7QJAGLpm9pU75JQN+Zg59MQUzKrQkjTkNek6jdkyOsz6M1Z1/5p+/JLW/5fFPQ4Lg8Iy1e4u3fXJwsfp/eAZ2Y7Jf2JpJ9zzj0v6V2S9ku6VdLTkt5RcL+DZnbYzA6vXzjfW3sBzIOPvumlf/iHzcvbBq26wSQd6KYU6ppU7/K2VVXVLjHUNov1WK+xCF3NizVE+uifXjz7j7kr8OUFPUIe0J86n7cm4U7qOeCZ2eXa6KD+wDn3p5LknHvGOfeSc+6CpN+VdHvefZ1zh5xztznnblvatqO/RgOYPF990/Yrr8x9/Lqhrep2Uwx0XSWBrm6wk8KGuzoBoWyxjya3yYrlhOF9CBHE8h4z9HGGdfjqny5b/SZJ9ZdZT2OaJuBH3c9Sm89pWm+LrJiZSXqPpEedc7+euvxa59zTi//+mKQjfbUJAPrqm87uX85dFCSGUBKLPs4d2Md2LFtwJS0JcMlUTKp7zdTdznUeJ08k4S5I/7TzxrN64cnVLZeVLcACILyiY2Pb6HMVze+TdK+kz5vZI4vLflHST5jZrZKcpOOSfrLHNgFA731T0+PD5hDuQut7GzYJHz6D3VCrag6lbcir2kYxhLsFb/3Ty5a+vuX/eSEPQL9CTM+Uegx4zrlPSMr7C3t/X20AgKyQfdO5621LVart4inoZqhtGGqZf2yVF9bytnmd4BtRsJPkv3+6c99RPXDywOb/syEvXcXjtAmAX31Ode6zggcAaGBO4S7E9MxYtp+vqYR1za2Kl6fN648t3IVSFfIADCt9/F2b6p000GkSAGAu2oQMFlLpLrbtN+dzuaUtn1zK/YmhTVP3iu0vbP6eHTSmB5Q+jwMCsKGqeuf7c0fAA4CIxBZM+uCzehd7OO4r6DEttNpcgl2RuidMTrCSJuBXm9ORfODMa2vdjoAHAIHVCRyxB5NQfIW7sW2/uYa8vk6KXmbuwQ7A9BHwAKAH6fCRPUn5mIKJTz7CXR/bL1QYmOu0zaFCHsGu/vE7CU54Dgwrfbxsok4Vj0VWAKAncw1yebqGuylty3TI8111i3XBlbV9672FrbmHurpYbAUII296c+gvT6jgAQB61SXcTb3imVT1Ygxlvq3tWw9azaNily9dxWt6HB6AOFRV8ajgAcDEpQfRQw54uwa7IaW3W19TDH1V9mKt4iV8b88m+3iyTw69fwGYr7YraG6EvD/KvY6ABwAIrm24i3HgnRcgQoc+TppeT91wl90fV064KPc1ANPTdHrmAycPNK62M0UTACZu6PONtQl3Y5mKGXqaYVbb6ZtzCIZtwx0AxC5vsZUyBDwAQDBNB9OxBrskyGV/hkLIu6jJlxeEu3o42TkQnyYhjymaABBY0yAw14UhYgx2UhznbsvTZtpm7Mfj1dH280G4AzB2dadrEvAAIIAuoaDLfWMKh3UH1LEGu7FoGvTGGPK67teEOwBDyDtFQpUXnlzVzhvPFl5fJ+QR8ADAo1irPX0bKtzV2f59huCq5/K5vxw/dfWkQ15bhDsAsfB1/ruqkEfAAwBP3BIDSanegNpnsGsakvo6yXad5/B9+oUm1byxhLwu7xXhDsBUlR2TR8ADAHjTd7hrou/pq9nAVvX8yfW+gt6UQl4bhLv2Vo6xBh8wZnyCAWAihj7+rmpAHWKFzLpTMofeNlL94OarrXWD2w17n5vcCpuEu2IbJ0cGELMXnlztdH8CHgAguBBVu9iOt6sj1pAnTSfotQ13hEIAU0HAAwB0VjQ4HvK8drGFu0Tdc+gNEfKk6Z4vD5dqevJkAP4VTYl+4cnVLT9NcAweAPQgPWgOcczTkGEmL9yFDnVlASnWYJdVZ7GX5ZNLvS++kr7d2I7PowpXrmx6ZtcpYQCq7Tq63nolzfRntOw0ChIVPAAILjuonspUuDxDVuyk8YS7RJ1qns/X1KaaN5Z9lXAHYC6qqnpU8AAgsCbnJxujIQLd2IJclT7Pn9hmfxxrRQ8X/d1LO7f8n+mZwHQR8ABgAD4HylMLOwiv6ZTNROipxkMasvIcq11H+/viAZizlWPbdG7/BW+P19sUTTO7zsw+ZmZfNLMvmNnPLi5/uZk9aGZfWvy7q682AcAQfdPUBsYYry77YjJ9c8rV6aGF6p+y1bv0VC/OgQcMw+dnr89P8YuSfsE5922SvkfSz5jZt0l6m6S/cs69WtJfLf4PAH3ptW8i3CE2PvZJwl4w3vsnpmYC8fIV8noLeM65p51zDy9+PyfpUUl7JN0t6f2Lm71f0o/21SYA6KtvOn7q6smtnonp8LlvEvb86aN/YvVMIC4+Qt4gx+CZ2Q2SvlPSpyTtds49vbjqK5J2D9EmAJh737RywnEc0oyFWAxoLMfsjWG/99E/Ub0DxiF9TF6bwNd7wDOznZL+RNLPOeeeN7vYqTrnnJnlrnNsZgclHZSkK7av9NFUADPio2/a/oqr+miqV9ml5bP/H8PAN3ZjWoEy5IqvN+x9bhTbIEY++qeVa7/pkuup3gHx6lLJ6zXgmdnl2uig/sA596eLi58xs2udc0+b2bWSns27r3PukKRDkrS6tJuT3QDwxlfftHzj3l77pi7TM+ucM4xw115eSMq7LMbAEzrkJc9RV50Twk+Zr/7pm179zZUfehZYAaahz1U0TdJ7JD3qnPv11FX3SXrz4vc3S/pIX20CgLn1TSsn3GxOCJ281vRPSG2OPYv1eLXQwTOm1xzzFxlz658A+NFnBe/7JN0r6fNm9sjisl+U9KuS/sjM3iLphKR/0WObAGA2fVOTgBPzoDdP3deW3M7n6/MVVGKbyhmykpcY+jWPYD+fTf8EwJ/eAp5z7hOSinrSH+yrHQCQNta+qemUtSlX7dq8thBBz5ehQ09aHyFPGub4vBjf+6yQ/VPT4+92HDnd5ekA9IjJ1gAwcU0DkO+B79q+9S0/vviYdtn1MUKGn1imMMYQNOvsN0322zGEOwDjl/fFyK6j/v4OFhnkNAkAgH4MWbkrGpT7WDRjTBXJO3Y/XnjdQ8/cVHpfH9W85ZNLXoN1KH1V8Qh3AKaOCh4AjEzdcNQmBPka/IYKFKEWSwkVGMvCXXJ98lOmazVv+eRSp1DdVxWv7etssl+M6cuBIfVRZQAQBhU8AJigmAexbYNG1WtaPbZWev3Z/cutnrdIVRipCm15ty+r6PmocA1RzUtvh6qKZV9WTrhZV/I4/x0wbVTwAACS4q7elYW71WNrleFuLKqqeT6Oy2tbzWsTLrOvpUu1smi/avtlRsxfggyBc+AB/fFRIS97DD7NANCD9PnOsj++xTw1s02wqAp3dfUZAptW75rc39c+M+TJw/sIsnXMMeRRvQP6FWIF2qqAyBRNeHX+lj1DN2ELlnXGGKQHs12n4MW4qEoXvsJd+j5FUzV9TdvrGu7Sj1M0pbHJdM2yRW2Sy+u+d01Om1BnOyS3yXudfS26MvfpmgDGo27ljwoeOjt/y57Nn9jE3DbMR5NqRJfKRdtw52Nw22e46zolc0zTOX2FRZ9ChK62r7POPj+m9zu0ttU7vixtjzEIiuw6ur75U/e2dRHwAGBEhpxWVyY5riv9k3ebusrC3dwUhR+f0xhj3a+6vsZkf5njftNE9vg7VtD0Ix3sxhryxtrusUmHvXSYaxrsEkzRRGfpb/bqdgR1vg3s2qnwjeNFPt8XNBP7sUQhp6bFGhp8r6Y5Bj7OPZhWZ6rmQ8/c5L0C2eR1NAl1c5im+dLa9tzLWVwFRZKxw/lb9jA+6GjHkdONx7Vdvmgh4MErnx0AnYkfTTqUvNvyPvSvr2OPYjVU9c7XAD9EsPEhmUbrK+g1OR6vb3n7Stnxl3NUFOyo3vmR9/eUoDRvbUJeW3xtA0yYj46E4xina+oVi9BiCOFtApbP4yWrtkGT8971MRUVG5pU7Qgk88Tf/HEj4AETFaJzJughtNDVu74qOL5P6B1iqmNWqCm1fZ/cvGxf4Vi88nBH9c6PKf6dnOJrGkJfX5gQ8IAJCt0RE/TqibnyQPUOvip5dSqZfYW8OgGu6DZTPyfe9jXCXR+q/jbytxO+lIVFAh4AIAqhB9hl1bsQgbfvylUbfYe80NukS4WWLz0uxfRMwL+2n6sdR05v+SlDwAMmqM6HH+HFcIxWnlgHsmXt6jq1MlS483kMWh+PU6Zr2Ku7vxcFPV+vsey9Prt/mYVWMtouww4grCaBLotVNIEJC7liEwEynDbB8Nz1VqsCFmu4qyMZmNc9jqrOQN7H9qhaTbLtqpp1Ak9sXyIk7akzPbluoCt7jUX7/dn9y5fsJ31XcGNXFero44FwkvFZqM8ZAQ+YuKTz8Bn0+MNfn8+l5KsWwagKeVMZxKYH6nlhr26Fxuf2qBPy0soCX99TO32uqpnwtd93CbDpLwQIdxfVqdbRx4fDtkUi5L5AwANmos0J6cseA2F0rciMfbBatxKZaDvdLsR2ahJq0iEuCXtNg11s1busLiHP52sj3G3Y/nVHuANmgmPwgBlqM6ebP/rtxT4Qn5uQg/o273Ufi48M5fipqxtvk6a3b/t+zinc1UU/D0wDFTxg5viDPgxCX7GmVbymjx2az2m5Zc8xJtn2Fm2ftq+ryT5DsAMwdQQ8AOhB1wF5qJNQxyoZhPsKen0P6pssNtL2sfuQ7He+j9Pr8hrW9q3nfh7S73HefkOwK8eXfcB0EPAAwBNbNy2fXPI+GJ5buEvLDsqrAl9sg/i6las2jzVnRSEvEdt+EDvCHTAtvQU8M3uvpB+R9Kxz7pbFZW+X9L9KSv7i/aJz7v6+2gQAIfomnyFvzuEuz9gH7oQ0f6pC3hT0MXYi3PkV8vREQF19LrLyPklvyLn8N5xzty5+CHcA+vY+BeibfAw8pz54RdzY/6LwPgUcOxHu+sX2Rl96C3jOuY9L+vu+ng8A6gjZNy2fXGo9SGZwDVQLcQ6/mITqn5quooz5ye4f7C/jEsMxeG81s38l6bCkX3DOnRm6QQAgj31TkymbBLu4TD1A1BXi2FJfYm1XYK37Jwbq4TFNE0MbOuC9S9L/Jckt/n2HpH+Td0MzOyjpoCRdsX2lr/YBmKdWfdNlq7sKH7BrcJvpIBYDydtfYw55M9Oqf1q+4ipJ0vlb9hDygIkbNOA5555Jfjez35X0ZyW3PSTpkCStLu0Oc4IkAFD7vumKPdfRN00Y1dXhtgHB8qK2/dPK6t7N/omQB0xbn4usXMLMrk3998ckHRmqLQCQoG8CECtf/RNTCMNh22JofZ4m4Q8lfb+kV5rZKUn/TtL3m9mt2phmcFzST/bVHgCQ6JtQD9W7YbWZHpo95+AYT1ERun+ikgdMU28Bzzn3EzkXv6ev5weAPPRN8etycnBpnAN7tFe0vySXj2l/6KN/IuT1Z0zbmirkuA29yAoAoMIcjz/qGuqKHiumwf3KifxDNsd+MvdQyqp4TfaXWPeHIY0peGAY7CPjQsADkCvv2zs6925WTjgG7zX4DHdFj933wL4ozDW5LftOvi77yw17nyPkLTCAB6aDgAfMXJNpGAwA2ksG7enBOwP24fQ1sG8S7Oo81pT2mbxtU/X6mh6Ld8fuxzd/f+iZm3JvQ8gDqvG3f1wGXUUTwHDO37Kn1Rx75uX7s3LCeQ0AU9CmGnPH7se3/IR8rrpCvbdj31+S7VL0Oqquzyp7D7P7Qtm+EXJfiMVLV5jOHChfLIj+HZgGKnjAjPj64508Dt/o1VM1WE2u71KdqTtAnUqlomywXqdqkwgxZXPsISyENtuky+eiaP9ILs/bL+ZSyTtzYEm7jhZXQZmpAYwfFTxgBtpW6+o8LsLzuUR/zJWKOm1rWqWrW9nzsSR/StEAACAASURBVF2aVu1Wj61t+WnyPD6t7VsPtpDPEFXqOvtHk31ois4cWCqt5tG3A8Pr8jmkggdMWB9/pPm2t1zTxTXaVCuahpMxVip8DMjv2P14ZUWvrTrvc1WIS64/u3+51vPFfjxe3X1/9dha6Wtu8lrz9pM3rR7Wh87elnvb7P4wxs9GF0nIK6voAQijzhit7YJ3VPCAierzG1i+7R2fmCt5WT6rLSGOw6oKMk0rdHVv76MyFrJyVyX9OptsnyJF4S79b537jOmz0cRLJd8b5FXz6NeBcLp8vpJZWWWPQcAD0BkVPIxJn9PzugQXH6GnTIhwV2dKZlGADf16IZ3bf6HwuqoFWFDfFP4mTuE1zBkBD5ioPjrnHUdO80dgxMZSqQg1rTLPWLaJ1G1RnlCVuyohQ1zefpJMzcybojlXZSEviyoeJMKeb318rgh4wISF6pQJdvXFfpxUTPo89slXFa+sWhVrRWqoaZlDbY+m4W4Ox+AVhTyqeP7k/Y0c299N/taPF4uswJuybyR8dBBNv/GgU9qw48hpL98WsT3DaxsGj5+6elSVpzYeeuamUa18SLjbqsv2aPK5aLqf9FkdHtr25Ze2/D8JeSvH+K6/D/wNhdRsLNtlESQCHjqpu6MOMc0j+5xz7lybhLw5b6c5im3VwD7DashVNUNr+mVAyCmZvsJdndVDh5paOhU7bzyrF55c3XLZuf0XtoS8qvPkoT5fX7BiXrKV9NLK+l/kX0zAQytj7LDmfnLuub5uoKm6obco2MRWvRtDuBvCWMN9V3VCXhqnwumGbYdE2djZ9/Ro6vIAEFhZteXc9bb5M5SxTO+c24C8qKIVy3GdPk9g7vO1zm0/aWPnjWeHbgKAhRDHvhLw0MoYD7wdY5sxHemBaohQ13WaZUwhr+y1+By8Fz1W121ZZ6ph1f37DHfLJ5e0fLLZAKNuuKuzLUK81rL95KFnbiIEVmCxFWDcmKKJTpLAFOuUTQIdYhK68jKlxVbKXsvYFlxpoiwQ+dx/mga6Ls7uX96cqlk3/NZ9rU32E0IdgKEUjZNDfZlCwIMXIYMUq2cC9XUJeWNacCUZrLcNej4G++eut8JKVjrU1NVHuPMR7NpMzWxS1fQZZJu+zzHt/30rOw4PgH8hK+UEPESPwAZsDMzrLpYxl0qeNJ1qXshw57Na5/O4O1+mtL+H9LKlr2/5f95iKwCmga9qAGCC2lYiYhwoHz91tdfj8vqaqlf3+LO+pmV21Ue4K3u9ZV9wzLnyBmBezu2/sPlThAoeAEzU1CobdaZsJoqqen0fh5WdqjnUVMUx6Pp6u+7vhEQAMSkLcFUIeAAwYXMKeWltg1zTQX7ZcXiJpqtqxhjsQlfvfL3mqe3vANAGUzQBYCTaHks1tcpE1ZTNMSPcDYdgCCAWXap3Uo8Bz8zea2bPmtmR1GUvN7MHzexLi3939dUeAEjMoX+aYijy/XraPp6PgDL0ye6LhAp3Tc8FWXeBoamZQ98EwL8+K3jvk/SGzGVvk/RXzrlXS/qrxf8BoG/v00z6p6kFvTG/nhAnvPcpRLiL+fVG6n2aSd8EYEPX6p3U4zF4zrmPm9kNmYvvlvT9i9/fL+n/k/R/9NUmAJDm2T9N7VildMhr8rp8hcO80JIXkMYSbnyGu75f85T27Tn2TQC6G3qRld3OuacXv39F0u4hGwMAKVH2T03Oh1clCTdTGQwnsqEt/fr6rPaNJcxldQ13Y33dI9K6b7pz31E9cPJAmFYBiMbQAW+Tc86ZWeFfFTM7KOmgJF2xfaW3dgFAWf+U7psuWx3noTBjneJY19RfXwwIdcNoMnZaufabLrmek50Dcak7PXPnjWdLrx96Fc1nzOxaSVr8+2zRDZ1zh5xztznnblvatqO3BgKYrVr9U7pv2n7llb00rO1qmkCZlROucfVuasfUjaSa3Wrs9E27mp2uA0CcqsKdNHzAu0/Smxe/v1nSRwZsCwCkRd0/EfLgU5tpmX0FuzZTkidetY26bwIQxs4bz9YKd1K/p0n4Q0n/TdIBMztlZm+R9KuSXm9mX5L0Q4v/A0Cvxto/EfLgw9yrdjEba98EwJ8mwS7R5yqaP1Fw1Q/21QYAyDPm/ikJeUOeJ2yoRUymLO/9DBHo24S7sZjCapoh+iYWWgHilHf8XdNgl4hmkRUAQHs+V9esK2/wnFxG0Gumznu3tm/da8hrEu7GFOwAYArKwt2d+45Kkj5fcD0BDwB60CV81R3UDxHy0N0Q7xnhDgDGKQl3ZQh4ABBY1wF89v5lgS+GkEf1Lgxf1bu64S6WYNdlGnLTcz2y7wLoy66j6zpzoFm/XifcScOvogkAk7W2bz1I2Kp6zOWTS70swHL81NWXDIgZIMdtbOEuLdmv2+zbeftq3m3mgOPvgP7tOHK60e3bHnuXIOABQAChq2h1Hr/PoJf+F375eh/rhLuxrJAZMugBQIzqVu8kpmgCgHd9TZFMnqdqoNvHSptlg2ZW2Wynz9NgjCHU5Wm7b2enbrJfApgSAh4AeOKWXOFAM2TIqbu6Yt/H5xWtsslgulyfp0MYa7DL6hr0ACBmedW7e3d9Uu8ouD0BDwACywadEFWDJtW8PkLe2M8/NpS+wt1Ugl1WDOeFBIDQ7t31ydLrCXgAMJAQVT3f50prawonme5L6Pfr3PWmlRNusqEuD0EvX3aBlReeXB2oJQBCYpEVAAiobsi5Ye9z3gJRnVU2+5AXWpkSN4w5hbu0Litv9rVIUV+eX79iy/8Jd8B0EfAAICJ9hby+pAMd4Q5DqhvYphbs8uSFu5VjDAmBkPJOlbDraJi/1XyaASCQtmHNZ8iLIeixND1iUhTg5hDspHqVu1CDTgDFfH7JwjF4ABAhn6tNxnJcHhCTOX4misId1TtgWvhEA0AA2SrcHbsf3/xp+xhdpCt5MVT1APTrpbXtuZcT7oD4dD1Glk81APSsSdDzHfIIdwAShDugX3nH4YXAJxsABjJEyAMAqTjccfwdEJ/sKU4+cOa1pbcn4AHAgOpW8wh5KJJ3InNsWDnhCn/mauXYNsIdMKBsFS/9ufNVVSfgAUBgdQJc3ZBH0IMkgkqFOttmbttv+xpTMoExyR6H16SKxyqaABCJO3Y/roeeuanydumQN5XTD9QJrlN5rW3MKYh00WY7rZxwsz0RfFpR9a6vY4aAOdlx5LTO37In2OPzVQ4ARKTJKpvSxareHCp7c3qtibpVprkHwK7VuLluv11H1zd/AMQhXWmvquIVoYIHAJGpW8nLmmJlr8iUX+tcw0YbPrfVnCp5BDpgeOkq3q6j6zpzwN+5OangAUCEmlbyssZW7eoS0sb2Wot0qULNIZiEWChl9djaJc8xVdu/7hpX65ieCQyvTRWPCh4ABPbQMze1CmzJfdpU89LGUu06furqziFtLK814SNQTDnchQhc2VC3emxNZ/cve3+eMSPYAf1LV/FWjm3Tuf0XNq9LQt7OG89Kqg55UQQ8Mzsu6ZyklyS96Jy7LcTzpA9mpPMCUEdf/VOZtlM289yw97lRBB8fsmExhtc95QqRL32EuikI1TcxPgL6k11spSzkSRtBLwl5ZaIIeAs/4Jz7aqgHz65Uk/yfjgyoZ+afmaD9Ux0xhLzlk5ceH7C2z++xPD6qeEWGDLehgt1Uqnchg2+dcJeu4o3sWDxvfdNM+3YgasmCK9lqXlXIiyngBVO2DOnMB61AqbzPTtWyvnyWwvE1ZVPyF3bSoc9X2Asd8pLn6EPI4DKiEFJq6HA3F9vOf4P+GRiBvAVXiqZsFollkRUn6QEz+4yZHfT5wHXPMXH+lj1Bz0cBjEmXz8MEP0et+qdsgKgKZW9aPbz5U+WO3Y93XoRFqnfuuSaWTy7lVvnaCB3AQi/IEvok2n2Gu7V9694rtVIcJxpfevSpzd9HGAaDjZ0A9Cfvi5e8xZDSp0+oEksF73XOudNmdo2kB83sMefcx9M3WHReByXpiu0rwRpCRQ/obmKfo9L+Kd03bX/FVV6eMB3yPnS2+LAaH9M2m1Ty1vat1wpwyyeXvASCkJW8saJqV98IA1tT0YydAPQjb8pmnigqeM6504t/n5X0YUm359zmkHPuNufcbUvbdgRv0wSrEEDvpvA5quqf0n3T9pUrt9y3aRUvT1VVz0c1r0mIqlvN8VnJi2FxlBgMFe58VmaluMLd+muu2/x9bCtpxjh2AtBOURWv6NQmK8e2lVb0Bg94Znalma0kv0u6U9KRYVu1YQqDU2BoY/4c+eif6oa8skqdVC/o9anPkCfNO+idu94mU7nrwwwqd1GPnQC0s+PI6cKZT2VhL8/gAU/SbkmfMLPPSvobSf/FOffRgdu0acyDU6CNEPv8iD9HXvonH5W8RFnQ61LNazMVMsRxWVXmFPKmGOxCV+/mEO4Woh47AWiv6vCWOmFv8GPwnHNflvQdQ7ejzPlb9kzlWCJgMGP8HPnsn3wfT/am1cOFVT+fp1SokoS8omqdr+Px0pKQN9Xj86YW6voyo3AX1diJcwwD/mXPj9fU4AFvLMY4OAX6kF7Kt+7UgblKh7yHnrmp87TKpJKXF/TahLwup04oW4AlRMiTprcIyxDBLvu++JxWmxXzCczHdvxdLDjHMBBO2eeoKvwR8Bog5AHoqizkfejsbbVOk5BVVM3rs5InVYe85DY+xVrNS4e1vGATQ5gruk3IkNdFqApdOtxRPfWDqh4QVtXnKoZj8IKiYwHComp3ka1brRUH01WybACrWmylSNlxeU10DUpVISJUeEgWYUn/VN2uL8mxdOmf0JLVTtM/Q+pSvVs9tka4GzHOMwz0b/IBT/Ib8uikANSRBL2iwFcW8tryFfK6qhPy+qgS1Q19YxdbmPMp5HF1hLt+EfSA/swi4ElU8oCQ6izdO/fPYFWgSYe8tlU8yU/I8zHdse/TKMzJ2MJc2+pdyKod4W44hDwgvNkEPMnfAJPOCVM29yAWUjbQlFWUhg55PhDy/BhboPOhrymZhLthUM3DmCX7b8z78ewWWUkGr13fEBZcAerjs1LM98qaiTEsvJLIXj/1EDP115fWpnrXNNwtPfqU1l9zXeXtqNrFh7EUYlY3K8S4qNDsAl7CV9ADgCbyThlQFPLarqqZ6BLykvb4OG6t6cqMRbeNNRjF2q4xahLulh59asvvRSEvewqEdLjjvRseIQ8xapsPYjlVyKymaObZceR0qzdh6DcOCMnn/s1nZauiAWXRoitdpmpK3adrxnT6gezCNXV+fD1PEQJCsSbVuzYrZa6/5rrNUNcm3KE7Dn0B8g09fXO2FbysJicTZMCKOeha5eZz0lyoSl6RutM1fVbz+hbyGD/CXb6mwa6rtuGO9y8uVPIQC5/BbKj9moBXAx0O5mzHkdONOjs+L8XqDCjTJ+5Owtcdux/fUslrGvaKpmomjy3VO1XDmIOeb4SDfHXDXcjTH0hU7vrU9G9EGUIe4AcBD0Al/uD2r2zxlSSsNQl6ZSFParb4yg17n5ttyGsT7LLTXKe47WIJdlK9cEdA94uQh6mYynRhAh7QQciOgD9w4+ZjAJkNeZI6B70yIUNe04VWYtTkPS07drHourEGvzrhbohgJ1G565PPkAdMyRBfWhDwMFux/yGq0z5CYFzckvNeGUiHPCn/VAp1g15VFU9qPmUz5lCSFzzaDvjrvK9dF6QZ4xTYMYY7qnfxo4oHVDt/yx6p4GNCwBtY7CEjz5g63TFu3yaKXt+Y3iNUSx+XJ+VX86TiFTfbVPiaLMASSyCpEzbSt6G6000M4a5N1S7vVCXwgyoeEAcCXo+m0unFGir63r5nDvQ/3WzX0XqDkhhPuonu6ga9rLanWhhTyGtzQu2VE46Ql8PXdNqQ4a7rdMyqkDf26cRD8nGeYf5uYSghvqQItT+XPS4Bryc+dpY+A0XdIJE2VKhou22HCGhd5bW56r0i7E1P3rRNqf657ZoYU8hrg5AXRohwlxfqpPaV2CTETeH40Bi1GSjzNwox8BnyhtqnCXg9aLKTxBI6qtpRN1SE3LFj2q7n9l8I+vgrx7YVXpd+bW2COcYpW82TwgW9JouvDKFN9c63mE4In5Zul88A3uc29x3ssgh34TQZKBPuEJOuIW/o/ZmAF1jdnSOWYFdX3VARIugNsU1DB7imz18U+JLXXPSecOD69PQV9OqEPKp4cRkqdPqs3rUJd3lTLwlxw+FvDsYqu++OafE7Al5AVTtC3QAydLiQuleQfAS9Oh+sJqEuxHbdeeNZ74/5wpOrl1xWFfjKgh4hb3yyg9O8AWwfQS/GSl4M1TvfugblomA3tgBe5zi7uoulMA0TQFfpsVPsh78Q8AZSFURiCHVpTSpIISp6PsKd720aIszVeZ6ywFcWxDEuZYPR9LFDWX1O3YzBuettkiEvdmXb/ez+5dZVvKKKXfKcXRDyAPgSY6hLI+BFpm4IaRIu8gJBV+f2X2gd8qT6Qc/XdExf4a5pqLtz39HGz/HAyQOVbaj7nha9F1TxwrD1fo8JKlsJMLsQi5R/bruy0Ne0WldWHQo5sE4G/k2CXtOwULXqYl6wbsNHhS37GKEqd2XbPR3U6oS9kMEuQbgDMBcEvAEUhZGyENKlWtT2vlUhomvIk8qDxpDhru02axPo6jxGNvQl7cu+R2XvCfrR9zm2qkKeVB46uk65rBMc+hpYFwWBJIB0DQp13tv09qgT9vqYMtn0OZq+X1UBuyy81XlcAEAzUQQ8M3uDpN+UtF3S7znnfnXgJvUuVLjrIu958wKFlD81sG3I87U0bYhqaB4foa7Jc6TDXl41Lxvy6r4PuFTbvim2EynnVfO6Pl4dsVRMfAaFsumxWWM63i3R5T3L284hq6pzx9gJQJHBA56ZbZf025JeL+mUpE+b2X3OuS8O27Iw8qpNRUGkLHg0CRVVU/6aaFo5ahLy2mhTDZX6CXX37vpkp+f4wJnXFj53NuRJW98TKnndde2b2oa8UKGo77ARS7gLJbYQHytCWxhzGzsBaGbwgCfpdklPOOe+LElm9kFJd0uaRSeVF0SKwkfbSlHT+9UJhHUqR4lQFaSm4c5HJbRqW3YNdWWPlQ58STuqqnmJ0FW82FeTaqlz39Sk2tNFbGFj6uEuEdt272qM71vd92CMr63CrMdOAMrFEPD2SHoq9f9Tkr471JP1cQLu9POk1VnC33e4a6NoOmBWk5DnW5/hro9qXR337vpkYVUvT1/vRXZfn9ACLt76pqkFgTITHEiXmtN7i6j0OnYCMC4xBLxazOygpIOL/6599PRvHWn1QOHHna+U9NXc5/mL9g/6+fZ3zdpoX7zqta/Dtmwqs+1z2/eOntoi/VHZlcO8t/U/U1Xtu75zWwaQ7Zse/+Wfb9c39WMan/9hxNw2ifZ1Mcm+SfI4dgov5v1Don1dxNw2afzty+2fYgh4pyVdl/r/XuUMGZ1zhyQdkiQzO+ycu62f5jUTc9sk2tdVzO2LuW1S/O3LMam+SaJ9XcTcNon2dRFz20pMqn+KuW0S7esi5rZJ021fDKswfFrSq83sRjNbknSPpPsGbhMA0DcBiBX9E4BCg1fwnHMvmtlbtTHpbruk9zrnvjBwswDMHH0TgFjRPwEoM3jAkyTn3P2S7m9wl0Oh2uJBzG2TaF9XMbcv5rZJ8bfvEhPrmyTa10XMbZNoXxcxt63QxPqnmNsm0b4uYm6bNNH2mXP1T0IKAAAAAIhXDMfgAQAAAAA8GFXAM7M3mNlRM3vCzN42dHuyzOy4mX3ezB4xs8MRtOe9ZvasmR1JXfZyM3vQzL60+HdXZO17u5mdXmzDR8zsroHadp2ZfczMvmhmXzCzn11cHsX2K2nf4NvPzK4ws78xs88u2vZ/Li6/0cw+tfj8fmixMMBkxNw/0Td5ad/gn61FO+iburVvdv1TzH2TRP/koW1RfLYWbYm2f5pd3+ScG8WPNg4iPibpWyQtSfqspG8bul2ZNh6X9Mqh25Fqzz+T9F2SjqQu+/eS3rb4/W2Sfi2y9r1d0v8Wwba7VtJ3LX5fkfS4pG+LZfuVtG/w7SfJJO1c/H65pE9J+h5tnMTvnsXl75b000O/zx5fc9T9E32Tl/YN/tlatIO+qVv7ZtU/xd43LdpI/9StbVF8thZtibZ/mlvfNKYK3u2SnnDOfdk5ty7pg5LuHrhNUXPOfVzS32cuvlvS+xe/v1/Sj/baqJSC9kXBOfe0c+7hxe/nJD0qaY8i2X4l7Ruc2/DC4r+XL36cpDsk/fHi8kH3vQDonxqgb2qPvqmbGfZP9E0Nxdw/xdw3SXH3T3Prm8YU8PZIeir1/1OK6I1ZcJIeMLPPmNnBoRtTYLdz7unF71+RtHvIxhR4q5l9bjEVYbBpWgkzu0HSd2rj25Totl+mfVIE28/MtpvZI5KelfSgNr5B/ppz7sXFTWL8/HYRe/9E3+TH4J+tNPqm1u2aU/8Ue98k0T/5EMVnKy3m/mkOfdOYAt4YvM45912SfljSz5jZPxu6QWXcRr03tmVU3yVpv6RbJT0t6R1DNsbMdkr6E0k/55x7Pn1dDNsvp31RbD/n3EvOuVsl7dXGN8g3D9EObKJv6i6Kz1aCvqk9+qfo0D91E81nKxFz/zSXvmlMAe+0pOtS/9+7uCwazrnTi3+flfRhbbw5sXnGzK6VpMW/zw7cni2cc88sdvALkn5XA25DM7tcG53AHzjn/nRxcTTbL699MW2/RXu+Juljkr5X0lVmlpx7M7rPb0dR90/0Td3F9Nmib/JjJv1T1H2TRP/UVWyfrZj7pzn1TWMKeJ+W9OrFajJLku6RdN/AbdpkZlea2Uryu6Q7JR0pv9cg7pP05sXvb5b0kQHbcomkA1j4MQ20Dc3MJL1H0qPOuV9PXRXF9itqXwzbz8yuNrOrFr/vkPR6bcx1/5ikNy5uFt2+11G0/RN9kx8xfLYW7aBv6mCG/VO0fZNE/+RDLJ+tRVui7Z9m1zdVrcIS04+ku7Sx6s0xSb80dHsybfsWbaxO9VlJX4ihfZL+UBvl5m9oY97uWyS9QtJfSfqSpL+U9PLI2vcBSZ+X9DltdAjXDtS212ljCsHnJD2y+Lkrlu1X0r7Bt5+kfyLpvy/acETSLy8u/xZJfyPpCUn/SdLyUPteoNcdZf9E3+StfYN/thZto2/q1r7Z9U+x9k2p7U7/1K1tUXy2Fu2Ltn+aW99kizsDAAAAAEZuTFM0AQAAAAAlCHgAAAAAMBEEPAAAAACYCAIeAAAAAEwEAQ8AAAAAJoKABwAAAAATQcADAAAAgIkg4AEAAADARBDwAAAAAGAiCHgAAAAAMBEEPAAAAACYCAIeAAAAAEwEAQ8AAAAAJoKABwAAAAATQcADAAAAgIkg4AEAAADARBDwAAAAAGAiCHgAAAAAMBEEPAAAAACYCAIeAAAAAEwEAQ8AAAAAJoKABwAAAAATQcADAAAAgIm4bOgGtLG0bYfbcdnLhm4GAI+e/8azX3XOXT10O7pY2rbD7di+MnQzAHj0/IvPjb5vkhg7AVNUNHYaZcDbcdnL9Npr3jR0MwB49NHTv3Vi6DZ0tWP7il77yh8fuhkAPProV35n9H2TxNgJmKKisRNTNAEAAABgIgh4AAAAADARBDwAAAAAmAgCHgAAAABMBAEPAAAAACaCgAcAAAAAE0HAAwAAAICJIOABAAAAwEQQ8AAAAABgIgh4AAAAADARBDwAAAAAmAgCHgAAAABMBAEPAAAAACaCgAcAAAAAExE04JnZATN7JPXzvJn9XOY2329mZ1O3+eWQbQIA+iYAMaJvAuDDZSEf3Dl3VNKtkmRm2yWdlvThnJv+V+fcj4RsCwAk6JsAxIi+CYAPfU7R/EFJx5xzJ3p8TgCoQt8EIEb0TQBa6TPg3SPpDwuu+14z+6yZ/bmZfXuPbQIA+iYAMaJvAtBKLwHPzJYk/c+S/lPO1Q9Lut459x2SfkvSfy54jINmdtjMDq9fOB+usQBmg74JQIx89E2Lx6F/AmaorwreD0t62Dn3TPYK59zzzrkXFr/fL+lyM3tlzu0OOeduc87dtrRtR/gWA5gD+iYAMercNy2up38CZqivgPcTKphmYGavMjNb/H77ok1/11O7AMwbfROAGNE3AWgt6CqakmRmV0p6vaSfTF32U5LknHu3pDdK+mkze1HSeUn3OOdc6HYBmDf6JgAxom8C0FXwgOec+wdJr8hc9u7U7++U9M7Q7QCANPomADGibwLQVZ+raAIAAAAAAiLgAQAAAMBEEPAAAAAAYCIIeAAAAAAwEQQ8AAAAAJgIAh4AAAAATAQBDwAAAAAmgoAHAAAAABNBwAMAAACAiSDgAQAAAMBEEPAAAAAAYCIIeAAAAAAwEQQ8AAAAAJgIAh4AAAAATAQBDwAAAAAmgoAHAAAAABMRPOCZ2XEz+7yZPWJmh3OuNzP7f83sCTP7nJl9V+g2AQB9E4AY0TcB6Oqynp7nB5xzXy247oclvXrx892S3rX4FwBCo28CECP6JgCtxTBF825Jv+82/LWkq8zs2qEbBWD26JsAxIi+CUCpPgKek/SAmX3GzA7mXL9H0lOp/59aXAYAIdE3AYgRfROATvqYovk659xpM7tG0oNm9phz7uNNH2TRyR2UpCu2r/huI4D58d83bdvpu40A5sdL3yQxdgLmKngFzzl3evHvs5I+LOn2zE1OS7ou9f+9i8uyj3PIOXebc+62pW07QjUXwEzQNwGIka++afEY9E/ADAUNeGZ2pZmtJL9LulPSkczN7pP0rxarQn2PpLPOuadDtgvAvNE3AYgRfRMAH0JP0dwt6cNmljzXf3TOfdTMfkqSnHPvlnS/pLskPSHpHyX9L4HbBAD0TQBiRN8EoLOgAc8592VJ35Fz+btTvztJPxOyHQCQRt8EIEb0TQB8iOE0CQAAAAAADwh4AAAAADARBDwAAAAAmAgCHgAAAABMXv/OMgAAIABJREFURB8nOgcAoND6zXu3/H/psVMDtWRe2O4AME0EPADAYLIhI30ZgSOMvG2evpztDgDjRsADAAyiKGjkXU/o6K5qe6dvx/YGgPEi4AEAelc3bDS5PaEkX9NtndyH7QkA48QiKwAATFSbcCcRloGpOH/LnqGbgAEQ8AAAvfMdIAgklyLcAfOWhDtC3vwQ8AAAg5hLkFi/ee/mT5/PCWC+sqGOkDcvBDwAwOR1CTxdwln2fn0Ery7PMZfQDUxZUZgj5M0HAQ8AMBgfgaLoMbKVs7aLjeT93vS+ee2KDeEOGL+qEHf+lj0EvRkg4AEARi0bwsoCVJNTBZSdo69Jm7rcpolYgyOAfjQJboS8aeM0CQCAQS09dqpzMGly/66nAOjzFAJ9BTaqdwAwHQQ8AMDond2/XHmb1WNrm7+HDGk+wmbZYxS91vTrq4tgBwDTQ8ADAIxWnWCXvm2dEFR3eqWvcJR9rPTzh3h9EsEOAKYsWMAzs+sk/b6k3ZKcpEPOud/M3Ob7JX1E0pOLi/7UOfcrodoEABL901Qk4efc9dbgXhdDUN2QljxPmwpZk/tng2U63NV5jSsnXK2QR7iLF30TAB9CVvBelPQLzrmHzWxF0mfM7EHn3Bczt/uvzrkfCdgOAMiifxq5JuFubd+6JGn55NLi9vVDXjpkZcNT0ypeWfgqCndVry95bRuWFv/mPw/BbhTomwB0FizgOeeelvT04vdzZvaopD2Ssp0UAPSK/mlcsouwZMPP1pBTbG3fem7IS6uantlkGmQbeVW7tq9Pulg1JNyNA30TAB96OU2Cmd0g6TslfSrn6u81s8+a2Z+b2beXPMZBMztsZofXL5wP1FIAc9O1f6Jv8mvpsVOX/KQ1OSatSvJYRaHOx3NlH8Nn+xM37H1ON+x9zvvjYliMnRAap0qYruCLrJjZTkl/IunnnHPPZ65+WNL1zrkXzOwuSf9Z0qvzHsc5d0jSIUlaXdrtAjYZwEz46J+29E2XX0Pf1FLTClOz4+62Wjmx8TZlK3E+TklQ5zHKqoCrx9YuCYHLJ5dKq3jHT13drJGIHmMnNEVYQ1rQCp6ZXa6NDuoPnHN/mr3eOfe8c+6Fxe/3S7rczF4Zsk0AINE/zc3yySUtn1wqDHdZ2amS6UCZvq7N6QyqJG1L2ipttB/zQN+EprqEO4LhNAULeGZmkt4j6VHn3K8X3OZVi9vJzG5ftOfvQrUJACT6p7EpC1F1jk9LwlFZuKtTeWtbNcwGRKk6/BHy5om+CUMg5E1PyCma3yfpXkmfN7NHFpf9oqR9kuSce7ekN0r6aTN7UdJ5Sfc455hCACA0+qeZqBPuspqeniBRdf66c9fblsBWJZmumdzn3PW2+Xrygi0BcBLom9AI4Qx5Qq6i+QlJpX8ZnXPvlPTOUG0AgDz0T+PR5bi4NuEurSzc1V1NM/sY6ZBX5zHSx+StnHCbj1d2XF6TEIm40DehCZ/h7vwte7TjyGlvj4dh9bKKJgAAfUmOt5Oah7uq88/VqehVTb8sOp6vSLrtTNkEAFQh4AEARicJOtmQkw52TadlNjl5elqbKmP6uLz0cxcpC3npQFt0HwDAfAQ/TQIAAG1lT3KehJbk2LT0cWmJkMfbFU1/bDuVtMmUzexrT+6f177043CSc2B6OPYOZQh4AICoJQElL+hJF6tuvqdj9iV5/pUTrvVxeengSbgDkDhzYOMLsF1Hq1cc5ji86WCKJgBgFJYeO3VJYMmeTmBs4S4tPWWzyuqxtdxTKRDuAEgbwS4Jd8n/MR9U8AAAo5IOLus37218rFk23GVXoyxavKTN6pTplS+LJM+/fHJpsxqXtLFJNY9wB0AqDnNnDizVquRh/Ah4AIDRypu+WSYd7pJgdcPe5yRJx09dLWlr4Aol7xQHa/vWN0Oe1GzKZhrhDpi2suPvqip1hLx5IOABAEYvW9XL03RaZjboNT1Refa5is5bV6XuOfcSyesn6AHAPBHwAACjV1XBywt3ycnCk8pdkaKKXt3g1TbYNT0pelZ6mxD2AGA+CHiIXtlUBFZ7Auan6XTMRF7lLgl5dWzcbqm0ipc97UKTcJc3JTQb8hJtwh4hD4DENM05IOChdz7P3dL0sQiEwDi1DXWJLqtlJsfoSdJxXa2qkJd9vi33r6gWFj1W9vnqLsKSRsgDpi3v+Ltz+y9o5Vj9RfM5VcI0EPAQTIwn4azTJjo2IC51p1/mqRPsiqp4STB7/asekyQ9+JWbJW2t5JVNnVzbt77lMR78ys26Ye9zuSGvakGX9MIraU2reoQ8YD7O7b+w+W+TkIfxI+DBixjDXFvp10LYA4bTNti1qdZlQ1423CW/P6iLVbhsZS1vhc70Y1SFvDqKgl76+auCHiEPANM0p404j07O37Knl3CXnLCz7xN19vX6ADQTYipmVhLM3viyh/XGlz285bo6x9alp2aWXdfmdAxlr7POidLrTnkFEJeiMUl2fJRU74r+j2mjgodWQoaeOudwyQr9LVTyeqnoAf1ZeuxUYRBJn+A7Lals1Q16WythG31LsrLmg5nbJlM0pY1QtnLCbVbLlh47pVXt3WzT8sklHdfVW4Jccv909a5NuCs6/q/J8XhU8IB52HnjWb3w5KokpmrOCQEPm4aoVNWpyOV965TtoIoex3fw4xg+oF9VIS+RDXvZEFTnHHYXr9/oTzYWVNFm0EuCWTrcpYNSEvKk5c3HOa6rc+9f1M6mmq6mSbADpi8ZN+288ezmv0nIwzwED3hm9gZJvylpu6Tfc879aub6ZUm/L+mfSvo7SW9yzh0P3S5s1dc0yybSwS7ppCTphSdXN6+r+iZqqGofIS9+9E3jUeck5tmgUxX4yhQFvSSY5YW7dFs3Qp60EfSWLrl/0/ZkNQ116bYhfvRN6CIb7u7cd1QPnDywGfLSVTyOw5uuoAHPzLZL+m1Jr5d0StKnzew+59wXUzd7i6QzzrlvNbN7JP2apDeFbBcu6qtq1yTcZSt2eZ2UtDXoSdVhL90WpnTOG33TeGVDSt3AV0dxKFza8v+icJdt48Vq3tb7F2kb3MragHGhb0IbRWOsO/cd3fy3KORhmkJX8G6X9IRz7suSZGYflHS3pHRHdbekty9+/2NJ7zQzc851m7eCSjFV7fKmYaaDXSL5PRv00o9Rp9Pq61srqnnRom+aiLqBr46iKmA62OU9Z1nbtk7ZzH+eNghwk0XfhNbS1bv02Em6GPLqYOwyfqED3h5JT6X+f0rSdxfdxjn3opmdlfQKSV8N3LbZiqlqVxbspIuB7t5dn9y87ANnXntJ0EvPLa9b1Uvax5TNWaJvmqiq4NMkAGaDWJtQtXXKZnMEudmhb0Ir2amZiWT89IEzr928nire9I3mnTWzg2Z22MwOr184P3RzRi2msJHXueQdCJx0TGlV30TV6biYe46u6Jvit37z3s2fro/Tx32y9/fVfswP/dN8lI158sZQmLbQFbzTkq5L/X/v4rK825wys8skrWrjoOEtnHOHJB2SpNWl3UxD6GjHkdPBK3lJeKqq5KU7peQbqBeeXNXOG89uhrg79x3d7KDSwS4bBpt8G9VHuIspTGOLMH3T5dfQNw3IVwAqO4/cquqfJHz95r3lj9ViqmbZa6TaNwne+iaJsdMcpcdPeWOnZNxUNl5i7DJ+oQPepyW92sxu1EaHdI+kf5m5zX2S3izpv0l6o6SHmEfej+QD3EfQq3ssXtLhnNt/YbMTSge9ROzBTqKDjBx90wi1DXB1Tvxd5NLz6S3XCnlJuMs7H19yTF+bdpWFwvT2IeyNFn0TWls5tm1z/JQOeYk64Q7TEDTgLeaGv1XSX2hjud/3Oue+YGa/Iumwc+4+Se+R9AEze0LS32ujM0OPYqrmJfKCXtFtmrYhNIJd/OibxqVNsPMV6tb2ZfuNJSUhT8oPUulwl9z/hr3PpU5wvtT6NAnZ11UU+LLbjMA3DvRNaCP9RXpeyJPyD3/hMJXpCn4ePOfc/ZLuz1z2y6nfvy7px0O3A+X6CHlScWdSFPzypm9WBbtQHRbBbVrom+LXNNgVhbqyKlrR7dLBLG3jnHYbIU/aOmUzaW863CX3f/2rHrt4wvPNxyg/dUKddjcNfAS9+NE3wZck5KVRvZuH4AEP41E3wIQIgnmhLBv68joljqMDpqlOuCur0uWFozrXZ4Pd61/12JbrH9TFgLZywuns/ovVvKQ96XCX3P+NL3t4y2NorxYVvfrnCM1rd1HgKwt6hDxg2pIqnrS1cke4mw8CHhobutrXF4IdMC+XTscsd+56uyRg5QXHdLjLe87lk81CHgBUSYc8zA8BD62kw09f59XrA6EOGI+kSpVXyVs54SqreGWOn7paN+x9Tg9+5ebNKtyDX7k5dRzdpdWzjfZcXFjl+KmrN6dlJh78ys2b1yXahLyiqZ1VK3NSvQOmqWpBu2z1ruhLdMZB00DAQ2fZzmAMgY8ODIhb9ri2MkVBLwlBdYJeXvUuHfLSlk9eXCQlL1BtXLe0+ZhJSMwLd+nnrwp5Zcfr1TnlAuEOGL8ms6io4s0XAQ/eNQlPvsMgwQ2YlqXHTtVebMVH0MtKQl7ye91KWxLyjutiSMwLdnXlhbsm59Ej3AHzxHF380TAw6AIZACqNAl50tbgU+d0CVXH3mWDWVUlLXnOdMiro6iKl34+KnUAijQ57zCmjYAHAIhekymbaemqXt5xeU0WVklPzWxi+eRS7efJhryyqaAJAh2AJoZexA7hEfAAAKORDjNNq3pFIa9M2ZTMOtW05PmSx8kLeukpoNn7lj0PwQ4AkIeABwCYhbyQl1ddC3nagryglw52yfV1KnfZgEvgA1A1TZPq3TwQ8AAAo5MON+nj7KqqaumQJ2lLda1P6edMwl6TcJcnvU0Ie8B8FYW8qnDHugjTwdI6AIBRKQp3ef/Pkw5ObY6pa6LOdNDlk0utw93Z/ctbfhLrN+9tfLwigOnIhjkqd/NCwAMAjEZeuDt3vW3+JJdXBb3VY2ubISp0yKurSbhLXmPVayfoAdNTt9KWhDrC3fwQ8AAAo1AU7tLS/29SzVs54ToFvS5TIpPnTofOIukAl7zWtX3rWtu3fknQSyPoAfNEuJsnAh4AIHpV4S69aEmbal6iKui1OVl6kfRz1a3aJW1Ih7tE8nvZayfkAcjD8XfTQsADAIxaEmySSlaiSTUvWz1rUs1rWr3LBrum4U669LUCAJAg4AEAJqVtyJOqF2CpU3FruvpllbxwV1e2LayuCUyDz4ob1bvpCRLwzOz/MbPHzOxzZvZhM7uq4HbHzezzZvaImR0O0RYASKN/mocuIS8tHfLaHKOXvU/6/3Urd0VTMpsi3MWNvgmAL6EqeA9KusU5908kPS7p35bc9gecc7c6524L1BYASKN/moku0zXTsiEtfX06NFUFqDbhLo0pmZNH34RGfFTeqN5NU5CA55x7wDn34uK/fy2Jo7oBRIH+aZyS8NR0umL6WLWyVSarNK3eNZmmmRcM06/Tx/F2VO/iR9+EvhHupquPY/D+jaQ/L7jOSXrAzD5jZgd7aAsApNE/TcQNe58rvT6vmlcW8ooCWpvj67Irc+Y9RjqAZcMdZom+CbUQ0pDnsrZ3NLO/lPSqnKt+yTn3kcVtfknSi5L+oOBhXuecO21m10h60Mwec859vOD5Dko6KElXbF9p22wAM9Bn/7Slb9q200v7cakhlvdfPbbWuNLXVFFlzefpGPJktycVvn4wdkIIO46c1vlb9jS+D6ardcBzzv1Q2fVm9q8l/YikH3TO5c5tcc6dXvz7rJl9WNLtknI7KefcIUmHJGl1aXf7s9ECmLw++6ctfdPl19A3BZaErpUTTueuNy2fXNLavnUdP3V17u2XTy5dclmTc89ln7vK0mOnNsNTXkCs+5zZ11dH8lrzXh/nv4sDYycAfWgd8MqY2Rsk/e+S/kfn3D8W3OZKSducc+cWv98p6VdCtAcAEvRP45MNJxeDy/JmCKqrabgrq+LVqXo1uX8SDvNCbF1twyuGR98EwJcgAU/SOyUta2PqgCT9tXPup8zsmyX9nnPuLkm7JX14cf1lkv6jc+6jgdoDAAn6p5GoqjpthJiti65I1Qui5J0bruy5moalosdrUgHMhrwyZat8YlTomwB4ESTgOee+teDyv5V01+L3L0v6jhDPDwBF6J/i12Q6YToI1bltWvYUB6GmMbYNXE1eW5fnQRzomwD4EqqCBwBAI20DVpsKW9HlMRyr5us4vibWb97LQivAiLVZaAXTRcADAAyur2DVV4ipCotV7ciGPAAA6iLgAQAG1SXc+Q5sdat4dZ63a0Ww7P55zx9D9REAMLw+TnQOAIB3oapxdaprbR9r6bFTvd6/CQIiMG51z23HOfCmj4AHABhM21AReqplUZBq87zJfdq2OWlL2f0JZwCk6vBGuJsHAh4AYBCxhrui5+ryvGNZwISgCIxfUYgj3M0HAQ8AgBIhp0XGiJAHjF82zBHu5oVFVgAAvRtD9W4sCGQA8hDq5ouABwCIHsEOAIB6CHgAgN75PB3B3DXZRmxzAJg+jsEDAAyiLEjM7bi3vlRtV7Y5AIwfFTwAwGCSQJFUlggY/Uhv5/Wb97LdAWBCCHgAgMERMIbDtgeAaWGKJgAAAABMBAEPAAAAACaCgAcAAAAAE0HAAwAAAICJCBbwzOztZnbazB5Z/NxVcLs3mNlRM3vCzN4Wqj0AINE3AYgTfRMAX0Kvovkbzrn/UHSlmW2X9NuSXi/plKRPm9l9zrkvBm4XgHmjbwIQI/omAJ0NPUXzdklPOOe+7Jxbl/RBSXcP3CYAoG8CECP6JgCVQge8t5rZ58zsvWa2K+f6PZKeSv3/1OIyAAiJvglAjOibAHTWKeCZ2V+a2ZGcn7slvUvSfkm3Snpa0js6PtdBMztsZofXL5zv8lAAJo6+CUCM+uybFs9H/wTMUKdj8JxzP1Tndmb2u5L+LOeq05KuS/1/7+KyvOc6JOmQJK0u7XbNWgpgTgbrmy6/hr4JQKE++6bF8zF2AmYo5Cqa16b++2OSjuTc7NOSXm1mN5rZkqR7JN0Xqk0AQN8EIEb0TQB8CbmK5r83s1slOUnHJf2kJJnZN0v6PefcXc65F83srZL+QtJ2Se91zn0hYJsAgL4JQIzomwB4ESzgOefuLbj8byXdlfr//ZLuD9UOAEijbwIQI/omAL4MfZoEAAAAAIAnBDwAAAAAmAgCHgAAAABMBAEPAAAAACaCgAcAAAAAE0HAAwAAAICJIOABAAAAwEQQ8AAAAABgIgh4AAAAADARBDwAAAAAmAgCHgAAAABMBAEPAAAAACaCgAcAAAAAE0HAAwAAAICJIOABAAAAwEQQ8AAAAABgIi4L8aBm9iFJBxb/vUrS15xzt+bc7rikc5JekvSic+62EO0BgAT9E4AY0TcB8CVIwHPOvSn53czeIelsyc1/wDn31RDtAIAs+icAMaJvAuBLkICXMDOT9C8k3RHyeQCgKfonADGibwLQVehj8P4HSc84575UcL2T9ICZfcbMDgZuCwCk0T8BiBF9E4BOWlfwzOwvJb0q56pfcs59ZPH7T0j6w5KHeZ1z7rSZXSPpQTN7zDn38YLnOyjpoCRdsX2lbbMBzECf/dOWvmnbzo4tBzBljJ0A9KF1wHPO/VDZ9WZ2maR/LumfljzG6cW/z5rZhyXdLim3k3LOHZJ0SJJWl3a7ls0GMAN99k9b+qbLr6FvAlCIsROAPoScovlDkh5zzp3Ku9LMrjSzleR3SXdKOhKwPQCQoH8CECP6JgCdhQx49ygzxcDMvtnM7l/8d7ekT5jZZyX9jaT/4pz7aMD2AECC/glAjOibAHQWbBVN59y/zrnsbyXdtfj9y5K+I9TzA0AR+icAMaJvAuBD6FU0AQAAAAA9IeABAAAAwEQQ8AAAAABgIgh4AAAAADARBDwAAAAAmAgCHgAAAABMBAEPAAAAACaCgAcAAAAAE0HAAwAAAICJIOABAAAAwEQQ8AAAAABgIgh4AAAAADARBDwAAAAAmAgCHgAAAABMBAEPAAAAACaCgAcAAAAAE0HAAwAAAICJ6BTwzOzHzewLZnbBzG7LXPdvzewJMztqZv9Twf1vNLNPLW73ITNb6tIeAEjQPwGIEX0TgNC6VvCOSPrnkj6evtDMvk3SPZK+XdIbJP2OmW3Puf+vSfoN59y3Sjoj6S0d2wMACfonADGibwIQVKeA55x71Dl3NOequyV90Dm35px7UtITkm5P38DMTNIdkv54cdH7Jf1ol/YAQIL+CUCM6JsAhBbqGLw9kp5K/f/U4rK0V0j6mnPuxZLbbDKzg2Z22MwOr18477WxAGbFa/9E3wTAE8ZOALy4rOoGZvaXkl6Vc9UvOec+4r9J+ZxzhyQdWrTp3EdP/1bet199eaWkr870+Xntw5n681/f9A4x9E+Zvum5j37ld/5B7KNzfH5e+3Domwowdoriuef+/Lz2sHL7p8qA9/+3d3ahcpxlHP/9SUyEWlqxSpM2aAKlWK+sobRSoZig7UEaK1WON7b0QqoWLCJqCZRi6UURvRDUoFT8oNjUj8ihpraKEa+aWkM+TJPoSY30HGrEgqkiVNTHi/c9Mqyz58zZmd2Z3fn/YMicmXefZ573nf1l52N3ImL3CMmWgW2Fv6/My4q8DFwqaWM+E1XWZhhnImLn2s3Gg6Tn+prftfez9i7kL6NrfoqIN3of7Wd+197P2ofRNTdlevvZqe19pM/5XXs7ucd1i+YCMC9ps6TtwFXAs8UGERHAIeD2vOgOYGJntYwxvcV+MsZ0EbvJGNMIdR+TcJukJeAG4CeSngKIiJPA48DzwE+BT0TEv/NrDkramkN8FviUpEXSfeWP1NkeY4xZwX4yxnQRu8kYM27WvEVzNSLiAHBgyLqHgIdKls8V5l9g4BeiKvL1EV7TJH3O79qdfyroqZ/aHqM+53ft/c2/Lnrqprbz97n2tvO79hZQutpvjDHGGGOMMWbaGdd38IwxxhhjjDHGTJjOHuBJ+qCkk5L+I2nnwLr7JC1KOiPpvUNev13S4dxuv6RNNbZlv6SjeTon6eiQduckncjtnhs1X0ncByQtF7Zhbki7m3OfLEr6XEO5vyDptKTjkg5IunRIu0ZrX6uW/CX0/Xn9YUlvqZszx90m6ZCk5/P+98mSNjdJulAYj/ubyF2Iv2pfKvHlXPtxSdc2lPfqQk1HJb0i6d6BNmOtfVroip/spv64Kcdu1U9tuSnHtp8q0BU35Vit+alNN+W4E/dTn92U4/uzU5GI6OQEvBW4GvglsLOw/BrgGLAZ2A6cBTaUvP5xYD7P7wM+1tB2fRG4f8i6c8BlY+iLB4BPr9FmQ+6LHcCm3EfXNJD7PcDGPP8w8PC4a69SC/BxYF+enwf2N5R7C3Btnr8Y+F1J7puAJ5oe56p9CcwBTwICrgcOj2EbNgB/At48ydqnZeqin+ym2XZTjteqn7rgpsI42E/lfdM5N+VYE/VTm27KsSfqp767qUpfTsJPXXJTZ6/gRcSpiCh7IOce4LGIeDUi/gAsMvBlY0kC3g38IC/6NvD+utuU434I+F7dWGPgOmAxIl6IiH8Cj5H6qhYR8XSkZ+0APEN65s64qVLLHtK4QhrnXXl8ahERL0XEkTz/N+AUcEXduA2zB/hOJJ4hPRNpS8M5dgFnI+KPDcedCbrmJ7tp9t0EU+GnSbgJ7KehdM1Nhbhd9NNY3ASt+MluWptefXbq7AHeKlwBvFj4e4n/34neAPy18OYqazMK7wLOR8Tvh6wP4GlJv5H00QbyFbknX1L+pqTXl6yv0i91uYt09qOMJmuvUsv/2uRxvkAa98bIty+8HThcsvoGScckPSnpbU3mZe2+nMRYzzP8P+Nx1j7ttOUnu6lHboLW/NQFN4H9NAp9/OzUBTfBZPzUdzdBN/zUGTfVekxCXST9HLi8ZNXeiJjogzsrbsuHWf0M1I0RsSzpTcDPJJ2OiF/VzQ98DXiQtPM+SLrV4a4qcevmXqld0l7gX8CjQ8KMXHsXkfQ64IfAvRHxysDqI6TL739Xuq//x6QH0jZFq32p9J2LW4H7SlaPu/bO0BU/2U120yAt+qn1vrSfuuOmdWzLWPzUppvWyt9XP/mzU3fc1OoBXkTsHuFly8C2wt9X5mVFXiZdet2Yz1KUtVnXtkjaCHwAeMcqMZbzv3+WdIB0ybzSzlW1LyR9A3iiZFWVfhkpt6Q7gfcBuyKi9LkadWovoUotK22W8thcQhr32kh6DUlQj0bEjwbXF6UVEQclfVXSZRHxlybyV+jLkce6IrcARyLifMm2jbX2LtEVP9lNq+a8kx65Cdr1UwfcBPZTZ9xUZVvG6ac23VQl/4T91Gs35Zht+6lTbprGWzQXgHmlXwPaTjoCfrbYIL+RDgG350V3AHXPau0GTkfEUtlKSRdJunhlnvQF29/WzLkSu3iP8G1D4v4auErpF7A2kS4TLzSQ+2bgM8CtEfGPIW2arr1KLQukcYU0zr8YJtD1IEnAI8CpiPjSkDaX53ZIuo70Pmrq4LJKXy4AH1HieuBCRLzURP7M0LOt46x9RmjDT3ZTD9wE7fqpI24C+2lUevXZqU035fyT9lNv3ZTjdcFP3XJTTPAXXdYzkd6QS8CrwHngqcK6vaRfCzoD3FJYfhDYmud3kOS1CHwf2Fxze74F3D2wbCtwsJDvWJ5Oki7RN9UX3wVOAMdJO+iWwfz57znSLxedbSp/7r8XgaN52jeYexy1l9UCfJ4kS4DX5nFdzOO8o6F6byTd0nG8UPMccPfK+AP35DqPkb48/c4Gx7q0LwfyC/hK7psTFH4prYH8F5Gkc0lh2URqn6apS36ym/rhphy7NT+17aYc335au48646YcrxU/temmHHfifuqrm1bry0n5qYtuUk5sjDHGGGPlICIpAAAAaUlEQVSMMWbKmcZbNI0xxhhjjDHGlOADPGOMMcYYY4yZEXyAZ4wxxhhjjDEzgg/wjDHGGGOMMWZG8AGeMcYYY4wxxswIPsAzxhhjjDHGmBnBB3jGGGOMMcYYMyP4AM8YY4wxxhhjZoT/AjAEUS9aVdDzAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 1080x576 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AN3WKPgHYGI_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5c057e6-b28e-480f-ba0f-e6f4eed897a3"
      },
      "source": [
        "def project(uxx=0,uxy=0,uxz=0,uyy=0,uyz=0,uzz=0,k_vec=np.array([0,0,1])):\n",
        "    '''\n",
        "    Returns TT part of the emergy-momentum tensor.\n",
        "    input: 6 fourier transform arrays uxx, uxy, uxz, uyy, uyz, uzz and np array k with shape (3,)\n",
        "    output: T, np array with shape (3,3)\n",
        "    '''\n",
        "    if np.linalg.norm(k_vec):\n",
        "        k_hat = k_vec / np.linalg.norm(k_vec)\n",
        "    else:\n",
        "        k_hat = np.array([0,0,0])\n",
        "    P = np.identity(3) - np.outer(k_hat,k_hat)\n",
        "    Oxxxx = P[0,0]*P[0,0] - 0.5*P[0,0]*P[0,0]\n",
        "    Oxxxy = P[0,0]*P[0,1] - 0.5*P[0,0]*P[0,1]\n",
        "    Oxxxz = P[0,0]*P[0,2] - 0.5*P[0,0]*P[0,2]\n",
        "    Oxxyy = P[0,1]*P[0,1] - 0.5*P[0,0]*P[1,1]\n",
        "    Oxxyz = P[0,1]*P[0,2] - 0.5*P[0,0]*P[1,2]\n",
        "    Oxxzz = P[0,2]*P[0,2] - 0.5*P[0,0]*P[2,2]\n",
        "    \n",
        "    Oxyxx = P[0,0]*P[1,0] - 0.5*P[0,1]*P[0,0]\n",
        "    Oxyxy = P[0,0]*P[1,1] - 0.5*P[0,1]*P[0,1]\n",
        "    Oxyxz = P[0,0]*P[1,1] - 0.5*P[0,1]*P[0,1]\n",
        "    Oxyyy = P[0,1]*P[1,1] - 0.5*P[0,1]*P[1,1]\n",
        "    Oxyyz = P[0,1]*P[1,2] - 0.5*P[0,1]*P[1,2]\n",
        "    Oxyzz = P[0,2]*P[1,2] - 0.5*P[0,1]*P[2,2]\n",
        "    \n",
        "    Oxzxx = P[0,0]*P[2,0] - 0.5*P[0,2]*P[0,0]\n",
        "    Oxzxy = P[0,0]*P[2,1] - 0.5*P[0,2]*P[0,1]\n",
        "    Oxzxz = P[0,0]*P[2,2] - 0.5*P[0,2]*P[0,2]\n",
        "    Oxzyy = P[0,1]*P[2,1] - 0.5*P[0,2]*P[1,1]\n",
        "    Oxzyz = P[0,1]*P[2,2] - 0.5*P[0,2]*P[1,2]\n",
        "    Oxzzz = P[0,2]*P[2,2] - 0.5*P[0,2]*P[2,2]\n",
        "    \n",
        "    Oyyxx = P[1,0]*P[1,0] - 0.5*P[1,1]*P[0,0]\n",
        "    Oyyxy = P[1,0]*P[1,1] - 0.5*P[1,1]*P[0,1]\n",
        "    Oyyxz = P[1,0]*P[1,2] - 0.5*P[1,1]*P[0,2]\n",
        "    Oyyyy = P[1,1]*P[1,1] - 0.5*P[1,1]*P[1,1]\n",
        "    Oyyyz = P[1,1]*P[1,2] - 0.5*P[1,1]*P[1,2]\n",
        "    Oyyzz = P[1,2]*P[1,2] - 0.5*P[1,1]*P[2,2]\n",
        "    \n",
        "    Oyzxx = P[1,0]*P[2,0] - 0.5*P[1,2]*P[0,0]\n",
        "    Oyzxy = P[1,0]*P[2,1] - 0.5*P[1,2]*P[0,1]\n",
        "    Oyzxz = P[1,0]*P[2,2] - 0.5*P[1,2]*P[0,2]\n",
        "    Oyzyy = P[1,1]*P[2,1] - 0.5*P[1,2]*P[1,1]\n",
        "    Oyzyz = P[1,1]*P[2,2] - 0.5*P[1,2]*P[1,2]\n",
        "    Oyzzz = P[1,2]*P[2,2] - 0.5*P[1,2]*P[2,2]\n",
        "    \n",
        "    Ozzxx = P[2,0]*P[2,0] - 0.5*P[2,2]*P[0,0]\n",
        "    Ozzxy = P[2,0]*P[2,1] - 0.5*P[2,2]*P[0,1]\n",
        "    Ozzxz = P[2,0]*P[2,2] - 0.5*P[2,2]*P[0,2]\n",
        "    Ozzyy = P[2,1]*P[2,1] - 0.5*P[2,2]*P[1,1]\n",
        "    Ozzyz = P[2,1]*P[2,2] - 0.5*P[2,2]*P[1,2]\n",
        "    Ozzzz = P[2,2]*P[2,2] - 0.5*P[2,2]*P[2,2]\n",
        "\n",
        "    Txx = Oxxxx*uxx + 2*Oxxxy*uxy + 2*Oxxxz*uxz + Oxxyy*uyy + 2*Oxxyz*uyz + Oxxzz+uzz\n",
        "    Txy = Oxyxx*uxx + 2*Oxyxy*uxy + 2*Oxyxz*uxz + Oxyyy*uyy + 2*Oxyyz*uyz + Oxyzz+uzz\n",
        "    Txz = Oxzxx*uxx + 2*Oxzxy*uxy + 2*Oxzxz*uxz + Oxzyy*uyy + 2*Oxzyz*uyz + Oxzzz+uzz\n",
        "    Tyy = Oyyxx*uxx + 2*Oyyxy*uxy + 2*Oyyxz*uxz + Oyyyy*uyy + 2*Oyyyz*uyz + Oyyzz+uzz\n",
        "    Tyz = Oyzxx*uxx + 2*Oyzxy*uxy + 2*Oyzxz*uxz + Oyzyy*uyy + 2*Oyzyz*uyz + Oyzzz+uzz\n",
        "    Tzz = Ozzxx*uxx + 2*Ozzxy*uxy + 2*Ozzxz*uxz + Ozzyy*uyy + 2*Ozzyz*uyz + Ozzzz+uzz\n",
        "    \n",
        "    return Txx, Txy, Txz, Tyy, Tyz, Tzz\n",
        "\n",
        "mem()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory in use is 528 mb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EfFklo_YQ9v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ada4e6a-b49b-4c06-8929-9b3739c30607"
      },
      "source": [
        "def multiply_factors(K, n,Txx, Txy, Txz, Tyy, Tyz, Tzz):\n",
        "    '''Multiplies a tensor with the appropriate Bessel and Neumann factors for the time integration.'''\n",
        "    x = K*tau[n]\n",
        "    if not x:\n",
        "        x = 1e-2 # neumann functio is -inf for x = 0\n",
        "\n",
        "    Txx_J = np.sqrt(x)*a(x)*spl.jv(v,x)*Txx\n",
        "    Txy_J = np.sqrt(x)*a(x)*spl.jv(v,x)*Txy\n",
        "    Txz_J = np.sqrt(x)*a(x)*spl.jv(v,x)*Txz\n",
        "    Tyy_J = np.sqrt(x)*a(x)*spl.jv(v,x)*Tyy\n",
        "    Tyz_J = np.sqrt(x)*a(x)*spl.jv(v,x)*Tyz\n",
        "    Tzz_J = np.sqrt(x)*a(x)*spl.jv(v,x)*Tzz\n",
        "    Txx_N = np.sqrt(x)*a(x)*spl.yv(v,x)*Txx\n",
        "    Txy_N = np.sqrt(x)*a(x)*spl.yv(v,x)*Txy\n",
        "    Txz_N = np.sqrt(x)*a(x)*spl.yv(v,x)*Txz\n",
        "    Tyy_N = np.sqrt(x)*a(x)*spl.yv(v,x)*Tyy\n",
        "    Tyz_N = np.sqrt(x)*a(x)*spl.yv(v,x)*Tyz\n",
        "    Tzz_N = np.sqrt(x)*a(x)*spl.yv(v,x)*Tzz\n",
        "    \n",
        "    return Txx_J, Txy_J, Txz_J, Tyy_J, Tyz_J, Tzz_J, Txx_N, Txy_N, Txz_N, Tyy_N, Tyz_N, Tzz_N\n",
        "\n",
        "mem()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory in use is 528 mb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXKQVT10YskH",
        "outputId": "e03d103f-bd58-4e4e-962d-f04ebf1712e2"
      },
      "source": [
        "_,_,_,_,_,_,kx,ky,kz = FT(2) # Find kx and ky\n",
        "\n",
        "Nk = 100 # no of k points\n",
        "k_max = np.sqrt(kx[0,:,:].max()**2 + ky[:,0,:].max()**2 + kz[:,:,0].max()**2)/np.sqrt(3)\n",
        "k_full_range = np.linspace(0,k_max,Nk)\n",
        "dk = k_full_range[1] - k_full_range[0]\n",
        "\n",
        "print('kmax = ', k_max)\n",
        "\n",
        "# define spherical co-ordinates\n",
        "# kxv, kyv, kzv = np.meshgrid(k_full_range,k_full_range,k_full_range,indexing='ij')\n",
        "R = np.sqrt(kx**2 + ky**2 + kz**2)\n",
        "kxky = np.sqrt(kx**2 + ky**2)\n",
        "Theta = np.arctan2(kxky,kz)\n",
        "Phi = np.arctan2(ky,kx)\n",
        "Phi[Phi < 0] = 2*np.pi + Phi[Phi < 0]\n",
        "Phi[0,0,:] = 0\n",
        "print(Theta.shape)\n",
        "\n",
        "del kx, ky, kz\n",
        "gc.collect()\n",
        "\n",
        "mem()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kmax =  16.084954386379742\n",
            "(256, 256, 256)\n",
            "Memory in use is 3860 mb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPh8v0fuzXIu",
        "outputId": "4681d4f4-7a17-4ba5-c76d-46a0453aa993"
      },
      "source": [
        "# Define k vector i.e. direction of propagation\n",
        "K = 10\n",
        "theta = 0\n",
        "phi = 0\n",
        "\n",
        "def cal_en_den_tensor(K): # calculate gw energy density tensor for a certain k value\n",
        "    Txx_J_sim = 0\n",
        "    Txy_J_sim = 0\n",
        "    Txz_J_sim = 0\n",
        "    Tyy_J_sim = 0\n",
        "    Tyz_J_sim = 0\n",
        "    Tzz_J_sim = 0\n",
        "\n",
        "    Txx_N_sim = 0\n",
        "    Txy_N_sim = 0\n",
        "    Txz_N_sim = 0\n",
        "    Tyy_N_sim = 0\n",
        "    Tyz_N_sim = 0\n",
        "    Tzz_N_sim = 0\n",
        "    \n",
        "    print('Doing angular calculation...')\n",
        "    \n",
        "    k_vec = np.array([np.cos(theta)*np.cos(phi), np.cos(theta)*np.sin(phi), np.sin(theta)])\n",
        "\n",
        "    for n in np.linspace(0,Nt-1,Nt)[::skip_factor]:\n",
        "        t0 = time.process_time()\n",
        "        n = int(n)\n",
        "        uxx, uxy, uxz, uyy, uyz, uzz, _, _, _ = FT(n)\n",
        "        uxx, uxy, uxz, uyy, uyz, uzz = project(uxx, uxy, uxz, uyy, uyz, uzz, k_vec)\n",
        "        Txx_J, Txy_J, Txz_J, Tyy_J, Tyz_J, Tzz_J, Txx_N, Txy_N, Txz_N, Tyy_N, Tyz_N, Tzz_N = multiply_factors(K, n, uxx, uxy, uxz, uyy, uyz, uzz)\n",
        "\n",
        "        del uxx, uxy, uxz, uyy, uyz, uzz\n",
        "        gc.collect()\n",
        "\n",
        "        # simpsons 3/8th rule\n",
        "        if not n or n == np.linspace(0,Nt-1,Nt)[::skip_factor][-1]:\n",
        "          weight = K/t[n]**beta\n",
        "        elif n % 3 == 0:\n",
        "          weight = 2*K/t[n]**beta\n",
        "        else:\n",
        "          weight = 3*K/t[n]**beta\n",
        "\n",
        "        Txx_J_sim += weight * Txx_J\n",
        "        Txy_J_sim += weight * Txy_J\n",
        "        Txz_J_sim += weight * Txz_J\n",
        "        Tyy_J_sim += weight * Tyy_J\n",
        "        Tyz_J_sim += weight * Tyz_J\n",
        "        Tzz_J_sim += weight * Tzz_J\n",
        "        Txx_N_sim += weight * Txx_N\n",
        "        Txy_N_sim += weight * Txy_N\n",
        "        Txz_N_sim += weight * Txz_N\n",
        "        Tyy_N_sim += weight * Tyy_N\n",
        "        Tyz_N_sim += weight * Tyz_N\n",
        "        Tzz_N_sim += weight * Tzz_N\n",
        "\n",
        "        del Txx_J, Txy_J, Txz_J, Tyy_J, Tyz_J, Tzz_J, Txx_N, Txy_N, Txz_N, Tyy_N, Tyz_N, Tzz_N\n",
        "        gc.collect()\n",
        "\n",
        "        t1 = time.process_time()\n",
        "\n",
        "        print(f'iteration for n = {n} done in {round(t1-t0,2)} sec.')\n",
        "        mem()                                                                                                                            \n",
        "\n",
        "    h = (t[::skip_factor][1] - t[::skip_factor][0])\n",
        "    print('\\n h = ', h)\n",
        "\n",
        "    Txx_J_sim *= 3*h/8\n",
        "    Txy_J_sim *= 3*h/8\n",
        "    Txz_J_sim *= 3*h/8\n",
        "    Tyy_J_sim *= 3*h/8\n",
        "    Tyz_J_sim *= 3*h/8\n",
        "    Tzz_J_sim *= 3*h/8\n",
        "    Txx_N_sim *= 3*h/8\n",
        "    Txy_N_sim *= 3*h/8\n",
        "    Txz_N_sim *= 3*h/8\n",
        "    Tyy_N_sim *= 3*h/8\n",
        "    Tyz_N_sim *= 3*h/8\n",
        "    Tzz_N_sim *= 3*h/8\n",
        "            \n",
        "    Txx_J_sim = np.abs(Txx_J_sim)**2\n",
        "    Txy_J_sim = np.abs(Txy_J_sim)**2\n",
        "    Txz_J_sim = np.abs(Txz_J_sim)**2\n",
        "    Tyy_J_sim = np.abs(Tyy_J_sim)**2\n",
        "    Tyz_J_sim = np.abs(Tyz_J_sim)**2\n",
        "    Tzz_J_sim = np.abs(Tzz_J_sim)**2\n",
        "    Txx_N_sim = np.abs(Txx_N_sim)**2\n",
        "    Txy_N_sim = np.abs(Txy_N_sim)**2\n",
        "    Txz_N_sim = np.abs(Txz_N_sim)**2\n",
        "    Tyy_N_sim = np.abs(Tyy_N_sim)**2\n",
        "    Tyz_N_sim = np.abs(Tyz_N_sim)**2\n",
        "    Tzz_N_sim = np.abs(Tzz_N_sim)**2\n",
        "\n",
        "    T2 = Txx_J_sim + Txx_N_sim + Tyy_J_sim + Tyy_N_sim + Tzz_J_sim + Tzz_N_sim + 2*( Txy_J_sim + Txy_N_sim + Txz_J_sim + Txz_N_sim + Tyz_J_sim + Tyz_N_sim)\n",
        "\n",
        "    del Txx_J_sim, Txy_J_sim, Txz_J_sim, Tyy_J_sim, Tyz_J_sim, Tzz_J_sim, Txx_N_sim, Txy_N_sim, Txz_N_sim, Tyy_N_sim, Tyz_N_sim, Tzz_N_sim\n",
        "    gc.collect()\n",
        "        \n",
        "    T2 = T2*np.sin(Theta) # for angular integration\n",
        "\n",
        "    print(f'k = {K}, theta = {theta}, phi = {phi}, time steps = {reduced_steps}')\n",
        "    mem()\n",
        "    return T2\n",
        "\n",
        "T2 = cal_en_den_tensor(K)\n",
        "\n",
        "spec = []\n",
        "kmaxx = k_max # change kmaxx and Nkk for checking custom k range\n",
        "Nkk = 1000\n",
        "k_range = np.linspace(0,kmaxx,Nkk)\n",
        "# k_range = np.logspace(-2,1,Nkk)\n",
        "tol = (k_range[1:]-k_range[:-1]) * 10\n",
        "\n",
        "# angular integration using monte-carlo method\n",
        "for i, r in enumerate(k_range[:-1]):\n",
        "  Tr = T2[abs(R-r)<=tol[i]] # 1D array\n",
        "  if not Tr.shape[0]:\n",
        "    spec.append(spec[-1])\n",
        "  else:\n",
        "    spec.append(4*np.pi/Tr.shape[0] * Tr.sum())\n",
        "  print(f'r = {round(r,3)} step done with {Tr.shape[0]} lattice points. Tolerance = {round(tol[i],3)}')\n",
        "\n",
        "G = sc.constants.G\n",
        "nn = int(np.linspace(0,Nt-1,Nt)[::skip_factor][-1])\n",
        "multiplier = 2*G**2*k_range[:-1]/(3*Lx*Ly*Lz*a(nn)**4*H(nn)**2)\n",
        "spec *= multiplier\n",
        "\n",
        "const_norm = 8*np.pi*G**2*eta**4/(3*beta**2)\n",
        "spec_normalised = spec/const_norm"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Doing angular calculation...\n",
            "iteration for n = 0 done in 10.56 sec.\n",
            "Memory in use is 7961 mb\n",
            "iteration for n = 1 done in 10.56 sec.\n",
            "Memory in use is 9625 mb\n",
            "iteration for n = 2 done in 9.86 sec.\n",
            "Memory in use is 9625 mb\n",
            "iteration for n = 3 done in 9.93 sec.\n",
            "Memory in use is 9625 mb\n",
            "iteration for n = 4 done in 9.81 sec.\n",
            "Memory in use is 9625 mb\n",
            "iteration for n = 5 done in 9.87 sec.\n",
            "Memory in use is 9625 mb\n",
            "iteration for n = 6 done in 9.71 sec.\n",
            "Memory in use is 9625 mb\n",
            "iteration for n = 7 done in 9.82 sec.\n",
            "Memory in use is 9625 mb\n",
            "iteration for n = 8 done in 9.87 sec.\n",
            "Memory in use is 9626 mb\n",
            "iteration for n = 9 done in 10.03 sec.\n",
            "Memory in use is 9499 mb\n",
            "iteration for n = 10 done in 11.48 sec.\n",
            "Memory in use is 9309 mb\n",
            "iteration for n = 11 done in 12.02 sec.\n",
            "Memory in use is 9368 mb\n",
            "iteration for n = 12 done in 11.55 sec.\n",
            "Memory in use is 9369 mb\n",
            "iteration for n = 13 done in 11.62 sec.\n",
            "Memory in use is 9332 mb\n",
            "iteration for n = 14 done in 11.6 sec.\n",
            "Memory in use is 9370 mb\n",
            "iteration for n = 15 done in 11.66 sec.\n",
            "Memory in use is 9368 mb\n",
            "iteration for n = 16 done in 11.74 sec.\n",
            "Memory in use is 9369 mb\n",
            "iteration for n = 17 done in 11.83 sec.\n",
            "Memory in use is 9368 mb\n",
            "iteration for n = 18 done in 12.12 sec.\n",
            "Memory in use is 9266 mb\n",
            "iteration for n = 19 done in 12.47 sec.\n",
            "Memory in use is 9366 mb\n",
            "iteration for n = 20 done in 11.44 sec.\n",
            "Memory in use is 9225 mb\n",
            "iteration for n = 21 done in 12.63 sec.\n",
            "Memory in use is 9494 mb\n",
            "iteration for n = 22 done in 11.27 sec.\n",
            "Memory in use is 9622 mb\n",
            "iteration for n = 23 done in 11.15 sec.\n",
            "Memory in use is 9622 mb\n",
            "iteration for n = 24 done in 11.06 sec.\n",
            "Memory in use is 9622 mb\n",
            "iteration for n = 25 done in 11.15 sec.\n",
            "Memory in use is 9622 mb\n",
            "iteration for n = 26 done in 11.04 sec.\n",
            "Memory in use is 9622 mb\n",
            "iteration for n = 27 done in 11.22 sec.\n",
            "Memory in use is 9622 mb\n",
            "iteration for n = 28 done in 11.29 sec.\n",
            "Memory in use is 9623 mb\n",
            "iteration for n = 29 done in 11.19 sec.\n",
            "Memory in use is 9623 mb\n",
            "iteration for n = 30 done in 11.16 sec.\n",
            "Memory in use is 9623 mb\n",
            "iteration for n = 31 done in 11.26 sec.\n",
            "Memory in use is 9623 mb\n",
            "iteration for n = 32 done in 11.24 sec.\n",
            "Memory in use is 9623 mb\n",
            "iteration for n = 33 done in 11.36 sec.\n",
            "Memory in use is 9623 mb\n",
            "iteration for n = 34 done in 11.52 sec.\n",
            "Memory in use is 9623 mb\n",
            "iteration for n = 35 done in 11.53 sec.\n",
            "Memory in use is 9539 mb\n",
            "iteration for n = 36 done in 11.78 sec.\n",
            "Memory in use is 9595 mb\n",
            "iteration for n = 37 done in 11.7 sec.\n",
            "Memory in use is 9596 mb\n",
            "iteration for n = 38 done in 11.52 sec.\n",
            "Memory in use is 9511 mb\n",
            "iteration for n = 39 done in 11.79 sec.\n",
            "Memory in use is 9595 mb\n",
            "iteration for n = 40 done in 11.51 sec.\n",
            "Memory in use is 9467 mb\n",
            "iteration for n = 41 done in 13.71 sec.\n",
            "Memory in use is 9188 mb\n",
            "iteration for n = 42 done in 16.41 sec.\n",
            "Memory in use is 9311 mb\n",
            "iteration for n = 43 done in 12.65 sec.\n",
            "Memory in use is 9188 mb\n",
            "iteration for n = 44 done in 13.59 sec.\n",
            "Memory in use is 9460 mb\n",
            "iteration for n = 45 done in 11.83 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 46 done in 11.61 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 47 done in 11.61 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 48 done in 11.54 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 49 done in 11.59 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 50 done in 11.56 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 51 done in 11.81 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 52 done in 11.56 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 53 done in 11.84 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 54 done in 11.75 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 55 done in 11.95 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 56 done in 11.82 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 57 done in 11.9 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 58 done in 11.84 sec.\n",
            "Memory in use is 9567 mb\n",
            "iteration for n = 59 done in 11.98 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 60 done in 11.87 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 61 done in 12.13 sec.\n",
            "Memory in use is 9513 mb\n",
            "iteration for n = 62 done in 12.04 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 63 done in 11.98 sec.\n",
            "Memory in use is 9464 mb\n",
            "iteration for n = 64 done in 12.25 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 65 done in 11.72 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 66 done in 12.34 sec.\n",
            "Memory in use is 9549 mb\n",
            "iteration for n = 67 done in 12.69 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 68 done in 11.67 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 69 done in 11.82 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 70 done in 11.73 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 71 done in 11.69 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 72 done in 11.55 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 73 done in 11.71 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 74 done in 11.61 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 75 done in 11.7 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 76 done in 17.22 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 77 done in 11.96 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 78 done in 11.86 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 79 done in 11.89 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 80 done in 11.72 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 81 done in 11.75 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 82 done in 11.64 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 83 done in 16.33 sec.\n",
            "Memory in use is 8340 mb\n",
            "iteration for n = 84 done in 13.71 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 85 done in 11.81 sec.\n",
            "Memory in use is 9584 mb\n",
            "iteration for n = 86 done in 11.77 sec.\n",
            "Memory in use is 9503 mb\n",
            "iteration for n = 87 done in 12.41 sec.\n",
            "Memory in use is 9489 mb\n",
            "iteration for n = 88 done in 12.02 sec.\n",
            "Memory in use is 9417 mb\n",
            "iteration for n = 89 done in 12.78 sec.\n",
            "Memory in use is 9460 mb\n",
            "iteration for n = 90 done in 11.65 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 91 done in 11.62 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 92 done in 11.58 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 93 done in 11.63 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 94 done in 11.78 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 95 done in 11.62 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 96 done in 11.7 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 97 done in 11.79 sec.\n",
            "Memory in use is 9570 mb\n",
            "iteration for n = 98 done in 11.82 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 99 done in 11.98 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 100 done in 11.73 sec.\n",
            "Memory in use is 9538 mb\n",
            "iteration for n = 101 done in 11.9 sec.\n",
            "Memory in use is 9585 mb\n",
            "iteration for n = 102 done in 11.83 sec.\n",
            "Memory in use is 9461 mb\n",
            "iteration for n = 103 done in 12.44 sec.\n",
            "Memory in use is 9570 mb\n",
            "iteration for n = 104 done in 11.83 sec.\n",
            "Memory in use is 9442 mb\n",
            "iteration for n = 105 done in 12.42 sec.\n",
            "Memory in use is 9533 mb\n",
            "iteration for n = 106 done in 11.66 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 107 done in 11.73 sec.\n",
            "Memory in use is 9575 mb\n",
            "iteration for n = 108 done in 11.79 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 109 done in 11.92 sec.\n",
            "Memory in use is 9544 mb\n",
            "iteration for n = 110 done in 12.73 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 111 done in 12.08 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 112 done in 11.8 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 113 done in 11.93 sec.\n",
            "Memory in use is 9716 mb\n",
            "iteration for n = 114 done in 11.83 sec.\n",
            "Memory in use is 9716 mb\n",
            "iteration for n = 115 done in 11.78 sec.\n",
            "Memory in use is 9716 mb\n",
            "iteration for n = 116 done in 11.84 sec.\n",
            "Memory in use is 9716 mb\n",
            "iteration for n = 117 done in 11.78 sec.\n",
            "Memory in use is 9716 mb\n",
            "iteration for n = 118 done in 12.03 sec.\n",
            "Memory in use is 9661 mb\n",
            "iteration for n = 119 done in 12.19 sec.\n",
            "Memory in use is 9716 mb\n",
            "iteration for n = 120 done in 12.13 sec.\n",
            "Memory in use is 9693 mb\n",
            "iteration for n = 121 done in 11.77 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 122 done in 12.04 sec.\n",
            "Memory in use is 9532 mb\n",
            "iteration for n = 123 done in 12.09 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 124 done in 11.97 sec.\n",
            "Memory in use is 9559 mb\n",
            "iteration for n = 125 done in 12.03 sec.\n",
            "Memory in use is 9442 mb\n",
            "iteration for n = 126 done in 18.69 sec.\n",
            "Memory in use is 9314 mb\n",
            "iteration for n = 127 done in 13.6 sec.\n",
            "Memory in use is 9356 mb\n",
            "iteration for n = 128 done in 11.92 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 129 done in 11.76 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 130 done in 11.82 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 131 done in 11.73 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 132 done in 11.76 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 133 done in 11.85 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 134 done in 11.81 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 135 done in 11.8 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 136 done in 11.91 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 137 done in 11.94 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 138 done in 11.92 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 139 done in 11.88 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 140 done in 11.88 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 141 done in 12.04 sec.\n",
            "Memory in use is 9492 mb\n",
            "iteration for n = 142 done in 12.12 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 143 done in 13.57 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 144 done in 12.21 sec.\n",
            "Memory in use is 9569 mb\n",
            "iteration for n = 145 done in 11.95 sec.\n",
            "Memory in use is 9492 mb\n",
            "iteration for n = 146 done in 12.02 sec.\n",
            "Memory in use is 9422 mb\n",
            "iteration for n = 147 done in 12.38 sec.\n",
            "Memory in use is 9425 mb\n",
            "iteration for n = 148 done in 12.54 sec.\n",
            "Memory in use is 9313 mb\n",
            "iteration for n = 149 done in 12.61 sec.\n",
            "Memory in use is 9185 mb\n",
            "iteration for n = 150 done in 13.07 sec.\n",
            "Memory in use is 9459 mb\n",
            "iteration for n = 151 done in 11.76 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 152 done in 11.97 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 153 done in 11.68 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 154 done in 11.79 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 155 done in 11.73 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 156 done in 11.99 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 157 done in 11.77 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 158 done in 11.85 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 159 done in 12.7 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 160 done in 11.98 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 161 done in 11.97 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 162 done in 12.01 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 163 done in 12.01 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 164 done in 12.02 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 165 done in 11.81 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 166 done in 11.99 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 167 done in 11.9 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 168 done in 16.26 sec.\n",
            "Memory in use is 9459 mb\n",
            "iteration for n = 169 done in 12.38 sec.\n",
            "Memory in use is 9565 mb\n",
            "iteration for n = 170 done in 12.74 sec.\n",
            "Memory in use is 9459 mb\n",
            "iteration for n = 171 done in 12.98 sec.\n",
            "Memory in use is 9562 mb\n",
            "iteration for n = 172 done in 11.92 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 173 done in 11.76 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 174 done in 11.92 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 175 done in 11.76 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 176 done in 11.94 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 177 done in 11.89 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 178 done in 11.76 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 179 done in 11.73 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 180 done in 11.88 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 181 done in 11.96 sec.\n",
            "Memory in use is 9499 mb\n",
            "iteration for n = 182 done in 11.99 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 183 done in 11.95 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 184 done in 12.08 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 185 done in 12.14 sec.\n",
            "Memory in use is 9527 mb\n",
            "iteration for n = 186 done in 12.07 sec.\n",
            "Memory in use is 9480 mb\n",
            "iteration for n = 187 done in 12.07 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 188 done in 12.07 sec.\n",
            "Memory in use is 9527 mb\n",
            "iteration for n = 189 done in 12.29 sec.\n",
            "Memory in use is 9584 mb\n",
            "iteration for n = 190 done in 12.56 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 191 done in 11.87 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 192 done in 11.88 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 193 done in 11.76 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 194 done in 12.1 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 195 done in 11.8 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 196 done in 11.9 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 197 done in 11.8 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 198 done in 11.79 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 199 done in 11.7 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 200 done in 11.81 sec.\n",
            "Memory in use is 9544 mb\n",
            "iteration for n = 201 done in 11.99 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 202 done in 12.18 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 203 done in 11.95 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 204 done in 12.03 sec.\n",
            "Memory in use is 9580 mb\n",
            "iteration for n = 205 done in 11.94 sec.\n",
            "Memory in use is 9563 mb\n",
            "iteration for n = 206 done in 12.17 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 207 done in 11.92 sec.\n",
            "Memory in use is 9512 mb\n",
            "iteration for n = 208 done in 12.17 sec.\n",
            "Memory in use is 9566 mb\n",
            "iteration for n = 209 done in 12.6 sec.\n",
            "Memory in use is 9438 mb\n",
            "iteration for n = 210 done in 18.52 sec.\n",
            "Memory in use is 9460 mb\n",
            "iteration for n = 211 done in 11.93 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 212 done in 11.82 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 213 done in 12.05 sec.\n",
            "Memory in use is 9500 mb\n",
            "iteration for n = 214 done in 12.54 sec.\n",
            "Memory in use is 9439 mb\n",
            "iteration for n = 215 done in 12.61 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 216 done in 11.89 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 217 done in 11.95 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 218 done in 12.0 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 219 done in 11.85 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 220 done in 11.87 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 221 done in 11.89 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 222 done in 11.95 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 223 done in 12.05 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 224 done in 12.13 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 225 done in 12.1 sec.\n",
            "Memory in use is 9578 mb\n",
            "iteration for n = 226 done in 12.26 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 227 done in 12.13 sec.\n",
            "Memory in use is 9516 mb\n",
            "iteration for n = 228 done in 12.06 sec.\n",
            "Memory in use is 9426 mb\n",
            "iteration for n = 229 done in 12.5 sec.\n",
            "Memory in use is 9540 mb\n",
            "iteration for n = 230 done in 12.16 sec.\n",
            "Memory in use is 9388 mb\n",
            "iteration for n = 231 done in 12.74 sec.\n",
            "Memory in use is 9310 mb\n",
            "iteration for n = 232 done in 13.03 sec.\n",
            "Memory in use is 9289 mb\n",
            "iteration for n = 233 done in 12.63 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 234 done in 11.96 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 235 done in 12.23 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 236 done in 12.16 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 237 done in 12.06 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 238 done in 12.02 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 239 done in 11.88 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 240 done in 11.85 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 241 done in 11.95 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 242 done in 11.95 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 243 done in 12.21 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 244 done in 12.06 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 245 done in 12.03 sec.\n",
            "Memory in use is 9554 mb\n",
            "iteration for n = 246 done in 12.07 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 247 done in 11.96 sec.\n",
            "Memory in use is 9549 mb\n",
            "iteration for n = 248 done in 11.98 sec.\n",
            "Memory in use is 9572 mb\n",
            "iteration for n = 249 done in 11.96 sec.\n",
            "Memory in use is 9554 mb\n",
            "iteration for n = 250 done in 12.21 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 251 done in 12.46 sec.\n",
            "Memory in use is 9281 mb\n",
            "iteration for n = 252 done in 18.43 sec.\n",
            "Memory in use is 9441 mb\n",
            "iteration for n = 253 done in 14.28 sec.\n",
            "Memory in use is 9314 mb\n",
            "iteration for n = 254 done in 13.44 sec.\n",
            "Memory in use is 9151 mb\n",
            "iteration for n = 255 done in 13.13 sec.\n",
            "Memory in use is 9300 mb\n",
            "iteration for n = 256 done in 13.09 sec.\n",
            "Memory in use is 9185 mb\n",
            "iteration for n = 257 done in 13.36 sec.\n",
            "Memory in use is 9421 mb\n",
            "iteration for n = 258 done in 14.44 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 259 done in 12.03 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 260 done in 12.02 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 261 done in 12.01 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 262 done in 12.06 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 263 done in 12.02 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 264 done in 12.05 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 265 done in 11.98 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 266 done in 12.2 sec.\n",
            "Memory in use is 9568 mb\n",
            "iteration for n = 267 done in 12.23 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 268 done in 12.13 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 269 done in 12.16 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 270 done in 12.16 sec.\n",
            "Memory in use is 9499 mb\n",
            "iteration for n = 271 done in 12.16 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 272 done in 12.23 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 273 done in 12.04 sec.\n",
            "Memory in use is 9448 mb\n",
            "iteration for n = 274 done in 12.76 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 275 done in 11.98 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 276 done in 11.91 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 277 done in 11.92 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 278 done in 12.08 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 279 done in 11.95 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 280 done in 11.96 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 281 done in 12.01 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 282 done in 12.2 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 283 done in 12.2 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 284 done in 12.23 sec.\n",
            "Memory in use is 9574 mb\n",
            "iteration for n = 285 done in 12.24 sec.\n",
            "Memory in use is 9574 mb\n",
            "iteration for n = 286 done in 12.4 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 287 done in 12.19 sec.\n",
            "Memory in use is 9549 mb\n",
            "iteration for n = 288 done in 12.27 sec.\n",
            "Memory in use is 9441 mb\n",
            "iteration for n = 289 done in 12.57 sec.\n",
            "Memory in use is 9550 mb\n",
            "iteration for n = 290 done in 11.97 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 291 done in 12.07 sec.\n",
            "Memory in use is 9567 mb\n",
            "iteration for n = 292 done in 13.58 sec.\n",
            "Memory in use is 9203 mb\n",
            "iteration for n = 293 done in 14.98 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 294 done in 12.22 sec.\n",
            "Memory in use is 9555 mb\n",
            "iteration for n = 295 done in 12.56 sec.\n",
            "Memory in use is 9441 mb\n",
            "iteration for n = 296 done in 12.48 sec.\n",
            "Memory in use is 9460 mb\n",
            "iteration for n = 297 done in 11.89 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 298 done in 11.89 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 299 done in 11.87 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 300 done in 12.0 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 301 done in 11.84 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 302 done in 11.95 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 303 done in 11.97 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 304 done in 12.04 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 305 done in 11.99 sec.\n",
            "Memory in use is 9562 mb\n",
            "iteration for n = 306 done in 12.1 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 307 done in 12.1 sec.\n",
            "Memory in use is 9553 mb\n",
            "iteration for n = 308 done in 12.26 sec.\n",
            "Memory in use is 9537 mb\n",
            "iteration for n = 309 done in 12.1 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 310 done in 12.1 sec.\n",
            "Memory in use is 9462 mb\n",
            "iteration for n = 311 done in 12.11 sec.\n",
            "Memory in use is 9420 mb\n",
            "iteration for n = 312 done in 12.3 sec.\n",
            "Memory in use is 9413 mb\n",
            "iteration for n = 313 done in 12.25 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 314 done in 11.98 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 315 done in 12.93 sec.\n",
            "Memory in use is 9474 mb\n",
            "iteration for n = 316 done in 12.47 sec.\n",
            "Memory in use is 9429 mb\n",
            "iteration for n = 317 done in 12.22 sec.\n",
            "Memory in use is 9461 mb\n",
            "iteration for n = 318 done in 12.25 sec.\n",
            "Memory in use is 9429 mb\n",
            "iteration for n = 319 done in 12.7 sec.\n",
            "Memory in use is 9460 mb\n",
            "iteration for n = 320 done in 12.13 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 321 done in 11.95 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 322 done in 12.0 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 323 done in 11.9 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 324 done in 12.35 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 325 done in 12.03 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 326 done in 11.92 sec.\n",
            "Memory in use is 9565 mb\n",
            "iteration for n = 327 done in 12.06 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 328 done in 11.97 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 329 done in 11.91 sec.\n",
            "Memory in use is 9454 mb\n",
            "iteration for n = 330 done in 12.21 sec.\n",
            "Memory in use is 9422 mb\n",
            "iteration for n = 331 done in 12.41 sec.\n",
            "Memory in use is 9547 mb\n",
            "iteration for n = 332 done in 12.19 sec.\n",
            "Memory in use is 9410 mb\n",
            "iteration for n = 333 done in 12.46 sec.\n",
            "Memory in use is 9432 mb\n",
            "iteration for n = 334 done in 18.4 sec.\n",
            "Memory in use is 9335 mb\n",
            "iteration for n = 335 done in 12.33 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 336 done in 12.11 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 337 done in 11.99 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 338 done in 11.98 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 339 done in 12.09 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 340 done in 11.97 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 341 done in 11.96 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 342 done in 11.95 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 343 done in 11.95 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 344 done in 11.98 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 345 done in 12.07 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 346 done in 12.13 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 347 done in 12.1 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 348 done in 12.41 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 349 done in 12.23 sec.\n",
            "Memory in use is 9462 mb\n",
            "iteration for n = 350 done in 12.5 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 351 done in 12.21 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 352 done in 12.33 sec.\n",
            "Memory in use is 9491 mb\n",
            "iteration for n = 353 done in 12.33 sec.\n",
            "Memory in use is 9556 mb\n",
            "iteration for n = 354 done in 12.63 sec.\n",
            "Memory in use is 9442 mb\n",
            "iteration for n = 355 done in 12.82 sec.\n",
            "Memory in use is 9447 mb\n",
            "iteration for n = 356 done in 12.07 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 357 done in 11.94 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 358 done in 11.88 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 359 done in 11.75 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 360 done in 12.0 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 361 done in 11.72 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 362 done in 11.95 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 363 done in 11.66 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 364 done in 11.85 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 365 done in 11.78 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 366 done in 12.3 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 367 done in 11.84 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 368 done in 12.06 sec.\n",
            "Memory in use is 9496 mb\n",
            "iteration for n = 369 done in 11.82 sec.\n",
            "Memory in use is 9532 mb\n",
            "iteration for n = 370 done in 12.21 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 371 done in 11.97 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 372 done in 12.28 sec.\n",
            "Memory in use is 9510 mb\n",
            "iteration for n = 373 done in 12.22 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 374 done in 12.18 sec.\n",
            "Memory in use is 9466 mb\n",
            "iteration for n = 375 done in 12.11 sec.\n",
            "Memory in use is 9364 mb\n",
            "iteration for n = 376 done in 18.02 sec.\n",
            "Memory in use is 9313 mb\n",
            "iteration for n = 377 done in 13.91 sec.\n",
            "Memory in use is 9314 mb\n",
            "iteration for n = 378 done in 13.91 sec.\n",
            "Memory in use is 9170 mb\n",
            "iteration for n = 379 done in 13.85 sec.\n",
            "Memory in use is 9440 mb\n",
            "iteration for n = 380 done in 12.09 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 381 done in 12.15 sec.\n",
            "Memory in use is 9715 mb\n",
            "iteration for n = 382 done in 11.93 sec.\n",
            "Memory in use is 9715 mb\n",
            "iteration for n = 383 done in 11.95 sec.\n",
            "Memory in use is 9715 mb\n",
            "iteration for n = 384 done in 12.18 sec.\n",
            "Memory in use is 9715 mb\n",
            "iteration for n = 385 done in 12.27 sec.\n",
            "Memory in use is 9715 mb\n",
            "iteration for n = 386 done in 11.99 sec.\n",
            "Memory in use is 9715 mb\n",
            "iteration for n = 387 done in 12.02 sec.\n",
            "Memory in use is 9715 mb\n",
            "iteration for n = 388 done in 12.02 sec.\n",
            "Memory in use is 9715 mb\n",
            "iteration for n = 389 done in 14.69 sec.\n",
            "Memory in use is 9715 mb\n",
            "iteration for n = 390 done in 12.27 sec.\n",
            "Memory in use is 9715 mb\n",
            "iteration for n = 391 done in 12.27 sec.\n",
            "Memory in use is 9715 mb\n",
            "iteration for n = 392 done in 12.2 sec.\n",
            "Memory in use is 9650 mb\n",
            "iteration for n = 393 done in 12.16 sec.\n",
            "Memory in use is 9571 mb\n",
            "iteration for n = 394 done in 12.21 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 395 done in 12.13 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 396 done in 12.04 sec.\n",
            "Memory in use is 9461 mb\n",
            "iteration for n = 397 done in 12.9 sec.\n",
            "Memory in use is 9570 mb\n",
            "iteration for n = 398 done in 13.36 sec.\n",
            "Memory in use is 9587 mb\n",
            "iteration for n = 399 done in 12.25 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 400 done in 12.13 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 401 done in 12.14 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 402 done in 11.98 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 403 done in 12.04 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 404 done in 11.98 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 405 done in 12.13 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 406 done in 12.21 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 407 done in 12.06 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 408 done in 12.19 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 409 done in 12.34 sec.\n",
            "Memory in use is 9574 mb\n",
            "iteration for n = 410 done in 12.3 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 411 done in 12.36 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 412 done in 12.2 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 413 done in 12.4 sec.\n",
            "Memory in use is 9504 mb\n",
            "iteration for n = 414 done in 12.54 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 415 done in 12.55 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 416 done in 12.15 sec.\n",
            "Memory in use is 9494 mb\n",
            "iteration for n = 417 done in 17.54 sec.\n",
            "Memory in use is 9426 mb\n",
            "iteration for n = 418 done in 12.5 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 419 done in 12.39 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 420 done in 12.21 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 421 done in 12.23 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 422 done in 12.3 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 423 done in 12.31 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 424 done in 12.3 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 425 done in 12.3 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 426 done in 12.25 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 427 done in 12.39 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 428 done in 12.39 sec.\n",
            "Memory in use is 9567 mb\n",
            "iteration for n = 429 done in 12.37 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 430 done in 12.36 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 431 done in 12.25 sec.\n",
            "Memory in use is 9463 mb\n",
            "iteration for n = 432 done in 12.59 sec.\n",
            "Memory in use is 9586 mb\n",
            "iteration for n = 433 done in 12.38 sec.\n",
            "Memory in use is 9551 mb\n",
            "iteration for n = 434 done in 12.21 sec.\n",
            "Memory in use is 9455 mb\n",
            "iteration for n = 435 done in 12.96 sec.\n",
            "Memory in use is 9438 mb\n",
            "iteration for n = 436 done in 12.36 sec.\n",
            "Memory in use is 9443 mb\n",
            "iteration for n = 437 done in 12.44 sec.\n",
            "Memory in use is 9438 mb\n",
            "iteration for n = 438 done in 13.31 sec.\n",
            "Memory in use is 9310 mb\n",
            "iteration for n = 439 done in 12.8 sec.\n",
            "Memory in use is 9310 mb\n",
            "iteration for n = 440 done in 13.27 sec.\n",
            "Memory in use is 9432 mb\n",
            "iteration for n = 441 done in 12.1 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 442 done in 11.93 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 443 done in 12.09 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 444 done in 12.13 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 445 done in 12.08 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 446 done in 12.03 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 447 done in 12.08 sec.\n",
            "Memory in use is 9716 mb\n",
            "iteration for n = 448 done in 11.94 sec.\n",
            "Memory in use is 9716 mb\n",
            "iteration for n = 449 done in 12.01 sec.\n",
            "Memory in use is 9716 mb\n",
            "iteration for n = 450 done in 12.17 sec.\n",
            "Memory in use is 9716 mb\n",
            "iteration for n = 451 done in 12.11 sec.\n",
            "Memory in use is 9716 mb\n",
            "iteration for n = 452 done in 12.14 sec.\n",
            "Memory in use is 9717 mb\n",
            "iteration for n = 453 done in 12.02 sec.\n",
            "Memory in use is 9682 mb\n",
            "iteration for n = 454 done in 12.15 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 455 done in 12.17 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 456 done in 12.17 sec.\n",
            "Memory in use is 9522 mb\n",
            "iteration for n = 457 done in 12.08 sec.\n",
            "Memory in use is 9576 mb\n",
            "iteration for n = 458 done in 15.88 sec.\n",
            "Memory in use is 8536 mb\n",
            "iteration for n = 459 done in 13.55 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 460 done in 12.2 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 461 done in 12.03 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 462 done in 12.09 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 463 done in 12.09 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 464 done in 12.05 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 465 done in 12.03 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 466 done in 12.11 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 467 done in 12.01 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 468 done in 12.03 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 469 done in 12.15 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 470 done in 12.22 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 471 done in 12.19 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 472 done in 12.15 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 473 done in 12.18 sec.\n",
            "Memory in use is 9584 mb\n",
            "iteration for n = 474 done in 12.44 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 475 done in 12.25 sec.\n",
            "Memory in use is 9588 mb\n",
            "iteration for n = 476 done in 12.14 sec.\n",
            "Memory in use is 9520 mb\n",
            "iteration for n = 477 done in 12.11 sec.\n",
            "Memory in use is 9478 mb\n",
            "iteration for n = 478 done in 12.3 sec.\n",
            "Memory in use is 9418 mb\n",
            "iteration for n = 479 done in 12.86 sec.\n",
            "Memory in use is 9291 mb\n",
            "iteration for n = 480 done in 13.04 sec.\n",
            "Memory in use is 9311 mb\n",
            "iteration for n = 481 done in 12.94 sec.\n",
            "Memory in use is 9182 mb\n",
            "iteration for n = 482 done in 12.77 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 483 done in 12.04 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 484 done in 12.07 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 485 done in 12.05 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 486 done in 12.03 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 487 done in 12.1 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 488 done in 12.14 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 489 done in 12.03 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 490 done in 12.11 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 491 done in 12.14 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 492 done in 12.14 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 493 done in 12.15 sec.\n",
            "Memory in use is 9510 mb\n",
            "iteration for n = 494 done in 12.27 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 495 done in 12.14 sec.\n",
            "Memory in use is 9485 mb\n",
            "iteration for n = 496 done in 12.42 sec.\n",
            "Memory in use is 9589 mb\n",
            "iteration for n = 497 done in 12.12 sec.\n",
            "Memory in use is 9508 mb\n",
            "iteration for n = 498 done in 12.52 sec.\n",
            "Memory in use is 9581 mb\n",
            "iteration for n = 499 done in 12.3 sec.\n",
            "Memory in use is 9472 mb\n",
            "\n",
            " h =  0.1002004008016033\n",
            "k = 10, theta = 0, phi = 0, time steps = 500\n",
            "Memory in use is 9480 mb\n",
            "r = 0.0 step done with 7 lattice points. Tolerance = 0.161\n",
            "r = 0.016 step done with 7 lattice points. Tolerance = 0.161\n",
            "r = 0.032 step done with 19 lattice points. Tolerance = 0.161\n",
            "r = 0.048 step done with 19 lattice points. Tolerance = 0.161\n",
            "r = 0.064 step done with 27 lattice points. Tolerance = 0.161\n",
            "r = 0.081 step done with 27 lattice points. Tolerance = 0.161\n",
            "r = 0.097 step done with 33 lattice points. Tolerance = 0.161\n",
            "r = 0.113 step done with 33 lattice points. Tolerance = 0.161\n",
            "r = 0.129 step done with 57 lattice points. Tolerance = 0.161\n",
            "r = 0.145 step done with 57 lattice points. Tolerance = 0.161\n",
            "r = 0.161 step done with 80 lattice points. Tolerance = 0.161\n",
            "r = 0.177 step done with 80 lattice points. Tolerance = 0.161\n",
            "r = 0.193 step done with 80 lattice points. Tolerance = 0.161\n",
            "r = 0.209 step done with 92 lattice points. Tolerance = 0.161\n",
            "r = 0.225 step done with 122 lattice points. Tolerance = 0.161\n",
            "r = 0.242 step done with 146 lattice points. Tolerance = 0.161\n",
            "r = 0.258 step done with 170 lattice points. Tolerance = 0.161\n",
            "r = 0.274 step done with 170 lattice points. Tolerance = 0.161\n",
            "r = 0.29 step done with 172 lattice points. Tolerance = 0.161\n",
            "r = 0.306 step done with 196 lattice points. Tolerance = 0.161\n",
            "r = 0.322 step done with 244 lattice points. Tolerance = 0.161\n",
            "r = 0.338 step done with 244 lattice points. Tolerance = 0.161\n",
            "r = 0.354 step done with 238 lattice points. Tolerance = 0.161\n",
            "r = 0.37 step done with 286 lattice points. Tolerance = 0.161\n",
            "r = 0.386 step done with 314 lattice points. Tolerance = 0.161\n",
            "r = 0.403 step done with 362 lattice points. Tolerance = 0.161\n",
            "r = 0.419 step done with 404 lattice points. Tolerance = 0.161\n",
            "r = 0.435 step done with 428 lattice points. Tolerance = 0.161\n",
            "r = 0.451 step done with 404 lattice points. Tolerance = 0.161\n",
            "r = 0.467 step done with 428 lattice points. Tolerance = 0.161\n",
            "r = 0.483 step done with 506 lattice points. Tolerance = 0.161\n",
            "r = 0.499 step done with 538 lattice points. Tolerance = 0.161\n",
            "r = 0.515 step done with 538 lattice points. Tolerance = 0.161\n",
            "r = 0.531 step done with 646 lattice points. Tolerance = 0.161\n",
            "r = 0.547 step done with 616 lattice points. Tolerance = 0.161\n",
            "r = 0.564 step done with 652 lattice points. Tolerance = 0.161\n",
            "r = 0.58 step done with 676 lattice points. Tolerance = 0.161\n",
            "r = 0.596 step done with 754 lattice points. Tolerance = 0.161\n",
            "r = 0.612 step done with 770 lattice points. Tolerance = 0.161\n",
            "r = 0.628 step done with 818 lattice points. Tolerance = 0.161\n",
            "r = 0.644 step done with 890 lattice points. Tolerance = 0.161\n",
            "r = 0.66 step done with 938 lattice points. Tolerance = 0.161\n",
            "r = 0.676 step done with 980 lattice points. Tolerance = 0.161\n",
            "r = 0.692 step done with 1052 lattice points. Tolerance = 0.161\n",
            "r = 0.708 step done with 1016 lattice points. Tolerance = 0.161\n",
            "r = 0.725 step done with 1030 lattice points. Tolerance = 0.161\n",
            "r = 0.741 step done with 1114 lattice points. Tolerance = 0.161\n",
            "r = 0.757 step done with 1186 lattice points. Tolerance = 0.161\n",
            "r = 0.773 step done with 1282 lattice points. Tolerance = 0.161\n",
            "r = 0.789 step done with 1354 lattice points. Tolerance = 0.161\n",
            "r = 0.805 step done with 1348 lattice points. Tolerance = 0.161\n",
            "r = 0.821 step done with 1388 lattice points. Tolerance = 0.161\n",
            "r = 0.837 step done with 1484 lattice points. Tolerance = 0.161\n",
            "r = 0.853 step done with 1466 lattice points. Tolerance = 0.161\n",
            "r = 0.869 step done with 1586 lattice points. Tolerance = 0.161\n",
            "r = 0.886 step done with 1670 lattice points. Tolerance = 0.161\n",
            "r = 0.902 step done with 1670 lattice points. Tolerance = 0.161\n",
            "r = 0.918 step done with 1676 lattice points. Tolerance = 0.161\n",
            "r = 0.934 step done with 1828 lattice points. Tolerance = 0.161\n",
            "r = 0.95 step done with 1924 lattice points. Tolerance = 0.161\n",
            "r = 0.966 step done with 1828 lattice points. Tolerance = 0.161\n",
            "r = 0.982 step done with 1930 lattice points. Tolerance = 0.161\n",
            "r = 0.998 step done with 2050 lattice points. Tolerance = 0.161\n",
            "r = 1.014 step done with 2050 lattice points. Tolerance = 0.161\n",
            "r = 1.03 step done with 2218 lattice points. Tolerance = 0.161\n",
            "r = 1.047 step done with 2324 lattice points. Tolerance = 0.161\n",
            "r = 1.063 step done with 2336 lattice points. Tolerance = 0.161\n",
            "r = 1.079 step done with 2312 lattice points. Tolerance = 0.161\n",
            "r = 1.095 step done with 2396 lattice points. Tolerance = 0.161\n",
            "r = 1.111 step done with 2546 lattice points. Tolerance = 0.161\n",
            "r = 1.127 step done with 2618 lattice points. Tolerance = 0.161\n",
            "r = 1.143 step done with 2690 lattice points. Tolerance = 0.161\n",
            "r = 1.159 step done with 2842 lattice points. Tolerance = 0.161\n",
            "r = 1.175 step done with 2836 lattice points. Tolerance = 0.161\n",
            "r = 1.191 step done with 2860 lattice points. Tolerance = 0.161\n",
            "r = 1.208 step done with 2980 lattice points. Tolerance = 0.161\n",
            "r = 1.224 step done with 3058 lattice points. Tolerance = 0.161\n",
            "r = 1.24 step done with 3142 lattice points. Tolerance = 0.161\n",
            "r = 1.256 step done with 3254 lattice points. Tolerance = 0.161\n",
            "r = 1.272 step done with 3290 lattice points. Tolerance = 0.161\n",
            "r = 1.288 step done with 3434 lattice points. Tolerance = 0.161\n",
            "r = 1.304 step done with 3500 lattice points. Tolerance = 0.161\n",
            "r = 1.32 step done with 3572 lattice points. Tolerance = 0.161\n",
            "r = 1.336 step done with 3668 lattice points. Tolerance = 0.161\n",
            "r = 1.352 step done with 3674 lattice points. Tolerance = 0.161\n",
            "r = 1.369 step done with 3778 lattice points. Tolerance = 0.161\n",
            "r = 1.385 step done with 3922 lattice points. Tolerance = 0.161\n",
            "r = 1.401 step done with 4162 lattice points. Tolerance = 0.161\n",
            "r = 1.417 step done with 4150 lattice points. Tolerance = 0.161\n",
            "r = 1.433 step done with 4024 lattice points. Tolerance = 0.161\n",
            "r = 1.449 step done with 4276 lattice points. Tolerance = 0.161\n",
            "r = 1.465 step done with 4348 lattice points. Tolerance = 0.161\n",
            "r = 1.481 step done with 4370 lattice points. Tolerance = 0.161\n",
            "r = 1.497 step done with 4730 lattice points. Tolerance = 0.161\n",
            "r = 1.513 step done with 4658 lattice points. Tolerance = 0.161\n",
            "r = 1.53 step done with 4682 lattice points. Tolerance = 0.161\n",
            "r = 1.546 step done with 4868 lattice points. Tolerance = 0.161\n",
            "r = 1.562 step done with 5084 lattice points. Tolerance = 0.161\n",
            "r = 1.578 step done with 5036 lattice points. Tolerance = 0.161\n",
            "r = 1.594 step done with 5224 lattice points. Tolerance = 0.161\n",
            "r = 1.61 step done with 5350 lattice points. Tolerance = 0.161\n",
            "r = 1.626 step done with 5434 lattice points. Tolerance = 0.161\n",
            "r = 1.642 step done with 5434 lattice points. Tolerance = 0.161\n",
            "r = 1.658 step done with 5722 lattice points. Tolerance = 0.161\n",
            "r = 1.675 step done with 5884 lattice points. Tolerance = 0.161\n",
            "r = 1.691 step done with 5876 lattice points. Tolerance = 0.161\n",
            "r = 1.707 step done with 5804 lattice points. Tolerance = 0.161\n",
            "r = 1.723 step done with 5876 lattice points. Tolerance = 0.161\n",
            "r = 1.739 step done with 6122 lattice points. Tolerance = 0.161\n",
            "r = 1.755 step done with 6386 lattice points. Tolerance = 0.161\n",
            "r = 1.771 step done with 6446 lattice points. Tolerance = 0.161\n",
            "r = 1.787 step done with 6470 lattice points. Tolerance = 0.161\n",
            "r = 1.803 step done with 6652 lattice points. Tolerance = 0.161\n",
            "r = 1.819 step done with 6604 lattice points. Tolerance = 0.161\n",
            "r = 1.836 step done with 6988 lattice points. Tolerance = 0.161\n",
            "r = 1.852 step done with 6946 lattice points. Tolerance = 0.161\n",
            "r = 1.868 step done with 7114 lattice points. Tolerance = 0.161\n",
            "r = 1.884 step done with 7114 lattice points. Tolerance = 0.161\n",
            "r = 1.9 step done with 7282 lattice points. Tolerance = 0.161\n",
            "r = 1.916 step done with 7490 lattice points. Tolerance = 0.161\n",
            "r = 1.932 step done with 7628 lattice points. Tolerance = 0.161\n",
            "r = 1.948 step done with 7784 lattice points. Tolerance = 0.161\n",
            "r = 1.964 step done with 8048 lattice points. Tolerance = 0.161\n",
            "r = 1.98 step done with 7922 lattice points. Tolerance = 0.161\n",
            "r = 1.997 step done with 8114 lattice points. Tolerance = 0.161\n",
            "r = 2.013 step done with 8426 lattice points. Tolerance = 0.161\n",
            "r = 2.029 step done with 8506 lattice points. Tolerance = 0.161\n",
            "r = 2.045 step done with 8746 lattice points. Tolerance = 0.161\n",
            "r = 2.061 step done with 8620 lattice points. Tolerance = 0.161\n",
            "r = 2.077 step done with 8908 lattice points. Tolerance = 0.161\n",
            "r = 2.093 step done with 8836 lattice points. Tolerance = 0.161\n",
            "r = 2.109 step done with 9322 lattice points. Tolerance = 0.161\n",
            "r = 2.125 step done with 9374 lattice points. Tolerance = 0.161\n",
            "r = 2.141 step done with 9302 lattice points. Tolerance = 0.161\n",
            "r = 2.158 step done with 9362 lattice points. Tolerance = 0.161\n",
            "r = 2.174 step done with 9884 lattice points. Tolerance = 0.161\n",
            "r = 2.19 step done with 9812 lattice points. Tolerance = 0.161\n",
            "r = 2.206 step done with 10076 lattice points. Tolerance = 0.161\n",
            "r = 2.222 step done with 10076 lattice points. Tolerance = 0.161\n",
            "r = 2.238 step done with 10090 lattice points. Tolerance = 0.161\n",
            "r = 2.254 step done with 10330 lattice points. Tolerance = 0.161\n",
            "r = 2.27 step done with 10714 lattice points. Tolerance = 0.161\n",
            "r = 2.286 step done with 10762 lattice points. Tolerance = 0.161\n",
            "r = 2.302 step done with 10744 lattice points. Tolerance = 0.161\n",
            "r = 2.319 step done with 10984 lattice points. Tolerance = 0.161\n",
            "r = 2.335 step done with 10972 lattice points. Tolerance = 0.161\n",
            "r = 2.351 step done with 11252 lattice points. Tolerance = 0.161\n",
            "r = 2.367 step done with 11306 lattice points. Tolerance = 0.161\n",
            "r = 2.383 step done with 11666 lattice points. Tolerance = 0.161\n",
            "r = 2.399 step done with 11810 lattice points. Tolerance = 0.161\n",
            "r = 2.415 step done with 12026 lattice points. Tolerance = 0.161\n",
            "r = 2.431 step done with 11948 lattice points. Tolerance = 0.161\n",
            "r = 2.447 step done with 12188 lattice points. Tolerance = 0.161\n",
            "r = 2.463 step done with 12484 lattice points. Tolerance = 0.161\n",
            "r = 2.48 step done with 12718 lattice points. Tolerance = 0.161\n",
            "r = 2.496 step done with 12646 lattice points. Tolerance = 0.161\n",
            "r = 2.512 step done with 12970 lattice points. Tolerance = 0.161\n",
            "r = 2.528 step done with 12826 lattice points. Tolerance = 0.161\n",
            "r = 2.544 step done with 13426 lattice points. Tolerance = 0.161\n",
            "r = 2.56 step done with 13460 lattice points. Tolerance = 0.161\n",
            "r = 2.576 step done with 13676 lattice points. Tolerance = 0.161\n",
            "r = 2.592 step done with 13316 lattice points. Tolerance = 0.161\n",
            "r = 2.608 step done with 13610 lattice points. Tolerance = 0.161\n",
            "r = 2.624 step done with 14306 lattice points. Tolerance = 0.161\n",
            "r = 2.641 step done with 14354 lattice points. Tolerance = 0.161\n",
            "r = 2.657 step done with 14462 lattice points. Tolerance = 0.161\n",
            "r = 2.673 step done with 14566 lattice points. Tolerance = 0.161\n",
            "r = 2.689 step done with 14836 lattice points. Tolerance = 0.161\n",
            "r = 2.705 step done with 14860 lattice points. Tolerance = 0.161\n",
            "r = 2.721 step done with 15172 lattice points. Tolerance = 0.161\n",
            "r = 2.737 step done with 15298 lattice points. Tolerance = 0.161\n",
            "r = 2.753 step done with 15394 lattice points. Tolerance = 0.161\n",
            "r = 2.769 step done with 15394 lattice points. Tolerance = 0.161\n",
            "r = 2.785 step done with 16010 lattice points. Tolerance = 0.161\n",
            "r = 2.802 step done with 15980 lattice points. Tolerance = 0.161\n",
            "r = 2.818 step done with 16100 lattice points. Tolerance = 0.161\n",
            "r = 2.834 step done with 16280 lattice points. Tolerance = 0.161\n",
            "r = 2.85 step done with 16904 lattice points. Tolerance = 0.161\n",
            "r = 2.866 step done with 16514 lattice points. Tolerance = 0.161\n",
            "r = 2.882 step done with 17090 lattice points. Tolerance = 0.161\n",
            "r = 2.898 step done with 16882 lattice points. Tolerance = 0.161\n",
            "r = 2.914 step done with 17578 lattice points. Tolerance = 0.161\n",
            "r = 2.93 step done with 17812 lattice points. Tolerance = 0.161\n",
            "r = 2.946 step done with 17548 lattice points. Tolerance = 0.161\n",
            "r = 2.963 step done with 17644 lattice points. Tolerance = 0.161\n",
            "r = 2.979 step done with 17860 lattice points. Tolerance = 0.161\n",
            "r = 2.995 step done with 18602 lattice points. Tolerance = 0.161\n",
            "r = 3.011 step done with 18566 lattice points. Tolerance = 0.161\n",
            "r = 3.027 step done with 18758 lattice points. Tolerance = 0.161\n",
            "r = 3.043 step done with 18914 lattice points. Tolerance = 0.161\n",
            "r = 3.059 step done with 18980 lattice points. Tolerance = 0.161\n",
            "r = 3.075 step done with 19412 lattice points. Tolerance = 0.161\n",
            "r = 3.091 step done with 19676 lattice points. Tolerance = 0.161\n",
            "r = 3.108 step done with 19354 lattice points. Tolerance = 0.161\n",
            "r = 3.124 step done with 19882 lattice points. Tolerance = 0.161\n",
            "r = 3.14 step done with 20218 lattice points. Tolerance = 0.161\n",
            "r = 3.156 step done with 20338 lattice points. Tolerance = 0.161\n",
            "r = 3.172 step done with 20458 lattice points. Tolerance = 0.161\n",
            "r = 3.188 step done with 21136 lattice points. Tolerance = 0.161\n",
            "r = 3.204 step done with 20992 lattice points. Tolerance = 0.161\n",
            "r = 3.22 step done with 21044 lattice points. Tolerance = 0.161\n",
            "r = 3.236 step done with 21218 lattice points. Tolerance = 0.161\n",
            "r = 3.252 step done with 21362 lattice points. Tolerance = 0.161\n",
            "r = 3.269 step done with 21650 lattice points. Tolerance = 0.161\n",
            "r = 3.285 step done with 22178 lattice points. Tolerance = 0.161\n",
            "r = 3.301 step done with 22538 lattice points. Tolerance = 0.161\n",
            "r = 3.317 step done with 22124 lattice points. Tolerance = 0.161\n",
            "r = 3.333 step done with 22636 lattice points. Tolerance = 0.161\n",
            "r = 3.349 step done with 23068 lattice points. Tolerance = 0.161\n",
            "r = 3.365 step done with 22870 lattice points. Tolerance = 0.161\n",
            "r = 3.381 step done with 23470 lattice points. Tolerance = 0.161\n",
            "r = 3.397 step done with 23458 lattice points. Tolerance = 0.161\n",
            "r = 3.413 step done with 23962 lattice points. Tolerance = 0.161\n",
            "r = 3.43 step done with 24044 lattice points. Tolerance = 0.161\n",
            "r = 3.446 step done with 24212 lattice points. Tolerance = 0.161\n",
            "r = 3.462 step done with 24452 lattice points. Tolerance = 0.161\n",
            "r = 3.478 step done with 24716 lattice points. Tolerance = 0.161\n",
            "r = 3.494 step done with 24626 lattice points. Tolerance = 0.161\n",
            "r = 3.51 step done with 24914 lattice points. Tolerance = 0.161\n",
            "r = 3.526 step done with 25178 lattice points. Tolerance = 0.161\n",
            "r = 3.542 step done with 25894 lattice points. Tolerance = 0.161\n",
            "r = 3.558 step done with 26104 lattice points. Tolerance = 0.161\n",
            "r = 3.574 step done with 26116 lattice points. Tolerance = 0.161\n",
            "r = 3.591 step done with 26572 lattice points. Tolerance = 0.161\n",
            "r = 3.607 step done with 26188 lattice points. Tolerance = 0.161\n",
            "r = 3.623 step done with 26770 lattice points. Tolerance = 0.161\n",
            "r = 3.639 step done with 27274 lattice points. Tolerance = 0.161\n",
            "r = 3.655 step done with 27290 lattice points. Tolerance = 0.161\n",
            "r = 3.671 step done with 27338 lattice points. Tolerance = 0.161\n",
            "r = 3.687 step done with 27812 lattice points. Tolerance = 0.161\n",
            "r = 3.703 step done with 27980 lattice points. Tolerance = 0.161\n",
            "r = 3.719 step done with 28400 lattice points. Tolerance = 0.161\n",
            "r = 3.735 step done with 27926 lattice points. Tolerance = 0.161\n",
            "r = 3.752 step done with 28850 lattice points. Tolerance = 0.161\n",
            "r = 3.768 step done with 28930 lattice points. Tolerance = 0.161\n",
            "r = 3.784 step done with 29098 lattice points. Tolerance = 0.161\n",
            "r = 3.8 step done with 29626 lattice points. Tolerance = 0.161\n",
            "r = 3.816 step done with 30100 lattice points. Tolerance = 0.161\n",
            "r = 3.832 step done with 29644 lattice points. Tolerance = 0.161\n",
            "r = 3.848 step done with 30124 lattice points. Tolerance = 0.161\n",
            "r = 3.864 step done with 30722 lattice points. Tolerance = 0.161\n",
            "r = 3.88 step done with 30746 lattice points. Tolerance = 0.161\n",
            "r = 3.896 step done with 30902 lattice points. Tolerance = 0.161\n",
            "r = 3.913 step done with 31406 lattice points. Tolerance = 0.161\n",
            "r = 3.929 step done with 31802 lattice points. Tolerance = 0.161\n",
            "r = 3.945 step done with 31700 lattice points. Tolerance = 0.161\n",
            "r = 3.961 step done with 31892 lattice points. Tolerance = 0.161\n",
            "r = 3.977 step done with 32020 lattice points. Tolerance = 0.161\n",
            "r = 3.993 step done with 32482 lattice points. Tolerance = 0.161\n",
            "r = 4.009 step done with 32890 lattice points. Tolerance = 0.161\n",
            "r = 4.025 step done with 33274 lattice points. Tolerance = 0.161\n",
            "r = 4.041 step done with 33346 lattice points. Tolerance = 0.161\n",
            "r = 4.057 step done with 34132 lattice points. Tolerance = 0.161\n",
            "r = 4.074 step done with 34048 lattice points. Tolerance = 0.161\n",
            "r = 4.09 step done with 34160 lattice points. Tolerance = 0.161\n",
            "r = 4.106 step done with 33884 lattice points. Tolerance = 0.161\n",
            "r = 4.122 step done with 34658 lattice points. Tolerance = 0.161\n",
            "r = 4.138 step done with 34970 lattice points. Tolerance = 0.161\n",
            "r = 4.154 step done with 35738 lattice points. Tolerance = 0.161\n",
            "r = 4.17 step done with 35522 lattice points. Tolerance = 0.161\n",
            "r = 4.186 step done with 35612 lattice points. Tolerance = 0.161\n",
            "r = 4.202 step done with 35668 lattice points. Tolerance = 0.161\n",
            "r = 4.218 step done with 36604 lattice points. Tolerance = 0.161\n",
            "r = 4.235 step done with 36124 lattice points. Tolerance = 0.161\n",
            "r = 4.251 step done with 36694 lattice points. Tolerance = 0.161\n",
            "r = 4.267 step done with 37126 lattice points. Tolerance = 0.161\n",
            "r = 4.283 step done with 37354 lattice points. Tolerance = 0.161\n",
            "r = 4.299 step done with 37970 lattice points. Tolerance = 0.161\n",
            "r = 4.315 step done with 38108 lattice points. Tolerance = 0.161\n",
            "r = 4.331 step done with 38300 lattice points. Tolerance = 0.161\n",
            "r = 4.347 step done with 38372 lattice points. Tolerance = 0.161\n",
            "r = 4.363 step done with 38474 lattice points. Tolerance = 0.161\n",
            "r = 4.379 step done with 39074 lattice points. Tolerance = 0.161\n",
            "r = 4.396 step done with 39338 lattice points. Tolerance = 0.161\n",
            "r = 4.412 step done with 39706 lattice points. Tolerance = 0.161\n",
            "r = 4.428 step done with 40846 lattice points. Tolerance = 0.161\n",
            "r = 4.444 step done with 40240 lattice points. Tolerance = 0.161\n",
            "r = 4.46 step done with 40444 lattice points. Tolerance = 0.161\n",
            "r = 4.476 step done with 40684 lattice points. Tolerance = 0.161\n",
            "r = 4.492 step done with 41506 lattice points. Tolerance = 0.161\n",
            "r = 4.508 step done with 41194 lattice points. Tolerance = 0.161\n",
            "r = 4.524 step done with 42290 lattice points. Tolerance = 0.161\n",
            "r = 4.54 step done with 41714 lattice points. Tolerance = 0.161\n",
            "r = 4.557 step done with 42506 lattice points. Tolerance = 0.161\n",
            "r = 4.573 step done with 42932 lattice points. Tolerance = 0.161\n",
            "r = 4.589 step done with 43124 lattice points. Tolerance = 0.161\n",
            "r = 4.605 step done with 43304 lattice points. Tolerance = 0.161\n",
            "r = 4.621 step done with 43238 lattice points. Tolerance = 0.161\n",
            "r = 4.637 step done with 43678 lattice points. Tolerance = 0.161\n",
            "r = 4.653 step done with 44026 lattice points. Tolerance = 0.161\n",
            "r = 4.669 step done with 44458 lattice points. Tolerance = 0.161\n",
            "r = 4.685 step done with 45100 lattice points. Tolerance = 0.161\n",
            "r = 4.702 step done with 45244 lattice points. Tolerance = 0.161\n",
            "r = 4.718 step done with 45172 lattice points. Tolerance = 0.161\n",
            "r = 4.734 step done with 45980 lattice points. Tolerance = 0.161\n",
            "r = 4.75 step done with 45818 lattice points. Tolerance = 0.161\n",
            "r = 4.766 step done with 45986 lattice points. Tolerance = 0.161\n",
            "r = 4.782 step done with 46766 lattice points. Tolerance = 0.161\n",
            "r = 4.798 step done with 47318 lattice points. Tolerance = 0.161\n",
            "r = 4.814 step done with 47000 lattice points. Tolerance = 0.161\n",
            "r = 4.83 step done with 47780 lattice points. Tolerance = 0.161\n",
            "r = 4.846 step done with 47404 lattice points. Tolerance = 0.161\n",
            "r = 4.863 step done with 48508 lattice points. Tolerance = 0.161\n",
            "r = 4.879 step done with 48442 lattice points. Tolerance = 0.161\n",
            "r = 4.895 step done with 48610 lattice points. Tolerance = 0.161\n",
            "r = 4.911 step done with 48586 lattice points. Tolerance = 0.161\n",
            "r = 4.927 step done with 49690 lattice points. Tolerance = 0.161\n",
            "r = 4.943 step done with 50140 lattice points. Tolerance = 0.161\n",
            "r = 4.959 step done with 50252 lattice points. Tolerance = 0.161\n",
            "r = 4.975 step done with 50648 lattice points. Tolerance = 0.161\n",
            "r = 4.991 step done with 50390 lattice points. Tolerance = 0.161\n",
            "r = 5.007 step done with 51170 lattice points. Tolerance = 0.161\n",
            "r = 5.024 step done with 51554 lattice points. Tolerance = 0.161\n",
            "r = 5.04 step done with 51794 lattice points. Tolerance = 0.161\n",
            "r = 5.056 step done with 52178 lattice points. Tolerance = 0.161\n",
            "r = 5.072 step done with 52636 lattice points. Tolerance = 0.161\n",
            "r = 5.088 step done with 52684 lattice points. Tolerance = 0.161\n",
            "r = 5.104 step done with 53260 lattice points. Tolerance = 0.161\n",
            "r = 5.12 step done with 53218 lattice points. Tolerance = 0.161\n",
            "r = 5.136 step done with 53362 lattice points. Tolerance = 0.161\n",
            "r = 5.152 step done with 54262 lattice points. Tolerance = 0.161\n",
            "r = 5.168 step done with 54614 lattice points. Tolerance = 0.161\n",
            "r = 5.185 step done with 54722 lattice points. Tolerance = 0.161\n",
            "r = 5.201 step done with 55388 lattice points. Tolerance = 0.161\n",
            "r = 5.217 step done with 55652 lattice points. Tolerance = 0.161\n",
            "r = 5.233 step done with 56132 lattice points. Tolerance = 0.161\n",
            "r = 5.249 step done with 55970 lattice points. Tolerance = 0.161\n",
            "r = 5.265 step done with 56282 lattice points. Tolerance = 0.161\n",
            "r = 5.281 step done with 56938 lattice points. Tolerance = 0.161\n",
            "r = 5.297 step done with 57394 lattice points. Tolerance = 0.161\n",
            "r = 5.313 step done with 57916 lattice points. Tolerance = 0.161\n",
            "r = 5.329 step done with 57544 lattice points. Tolerance = 0.161\n",
            "r = 5.346 step done with 57472 lattice points. Tolerance = 0.161\n",
            "r = 5.362 step done with 58852 lattice points. Tolerance = 0.161\n",
            "r = 5.378 step done with 58642 lattice points. Tolerance = 0.161\n",
            "r = 5.394 step done with 59546 lattice points. Tolerance = 0.161\n",
            "r = 5.41 step done with 60194 lattice points. Tolerance = 0.161\n",
            "r = 5.426 step done with 59786 lattice points. Tolerance = 0.161\n",
            "r = 5.442 step done with 60308 lattice points. Tolerance = 0.161\n",
            "r = 5.458 step done with 61292 lattice points. Tolerance = 0.161\n",
            "r = 5.474 step done with 61460 lattice points. Tolerance = 0.161\n",
            "r = 5.49 step done with 61580 lattice points. Tolerance = 0.161\n",
            "r = 5.507 step done with 61942 lattice points. Tolerance = 0.161\n",
            "r = 5.523 step done with 62158 lattice points. Tolerance = 0.161\n",
            "r = 5.539 step done with 62866 lattice points. Tolerance = 0.161\n",
            "r = 5.555 step done with 62962 lattice points. Tolerance = 0.161\n",
            "r = 5.571 step done with 62980 lattice points. Tolerance = 0.161\n",
            "r = 5.587 step done with 63964 lattice points. Tolerance = 0.161\n",
            "r = 5.603 step done with 63860 lattice points. Tolerance = 0.161\n",
            "r = 5.619 step done with 63908 lattice points. Tolerance = 0.161\n",
            "r = 5.635 step done with 64586 lattice points. Tolerance = 0.161\n",
            "r = 5.651 step done with 65426 lattice points. Tolerance = 0.161\n",
            "r = 5.668 step done with 66266 lattice points. Tolerance = 0.161\n",
            "r = 5.684 step done with 65918 lattice points. Tolerance = 0.161\n",
            "r = 5.7 step done with 66464 lattice points. Tolerance = 0.161\n",
            "r = 5.716 step done with 66412 lattice points. Tolerance = 0.161\n",
            "r = 5.732 step done with 66916 lattice points. Tolerance = 0.161\n",
            "r = 5.748 step done with 67450 lattice points. Tolerance = 0.161\n",
            "r = 5.764 step done with 67882 lattice points. Tolerance = 0.161\n",
            "r = 5.78 step done with 68266 lattice points. Tolerance = 0.161\n",
            "r = 5.796 step done with 67978 lattice points. Tolerance = 0.161\n",
            "r = 5.812 step done with 68914 lattice points. Tolerance = 0.161\n",
            "r = 5.829 step done with 69020 lattice points. Tolerance = 0.161\n",
            "r = 5.845 step done with 69476 lattice points. Tolerance = 0.161\n",
            "r = 5.861 step done with 69704 lattice points. Tolerance = 0.161\n",
            "r = 5.877 step done with 70070 lattice points. Tolerance = 0.161\n",
            "r = 5.893 step done with 70730 lattice points. Tolerance = 0.161\n",
            "r = 5.909 step done with 71282 lattice points. Tolerance = 0.161\n",
            "r = 5.925 step done with 72122 lattice points. Tolerance = 0.161\n",
            "r = 5.941 step done with 72682 lattice points. Tolerance = 0.161\n",
            "r = 5.957 step done with 72676 lattice points. Tolerance = 0.161\n",
            "r = 5.973 step done with 72748 lattice points. Tolerance = 0.161\n",
            "r = 5.99 step done with 73204 lattice points. Tolerance = 0.161\n",
            "r = 6.006 step done with 73426 lattice points. Tolerance = 0.161\n",
            "r = 6.022 step done with 73642 lattice points. Tolerance = 0.161\n",
            "r = 6.038 step done with 74174 lattice points. Tolerance = 0.161\n",
            "r = 6.054 step done with 75014 lattice points. Tolerance = 0.161\n",
            "r = 6.07 step done with 75092 lattice points. Tolerance = 0.161\n",
            "r = 6.086 step done with 75284 lattice points. Tolerance = 0.161\n",
            "r = 6.102 step done with 76172 lattice points. Tolerance = 0.161\n",
            "r = 6.118 step done with 75692 lattice points. Tolerance = 0.161\n",
            "r = 6.135 step done with 76562 lattice points. Tolerance = 0.161\n",
            "r = 6.151 step done with 76970 lattice points. Tolerance = 0.161\n",
            "r = 6.167 step done with 77818 lattice points. Tolerance = 0.161\n",
            "r = 6.183 step done with 78082 lattice points. Tolerance = 0.161\n",
            "r = 6.199 step done with 79036 lattice points. Tolerance = 0.161\n",
            "r = 6.215 step done with 79816 lattice points. Tolerance = 0.161\n",
            "r = 6.231 step done with 79288 lattice points. Tolerance = 0.161\n",
            "r = 6.247 step done with 78820 lattice points. Tolerance = 0.161\n",
            "r = 6.263 step done with 79658 lattice points. Tolerance = 0.161\n",
            "r = 6.279 step done with 80522 lattice points. Tolerance = 0.161\n",
            "r = 6.296 step done with 80690 lattice points. Tolerance = 0.161\n",
            "r = 6.312 step done with 81218 lattice points. Tolerance = 0.161\n",
            "r = 6.328 step done with 82076 lattice points. Tolerance = 0.161\n",
            "r = 6.344 step done with 82292 lattice points. Tolerance = 0.161\n",
            "r = 6.36 step done with 82124 lattice points. Tolerance = 0.161\n",
            "r = 6.376 step done with 83074 lattice points. Tolerance = 0.161\n",
            "r = 6.392 step done with 83158 lattice points. Tolerance = 0.161\n",
            "r = 6.408 step done with 83950 lattice points. Tolerance = 0.161\n",
            "r = 6.424 step done with 83962 lattice points. Tolerance = 0.161\n",
            "r = 6.44 step done with 85522 lattice points. Tolerance = 0.161\n",
            "r = 6.457 step done with 85396 lattice points. Tolerance = 0.161\n",
            "r = 6.473 step done with 85900 lattice points. Tolerance = 0.161\n",
            "r = 6.489 step done with 85436 lattice points. Tolerance = 0.161\n",
            "r = 6.505 step done with 86090 lattice points. Tolerance = 0.161\n",
            "r = 6.521 step done with 86930 lattice points. Tolerance = 0.161\n",
            "r = 6.537 step done with 87122 lattice points. Tolerance = 0.161\n",
            "r = 6.553 step done with 87626 lattice points. Tolerance = 0.161\n",
            "r = 6.569 step done with 88550 lattice points. Tolerance = 0.161\n",
            "r = 6.585 step done with 88280 lattice points. Tolerance = 0.161\n",
            "r = 6.601 step done with 88612 lattice points. Tolerance = 0.161\n",
            "r = 6.618 step done with 89668 lattice points. Tolerance = 0.161\n",
            "r = 6.634 step done with 89362 lattice points. Tolerance = 0.161\n",
            "r = 6.65 step done with 89986 lattice points. Tolerance = 0.161\n",
            "r = 6.666 step done with 90370 lattice points. Tolerance = 0.161\n",
            "r = 6.682 step done with 91450 lattice points. Tolerance = 0.161\n",
            "r = 6.698 step done with 91124 lattice points. Tolerance = 0.161\n",
            "r = 6.714 step done with 92132 lattice points. Tolerance = 0.161\n",
            "r = 6.73 step done with 92540 lattice points. Tolerance = 0.161\n",
            "r = 6.746 step done with 92624 lattice points. Tolerance = 0.161\n",
            "r = 6.762 step done with 93158 lattice points. Tolerance = 0.161\n",
            "r = 6.779 step done with 93170 lattice points. Tolerance = 0.161\n",
            "r = 6.795 step done with 93794 lattice points. Tolerance = 0.161\n",
            "r = 6.811 step done with 94858 lattice points. Tolerance = 0.161\n",
            "r = 6.827 step done with 95524 lattice points. Tolerance = 0.161\n",
            "r = 6.843 step done with 95212 lattice points. Tolerance = 0.161\n",
            "r = 6.859 step done with 94660 lattice points. Tolerance = 0.161\n",
            "r = 6.875 step done with 96076 lattice points. Tolerance = 0.161\n",
            "r = 6.891 step done with 97258 lattice points. Tolerance = 0.161\n",
            "r = 6.907 step done with 97594 lattice points. Tolerance = 0.161\n",
            "r = 6.923 step done with 98006 lattice points. Tolerance = 0.161\n",
            "r = 6.94 step done with 97862 lattice points. Tolerance = 0.161\n",
            "r = 6.956 step done with 98636 lattice points. Tolerance = 0.161\n",
            "r = 6.972 step done with 99044 lattice points. Tolerance = 0.161\n",
            "r = 6.988 step done with 100148 lattice points. Tolerance = 0.161\n",
            "r = 7.004 step done with 99698 lattice points. Tolerance = 0.161\n",
            "r = 7.02 step done with 99794 lattice points. Tolerance = 0.161\n",
            "r = 7.036 step done with 100258 lattice points. Tolerance = 0.161\n",
            "r = 7.052 step done with 101554 lattice points. Tolerance = 0.161\n",
            "r = 7.068 step done with 102274 lattice points. Tolerance = 0.161\n",
            "r = 7.084 step done with 102220 lattice points. Tolerance = 0.161\n",
            "r = 7.101 step done with 103360 lattice points. Tolerance = 0.161\n",
            "r = 7.117 step done with 103888 lattice points. Tolerance = 0.161\n",
            "r = 7.133 step done with 103658 lattice points. Tolerance = 0.161\n",
            "r = 7.149 step done with 103682 lattice points. Tolerance = 0.161\n",
            "r = 7.165 step done with 104786 lattice points. Tolerance = 0.161\n",
            "r = 7.181 step done with 106082 lattice points. Tolerance = 0.161\n",
            "r = 7.197 step done with 105554 lattice points. Tolerance = 0.161\n",
            "r = 7.213 step done with 105476 lattice points. Tolerance = 0.161\n",
            "r = 7.229 step done with 105956 lattice points. Tolerance = 0.161\n",
            "r = 7.245 step done with 106708 lattice points. Tolerance = 0.161\n",
            "r = 7.262 step done with 107122 lattice points. Tolerance = 0.161\n",
            "r = 7.278 step done with 107854 lattice points. Tolerance = 0.161\n",
            "r = 7.294 step done with 108454 lattice points. Tolerance = 0.161\n",
            "r = 7.31 step done with 109018 lattice points. Tolerance = 0.161\n",
            "r = 7.326 step done with 110044 lattice points. Tolerance = 0.161\n",
            "r = 7.342 step done with 110836 lattice points. Tolerance = 0.161\n",
            "r = 7.358 step done with 110948 lattice points. Tolerance = 0.161\n",
            "r = 7.374 step done with 110396 lattice points. Tolerance = 0.161\n",
            "r = 7.39 step done with 111434 lattice points. Tolerance = 0.161\n",
            "r = 7.406 step done with 112466 lattice points. Tolerance = 0.161\n",
            "r = 7.423 step done with 112274 lattice points. Tolerance = 0.161\n",
            "r = 7.439 step done with 113018 lattice points. Tolerance = 0.161\n",
            "r = 7.455 step done with 113264 lattice points. Tolerance = 0.161\n",
            "r = 7.471 step done with 113656 lattice points. Tolerance = 0.161\n",
            "r = 7.487 step done with 114244 lattice points. Tolerance = 0.161\n",
            "r = 7.503 step done with 114484 lattice points. Tolerance = 0.161\n",
            "r = 7.519 step done with 115642 lattice points. Tolerance = 0.161\n",
            "r = 7.535 step done with 116098 lattice points. Tolerance = 0.161\n",
            "r = 7.551 step done with 116914 lattice points. Tolerance = 0.161\n",
            "r = 7.567 step done with 117410 lattice points. Tolerance = 0.161\n",
            "r = 7.584 step done with 118244 lattice points. Tolerance = 0.161\n",
            "r = 7.6 step done with 118532 lattice points. Tolerance = 0.161\n",
            "r = 7.616 step done with 118460 lattice points. Tolerance = 0.161\n",
            "r = 7.632 step done with 117998 lattice points. Tolerance = 0.161\n",
            "r = 7.648 step done with 119294 lattice points. Tolerance = 0.161\n",
            "r = 7.664 step done with 119498 lattice points. Tolerance = 0.161\n",
            "r = 7.68 step done with 120586 lattice points. Tolerance = 0.161\n",
            "r = 7.696 step done with 121642 lattice points. Tolerance = 0.161\n",
            "r = 7.712 step done with 120772 lattice points. Tolerance = 0.161\n",
            "r = 7.729 step done with 121420 lattice points. Tolerance = 0.161\n",
            "r = 7.745 step done with 121900 lattice points. Tolerance = 0.161\n",
            "r = 7.761 step done with 121570 lattice points. Tolerance = 0.161\n",
            "r = 7.777 step done with 124642 lattice points. Tolerance = 0.161\n",
            "r = 7.793 step done with 124538 lattice points. Tolerance = 0.161\n",
            "r = 7.809 step done with 124934 lattice points. Tolerance = 0.161\n",
            "r = 7.825 step done with 124934 lattice points. Tolerance = 0.161\n",
            "r = 7.841 step done with 125132 lattice points. Tolerance = 0.161\n",
            "r = 7.857 step done with 126164 lattice points. Tolerance = 0.161\n",
            "r = 7.873 step done with 125972 lattice points. Tolerance = 0.161\n",
            "r = 7.89 step done with 126218 lattice points. Tolerance = 0.161\n",
            "r = 7.906 step done with 126634 lattice points. Tolerance = 0.161\n",
            "r = 7.922 step done with 127882 lattice points. Tolerance = 0.161\n",
            "r = 7.938 step done with 127882 lattice points. Tolerance = 0.161\n",
            "r = 7.954 step done with 130180 lattice points. Tolerance = 0.161\n",
            "r = 7.97 step done with 129868 lattice points. Tolerance = 0.161\n",
            "r = 7.986 step done with 130312 lattice points. Tolerance = 0.161\n",
            "r = 8.002 step done with 130136 lattice points. Tolerance = 0.161\n",
            "r = 8.018 step done with 130490 lattice points. Tolerance = 0.161\n",
            "r = 8.034 step done with 131714 lattice points. Tolerance = 0.161\n",
            "r = 8.051 step done with 132794 lattice points. Tolerance = 0.161\n",
            "r = 8.067 step done with 133274 lattice points. Tolerance = 0.161\n",
            "r = 8.083 step done with 134444 lattice points. Tolerance = 0.161\n",
            "r = 8.099 step done with 131708 lattice points. Tolerance = 0.161\n",
            "r = 8.115 step done with 133924 lattice points. Tolerance = 0.161\n",
            "r = 8.131 step done with 134332 lattice points. Tolerance = 0.161\n",
            "r = 8.147 step done with 135754 lattice points. Tolerance = 0.161\n",
            "r = 8.163 step done with 136342 lattice points. Tolerance = 0.161\n",
            "r = 8.179 step done with 136102 lattice points. Tolerance = 0.161\n",
            "r = 8.195 step done with 137674 lattice points. Tolerance = 0.161\n",
            "r = 8.212 step done with 137956 lattice points. Tolerance = 0.161\n",
            "r = 8.228 step done with 138740 lattice points. Tolerance = 0.161\n",
            "r = 8.244 step done with 138860 lattice points. Tolerance = 0.161\n",
            "r = 8.26 step done with 139490 lattice points. Tolerance = 0.161\n",
            "r = 8.276 step done with 139250 lattice points. Tolerance = 0.161\n",
            "r = 8.292 step done with 139658 lattice points. Tolerance = 0.161\n",
            "r = 8.308 step done with 141362 lattice points. Tolerance = 0.161\n",
            "r = 8.324 step done with 141842 lattice points. Tolerance = 0.161\n",
            "r = 8.34 step done with 141472 lattice points. Tolerance = 0.161\n",
            "r = 8.356 step done with 142720 lattice points. Tolerance = 0.161\n",
            "r = 8.373 step done with 142084 lattice points. Tolerance = 0.161\n",
            "r = 8.389 step done with 143194 lattice points. Tolerance = 0.161\n",
            "r = 8.405 step done with 144034 lattice points. Tolerance = 0.161\n",
            "r = 8.421 step done with 145762 lattice points. Tolerance = 0.161\n",
            "r = 8.437 step done with 145178 lattice points. Tolerance = 0.161\n",
            "r = 8.453 step done with 145946 lattice points. Tolerance = 0.161\n",
            "r = 8.469 step done with 146084 lattice points. Tolerance = 0.161\n",
            "r = 8.485 step done with 147284 lattice points. Tolerance = 0.161\n",
            "r = 8.501 step done with 147140 lattice points. Tolerance = 0.161\n",
            "r = 8.517 step done with 147446 lattice points. Tolerance = 0.161\n",
            "r = 8.534 step done with 148934 lattice points. Tolerance = 0.161\n",
            "r = 8.55 step done with 147970 lattice points. Tolerance = 0.161\n",
            "r = 8.566 step done with 149218 lattice points. Tolerance = 0.161\n",
            "r = 8.582 step done with 150364 lattice points. Tolerance = 0.161\n",
            "r = 8.598 step done with 150916 lattice points. Tolerance = 0.161\n",
            "r = 8.614 step done with 151036 lattice points. Tolerance = 0.161\n",
            "r = 8.63 step done with 151204 lattice points. Tolerance = 0.161\n",
            "r = 8.646 step done with 151954 lattice points. Tolerance = 0.161\n",
            "r = 8.662 step done with 153194 lattice points. Tolerance = 0.161\n",
            "r = 8.678 step done with 153410 lattice points. Tolerance = 0.161\n",
            "r = 8.695 step done with 155102 lattice points. Tolerance = 0.161\n",
            "r = 8.711 step done with 154592 lattice points. Tolerance = 0.161\n",
            "r = 8.727 step done with 155132 lattice points. Tolerance = 0.161\n",
            "r = 8.743 step done with 155516 lattice points. Tolerance = 0.161\n",
            "r = 8.759 step done with 156644 lattice points. Tolerance = 0.161\n",
            "r = 8.775 step done with 155962 lattice points. Tolerance = 0.161\n",
            "r = 8.791 step done with 158362 lattice points. Tolerance = 0.161\n",
            "r = 8.807 step done with 157042 lattice points. Tolerance = 0.161\n",
            "r = 8.823 step done with 158962 lattice points. Tolerance = 0.161\n",
            "r = 8.839 step done with 159604 lattice points. Tolerance = 0.161\n",
            "r = 8.856 step done with 159580 lattice points. Tolerance = 0.161\n",
            "r = 8.872 step done with 161888 lattice points. Tolerance = 0.161\n",
            "r = 8.888 step done with 159854 lattice points. Tolerance = 0.161\n",
            "r = 8.904 step done with 161306 lattice points. Tolerance = 0.161\n",
            "r = 8.92 step done with 162386 lattice points. Tolerance = 0.161\n",
            "r = 8.936 step done with 163058 lattice points. Tolerance = 0.161\n",
            "r = 8.952 step done with 163850 lattice points. Tolerance = 0.161\n",
            "r = 8.968 step done with 164444 lattice points. Tolerance = 0.161\n",
            "r = 8.984 step done with 164380 lattice points. Tolerance = 0.161\n",
            "r = 9.0 step done with 165196 lattice points. Tolerance = 0.161\n",
            "r = 9.017 step done with 164794 lattice points. Tolerance = 0.161\n",
            "r = 9.033 step done with 166186 lattice points. Tolerance = 0.161\n",
            "r = 9.049 step done with 167302 lattice points. Tolerance = 0.161\n",
            "r = 9.065 step done with 168766 lattice points. Tolerance = 0.161\n",
            "r = 9.081 step done with 167026 lattice points. Tolerance = 0.161\n",
            "r = 9.097 step done with 169556 lattice points. Tolerance = 0.161\n",
            "r = 9.113 step done with 168908 lattice points. Tolerance = 0.161\n",
            "r = 9.129 step done with 170180 lattice points. Tolerance = 0.161\n",
            "r = 9.145 step done with 170282 lattice points. Tolerance = 0.161\n",
            "r = 9.162 step done with 170906 lattice points. Tolerance = 0.161\n",
            "r = 9.178 step done with 171074 lattice points. Tolerance = 0.161\n",
            "r = 9.194 step done with 172490 lattice points. Tolerance = 0.161\n",
            "r = 9.21 step done with 173692 lattice points. Tolerance = 0.161\n",
            "r = 9.226 step done with 173920 lattice points. Tolerance = 0.161\n",
            "r = 9.242 step done with 173704 lattice points. Tolerance = 0.161\n",
            "r = 9.258 step done with 174556 lattice points. Tolerance = 0.161\n",
            "r = 9.274 step done with 174754 lattice points. Tolerance = 0.161\n",
            "r = 9.29 step done with 175954 lattice points. Tolerance = 0.161\n",
            "r = 9.306 step done with 177866 lattice points. Tolerance = 0.161\n",
            "r = 9.323 step done with 177602 lattice points. Tolerance = 0.161\n",
            "r = 9.339 step done with 177596 lattice points. Tolerance = 0.161\n",
            "r = 9.355 step done with 179396 lattice points. Tolerance = 0.161\n",
            "r = 9.371 step done with 179372 lattice points. Tolerance = 0.161\n",
            "r = 9.387 step done with 178532 lattice points. Tolerance = 0.161\n",
            "r = 9.403 step done with 181070 lattice points. Tolerance = 0.161\n",
            "r = 9.419 step done with 180718 lattice points. Tolerance = 0.161\n",
            "r = 9.435 step done with 180886 lattice points. Tolerance = 0.161\n",
            "r = 9.451 step done with 183418 lattice points. Tolerance = 0.161\n",
            "r = 9.467 step done with 183700 lattice points. Tolerance = 0.161\n",
            "r = 9.484 step done with 183796 lattice points. Tolerance = 0.161\n",
            "r = 9.5 step done with 184852 lattice points. Tolerance = 0.161\n",
            "r = 9.516 step done with 183754 lattice points. Tolerance = 0.161\n",
            "r = 9.532 step done with 185882 lattice points. Tolerance = 0.161\n",
            "r = 9.548 step done with 186410 lattice points. Tolerance = 0.161\n",
            "r = 9.564 step done with 186506 lattice points. Tolerance = 0.161\n",
            "r = 9.58 step done with 187478 lattice points. Tolerance = 0.161\n",
            "r = 9.596 step done with 188000 lattice points. Tolerance = 0.161\n",
            "r = 9.612 step done with 187520 lattice points. Tolerance = 0.161\n",
            "r = 9.628 step done with 188180 lattice points. Tolerance = 0.161\n",
            "r = 9.645 step done with 188554 lattice points. Tolerance = 0.161\n",
            "r = 9.661 step done with 190834 lattice points. Tolerance = 0.161\n",
            "r = 9.677 step done with 189874 lattice points. Tolerance = 0.161\n",
            "r = 9.693 step done with 190138 lattice points. Tolerance = 0.161\n",
            "r = 9.709 step done with 191842 lattice points. Tolerance = 0.161\n",
            "r = 9.725 step done with 193804 lattice points. Tolerance = 0.161\n",
            "r = 9.741 step done with 194036 lattice points. Tolerance = 0.161\n",
            "r = 9.757 step done with 195020 lattice points. Tolerance = 0.161\n",
            "r = 9.773 step done with 193022 lattice points. Tolerance = 0.161\n",
            "r = 9.789 step done with 194798 lattice points. Tolerance = 0.161\n",
            "r = 9.806 step done with 195722 lattice points. Tolerance = 0.161\n",
            "r = 9.822 step done with 197426 lattice points. Tolerance = 0.161\n",
            "r = 9.838 step done with 198116 lattice points. Tolerance = 0.161\n",
            "r = 9.854 step done with 197788 lattice points. Tolerance = 0.161\n",
            "r = 9.87 step done with 198388 lattice points. Tolerance = 0.161\n",
            "r = 9.886 step done with 199300 lattice points. Tolerance = 0.161\n",
            "r = 9.902 step done with 199714 lattice points. Tolerance = 0.161\n",
            "r = 9.918 step done with 200122 lattice points. Tolerance = 0.161\n",
            "r = 9.934 step done with 202570 lattice points. Tolerance = 0.161\n",
            "r = 9.95 step done with 202534 lattice points. Tolerance = 0.161\n",
            "r = 9.967 step done with 203432 lattice points. Tolerance = 0.161\n",
            "r = 9.983 step done with 203300 lattice points. Tolerance = 0.161\n",
            "r = 9.999 step done with 204860 lattice points. Tolerance = 0.161\n",
            "r = 10.015 step done with 204812 lattice points. Tolerance = 0.161\n",
            "r = 10.031 step done with 206378 lattice points. Tolerance = 0.161\n",
            "r = 10.047 step done with 205154 lattice points. Tolerance = 0.161\n",
            "r = 10.063 step done with 206114 lattice points. Tolerance = 0.161\n",
            "r = 10.079 step done with 205858 lattice points. Tolerance = 0.161\n",
            "r = 10.095 step done with 208468 lattice points. Tolerance = 0.161\n",
            "r = 10.111 step done with 208852 lattice points. Tolerance = 0.161\n",
            "r = 10.128 step done with 209176 lattice points. Tolerance = 0.161\n",
            "r = 10.144 step done with 207742 lattice points. Tolerance = 0.161\n",
            "r = 10.16 step done with 209842 lattice points. Tolerance = 0.161\n",
            "r = 10.176 step done with 211778 lattice points. Tolerance = 0.161\n",
            "r = 10.192 step done with 212306 lattice points. Tolerance = 0.161\n",
            "r = 10.208 step done with 212234 lattice points. Tolerance = 0.161\n",
            "r = 10.224 step done with 213332 lattice points. Tolerance = 0.161\n",
            "r = 10.24 step done with 215060 lattice points. Tolerance = 0.161\n",
            "r = 10.256 step done with 214052 lattice points. Tolerance = 0.161\n",
            "r = 10.272 step done with 214970 lattice points. Tolerance = 0.161\n",
            "r = 10.289 step done with 215458 lattice points. Tolerance = 0.161\n",
            "r = 10.305 step done with 216718 lattice points. Tolerance = 0.161\n",
            "r = 10.321 step done with 217534 lattice points. Tolerance = 0.161\n",
            "r = 10.337 step done with 218122 lattice points. Tolerance = 0.161\n",
            "r = 10.353 step done with 217876 lattice points. Tolerance = 0.161\n",
            "r = 10.369 step done with 219844 lattice points. Tolerance = 0.161\n",
            "r = 10.385 step done with 220204 lattice points. Tolerance = 0.161\n",
            "r = 10.401 step done with 221210 lattice points. Tolerance = 0.161\n",
            "r = 10.417 step done with 221354 lattice points. Tolerance = 0.161\n",
            "r = 10.433 step done with 221786 lattice points. Tolerance = 0.161\n",
            "r = 10.45 step done with 222866 lattice points. Tolerance = 0.161\n",
            "r = 10.466 step done with 225116 lattice points. Tolerance = 0.161\n",
            "r = 10.482 step done with 223928 lattice points. Tolerance = 0.161\n",
            "r = 10.498 step done with 224792 lattice points. Tolerance = 0.161\n",
            "r = 10.514 step done with 224212 lattice points. Tolerance = 0.161\n",
            "r = 10.53 step done with 226810 lattice points. Tolerance = 0.161\n",
            "r = 10.546 step done with 227914 lattice points. Tolerance = 0.161\n",
            "r = 10.562 step done with 226546 lattice points. Tolerance = 0.161\n",
            "r = 10.578 step done with 228106 lattice points. Tolerance = 0.161\n",
            "r = 10.594 step done with 228892 lattice points. Tolerance = 0.161\n",
            "r = 10.611 step done with 229940 lattice points. Tolerance = 0.161\n",
            "r = 10.627 step done with 229484 lattice points. Tolerance = 0.161\n",
            "r = 10.643 step done with 229844 lattice points. Tolerance = 0.161\n",
            "r = 10.659 step done with 232214 lattice points. Tolerance = 0.161\n",
            "r = 10.675 step done with 232838 lattice points. Tolerance = 0.161\n",
            "r = 10.691 step done with 232178 lattice points. Tolerance = 0.161\n",
            "r = 10.707 step done with 233618 lattice points. Tolerance = 0.161\n",
            "r = 10.723 step done with 235780 lattice points. Tolerance = 0.161\n",
            "r = 10.739 step done with 235612 lattice points. Tolerance = 0.161\n",
            "r = 10.756 step done with 236236 lattice points. Tolerance = 0.161\n",
            "r = 10.772 step done with 235780 lattice points. Tolerance = 0.161\n",
            "r = 10.788 step done with 236842 lattice points. Tolerance = 0.161\n",
            "r = 10.804 step done with 238114 lattice points. Tolerance = 0.161\n",
            "r = 10.82 step done with 238474 lattice points. Tolerance = 0.161\n",
            "r = 10.836 step done with 240854 lattice points. Tolerance = 0.161\n",
            "r = 10.852 step done with 238376 lattice points. Tolerance = 0.161\n",
            "r = 10.868 step done with 239468 lattice points. Tolerance = 0.161\n",
            "r = 10.884 step done with 242036 lattice points. Tolerance = 0.161\n",
            "r = 10.9 step done with 242546 lattice points. Tolerance = 0.161\n",
            "r = 10.917 step done with 243242 lattice points. Tolerance = 0.161\n",
            "r = 10.933 step done with 243314 lattice points. Tolerance = 0.161\n",
            "r = 10.949 step done with 244786 lattice points. Tolerance = 0.161\n",
            "r = 10.965 step done with 245842 lattice points. Tolerance = 0.161\n",
            "r = 10.981 step done with 245980 lattice points. Tolerance = 0.161\n",
            "r = 10.997 step done with 246892 lattice points. Tolerance = 0.161\n",
            "r = 11.013 step done with 247576 lattice points. Tolerance = 0.161\n",
            "r = 11.029 step done with 247390 lattice points. Tolerance = 0.161\n",
            "r = 11.045 step done with 247754 lattice points. Tolerance = 0.161\n",
            "r = 11.061 step done with 249266 lattice points. Tolerance = 0.161\n",
            "r = 11.078 step done with 250466 lattice points. Tolerance = 0.161\n",
            "r = 11.094 step done with 252722 lattice points. Tolerance = 0.161\n",
            "r = 11.11 step done with 251540 lattice points. Tolerance = 0.161\n",
            "r = 11.126 step done with 251876 lattice points. Tolerance = 0.161\n",
            "r = 11.142 step done with 253028 lattice points. Tolerance = 0.161\n",
            "r = 11.158 step done with 252586 lattice points. Tolerance = 0.161\n",
            "r = 11.174 step done with 255850 lattice points. Tolerance = 0.161\n",
            "r = 11.19 step done with 255502 lattice points. Tolerance = 0.161\n",
            "r = 11.206 step done with 256366 lattice points. Tolerance = 0.161\n",
            "r = 11.222 step done with 256756 lattice points. Tolerance = 0.161\n",
            "r = 11.239 step done with 257596 lattice points. Tolerance = 0.161\n",
            "r = 11.255 step done with 259252 lattice points. Tolerance = 0.161\n",
            "r = 11.271 step done with 259124 lattice points. Tolerance = 0.161\n",
            "r = 11.287 step done with 260186 lattice points. Tolerance = 0.161\n",
            "r = 11.303 step done with 260018 lattice points. Tolerance = 0.161\n",
            "r = 11.319 step done with 260738 lattice points. Tolerance = 0.161\n",
            "r = 11.335 step done with 262922 lattice points. Tolerance = 0.161\n",
            "r = 11.351 step done with 263540 lattice points. Tolerance = 0.161\n",
            "r = 11.367 step done with 263528 lattice points. Tolerance = 0.161\n",
            "r = 11.383 step done with 263824 lattice points. Tolerance = 0.161\n",
            "r = 11.4 step done with 264028 lattice points. Tolerance = 0.161\n",
            "r = 11.416 step done with 264754 lattice points. Tolerance = 0.161\n",
            "r = 11.432 step done with 267370 lattice points. Tolerance = 0.161\n",
            "r = 11.448 step done with 269410 lattice points. Tolerance = 0.161\n",
            "r = 11.464 step done with 268450 lattice points. Tolerance = 0.161\n",
            "r = 11.48 step done with 268892 lattice points. Tolerance = 0.161\n",
            "r = 11.496 step done with 269324 lattice points. Tolerance = 0.161\n",
            "r = 11.512 step done with 270860 lattice points. Tolerance = 0.161\n",
            "r = 11.528 step done with 270218 lattice points. Tolerance = 0.161\n",
            "r = 11.544 step done with 271766 lattice points. Tolerance = 0.161\n",
            "r = 11.561 step done with 272174 lattice points. Tolerance = 0.161\n",
            "r = 11.577 step done with 272666 lattice points. Tolerance = 0.161\n",
            "r = 11.593 step done with 274042 lattice points. Tolerance = 0.161\n",
            "r = 11.609 step done with 274516 lattice points. Tolerance = 0.161\n",
            "r = 11.625 step done with 275476 lattice points. Tolerance = 0.161\n",
            "r = 11.641 step done with 276172 lattice points. Tolerance = 0.161\n",
            "r = 11.657 step done with 275506 lattice points. Tolerance = 0.161\n",
            "r = 11.673 step done with 277786 lattice points. Tolerance = 0.161\n",
            "r = 11.689 step done with 278266 lattice points. Tolerance = 0.161\n",
            "r = 11.705 step done with 280514 lattice points. Tolerance = 0.161\n",
            "r = 11.722 step done with 280910 lattice points. Tolerance = 0.161\n",
            "r = 11.738 step done with 280352 lattice points. Tolerance = 0.161\n",
            "r = 11.754 step done with 280748 lattice points. Tolerance = 0.161\n",
            "r = 11.77 step done with 282356 lattice points. Tolerance = 0.161\n",
            "r = 11.786 step done with 283274 lattice points. Tolerance = 0.161\n",
            "r = 11.802 step done with 284690 lattice points. Tolerance = 0.161\n",
            "r = 11.818 step done with 285418 lattice points. Tolerance = 0.161\n",
            "r = 11.834 step done with 285418 lattice points. Tolerance = 0.161\n",
            "r = 11.85 step done with 286732 lattice points. Tolerance = 0.161\n",
            "r = 11.866 step done with 286108 lattice points. Tolerance = 0.161\n",
            "r = 11.883 step done with 287932 lattice points. Tolerance = 0.161\n",
            "r = 11.899 step done with 289000 lattice points. Tolerance = 0.161\n",
            "r = 11.915 step done with 290414 lattice points. Tolerance = 0.161\n",
            "r = 11.931 step done with 290042 lattice points. Tolerance = 0.161\n",
            "r = 11.947 step done with 291242 lattice points. Tolerance = 0.161\n",
            "r = 11.963 step done with 292322 lattice points. Tolerance = 0.161\n",
            "r = 11.979 step done with 294332 lattice points. Tolerance = 0.161\n",
            "r = 11.995 step done with 293156 lattice points. Tolerance = 0.161\n",
            "r = 12.011 step done with 294404 lattice points. Tolerance = 0.161\n",
            "r = 12.027 step done with 293300 lattice points. Tolerance = 0.161\n",
            "r = 12.044 step done with 294706 lattice points. Tolerance = 0.161\n",
            "r = 12.06 step done with 297154 lattice points. Tolerance = 0.161\n",
            "r = 12.076 step done with 298414 lattice points. Tolerance = 0.161\n",
            "r = 12.092 step done with 296926 lattice points. Tolerance = 0.161\n",
            "r = 12.108 step done with 297820 lattice points. Tolerance = 0.161\n",
            "r = 12.124 step done with 300004 lattice points. Tolerance = 0.161\n",
            "r = 12.14 step done with 301196 lattice points. Tolerance = 0.161\n",
            "r = 12.156 step done with 300338 lattice points. Tolerance = 0.161\n",
            "r = 12.172 step done with 302186 lattice points. Tolerance = 0.161\n",
            "r = 12.188 step done with 304082 lattice points. Tolerance = 0.161\n",
            "r = 12.205 step done with 303290 lattice points. Tolerance = 0.161\n",
            "r = 12.221 step done with 305522 lattice points. Tolerance = 0.161\n",
            "r = 12.237 step done with 304580 lattice points. Tolerance = 0.161\n",
            "r = 12.253 step done with 306016 lattice points. Tolerance = 0.161\n",
            "r = 12.269 step done with 306400 lattice points. Tolerance = 0.161\n",
            "r = 12.285 step done with 307954 lattice points. Tolerance = 0.161\n",
            "r = 12.301 step done with 308074 lattice points. Tolerance = 0.161\n",
            "r = 12.317 step done with 309250 lattice points. Tolerance = 0.161\n",
            "r = 12.333 step done with 310642 lattice points. Tolerance = 0.161\n",
            "r = 12.35 step done with 312490 lattice points. Tolerance = 0.161\n",
            "r = 12.366 step done with 311708 lattice points. Tolerance = 0.161\n",
            "r = 12.382 step done with 313052 lattice points. Tolerance = 0.161\n",
            "r = 12.398 step done with 311852 lattice points. Tolerance = 0.161\n",
            "r = 12.414 step done with 314954 lattice points. Tolerance = 0.161\n",
            "r = 12.43 step done with 315686 lattice points. Tolerance = 0.161\n",
            "r = 12.446 step done with 315350 lattice points. Tolerance = 0.161\n",
            "r = 12.462 step done with 315626 lattice points. Tolerance = 0.161\n",
            "r = 12.478 step done with 318604 lattice points. Tolerance = 0.161\n",
            "r = 12.494 step done with 319516 lattice points. Tolerance = 0.161\n",
            "r = 12.511 step done with 319084 lattice points. Tolerance = 0.161\n",
            "r = 12.527 step done with 319588 lattice points. Tolerance = 0.161\n",
            "r = 12.543 step done with 319498 lattice points. Tolerance = 0.161\n",
            "r = 12.559 step done with 321538 lattice points. Tolerance = 0.161\n",
            "r = 12.575 step done with 322538 lattice points. Tolerance = 0.161\n",
            "r = 12.591 step done with 324314 lattice points. Tolerance = 0.161\n",
            "r = 12.607 step done with 323120 lattice points. Tolerance = 0.161\n",
            "r = 12.623 step done with 325784 lattice points. Tolerance = 0.161\n",
            "r = 12.639 step done with 325700 lattice points. Tolerance = 0.161\n",
            "r = 12.655 step done with 325820 lattice points. Tolerance = 0.161\n",
            "r = 12.672 step done with 326618 lattice points. Tolerance = 0.161\n",
            "r = 12.688 step done with 330778 lattice points. Tolerance = 0.161\n",
            "r = 12.704 step done with 327802 lattice points. Tolerance = 0.161\n",
            "r = 12.72 step done with 331426 lattice points. Tolerance = 0.161\n",
            "r = 12.736 step done with 331012 lattice points. Tolerance = 0.161\n",
            "r = 12.752 step done with 331180 lattice points. Tolerance = 0.161\n",
            "r = 12.768 step done with 331564 lattice points. Tolerance = 0.161\n",
            "r = 12.784 step done with 334030 lattice points. Tolerance = 0.161\n",
            "r = 12.8 step done with 334646 lattice points. Tolerance = 0.161\n",
            "r = 12.816 step done with 333194 lattice points. Tolerance = 0.161\n",
            "r = 12.833 step done with 335762 lattice points. Tolerance = 0.161\n",
            "r = 12.849 step done with 337922 lattice points. Tolerance = 0.161\n",
            "r = 12.865 step done with 337628 lattice points. Tolerance = 0.161\n",
            "r = 12.881 step done with 339092 lattice points. Tolerance = 0.161\n",
            "r = 12.897 step done with 339500 lattice points. Tolerance = 0.161\n",
            "r = 12.913 step done with 338578 lattice points. Tolerance = 0.161\n",
            "r = 12.929 step done with 341890 lattice points. Tolerance = 0.161\n",
            "r = 12.945 step done with 340666 lattice points. Tolerance = 0.161\n",
            "r = 12.961 step done with 343894 lattice points. Tolerance = 0.161\n",
            "r = 12.977 step done with 344614 lattice points. Tolerance = 0.161\n",
            "r = 12.994 step done with 345268 lattice points. Tolerance = 0.161\n",
            "r = 13.01 step done with 342836 lattice points. Tolerance = 0.161\n",
            "r = 13.026 step done with 346532 lattice points. Tolerance = 0.161\n",
            "r = 13.042 step done with 346130 lattice points. Tolerance = 0.161\n",
            "r = 13.058 step done with 346610 lattice points. Tolerance = 0.161\n",
            "r = 13.074 step done with 348050 lattice points. Tolerance = 0.161\n",
            "r = 13.09 step done with 350474 lattice points. Tolerance = 0.161\n",
            "r = 13.106 step done with 349772 lattice points. Tolerance = 0.161\n",
            "r = 13.122 step done with 350740 lattice points. Tolerance = 0.161\n",
            "r = 13.138 step done with 351616 lattice points. Tolerance = 0.161\n",
            "r = 13.155 step done with 353128 lattice points. Tolerance = 0.161\n",
            "r = 13.171 step done with 353026 lattice points. Tolerance = 0.161\n",
            "r = 13.187 step done with 354778 lattice points. Tolerance = 0.161\n",
            "r = 13.203 step done with 355738 lattice points. Tolerance = 0.161\n",
            "r = 13.219 step done with 355906 lattice points. Tolerance = 0.161\n",
            "r = 13.235 step done with 358628 lattice points. Tolerance = 0.161\n",
            "r = 13.251 step done with 357500 lattice points. Tolerance = 0.161\n",
            "r = 13.267 step done with 358868 lattice points. Tolerance = 0.161\n",
            "r = 13.283 step done with 359012 lattice points. Tolerance = 0.161\n",
            "r = 13.299 step done with 360242 lattice points. Tolerance = 0.161\n",
            "r = 13.316 step done with 362198 lattice points. Tolerance = 0.161\n",
            "r = 13.332 step done with 362534 lattice points. Tolerance = 0.161\n",
            "r = 13.348 step done with 364378 lattice points. Tolerance = 0.161\n",
            "r = 13.364 step done with 364276 lattice points. Tolerance = 0.161\n",
            "r = 13.38 step done with 366676 lattice points. Tolerance = 0.161\n",
            "r = 13.396 step done with 367132 lattice points. Tolerance = 0.161\n",
            "r = 13.412 step done with 367042 lattice points. Tolerance = 0.161\n",
            "r = 13.428 step done with 368506 lattice points. Tolerance = 0.161\n",
            "r = 13.444 step done with 368666 lattice points. Tolerance = 0.161\n",
            "r = 13.46 step done with 371186 lattice points. Tolerance = 0.161\n",
            "r = 13.477 step done with 370634 lattice points. Tolerance = 0.161\n",
            "r = 13.493 step done with 371552 lattice points. Tolerance = 0.161\n",
            "r = 13.509 step done with 372488 lattice points. Tolerance = 0.161\n",
            "r = 13.525 step done with 372716 lattice points. Tolerance = 0.161\n",
            "r = 13.541 step done with 373946 lattice points. Tolerance = 0.161\n",
            "r = 13.557 step done with 374650 lattice points. Tolerance = 0.161\n",
            "r = 13.573 step done with 377026 lattice points. Tolerance = 0.161\n",
            "r = 13.589 step done with 377626 lattice points. Tolerance = 0.161\n",
            "r = 13.605 step done with 377002 lattice points. Tolerance = 0.161\n",
            "r = 13.621 step done with 379684 lattice points. Tolerance = 0.161\n",
            "r = 13.638 step done with 378196 lattice points. Tolerance = 0.161\n",
            "r = 13.654 step done with 380596 lattice points. Tolerance = 0.161\n",
            "r = 13.67 step done with 380174 lattice points. Tolerance = 0.161\n",
            "r = 13.686 step done with 382886 lattice points. Tolerance = 0.161\n",
            "r = 13.702 step done with 381362 lattice points. Tolerance = 0.161\n",
            "r = 13.718 step done with 384170 lattice points. Tolerance = 0.161\n",
            "r = 13.734 step done with 384548 lattice points. Tolerance = 0.161\n",
            "r = 13.75 step done with 385700 lattice points. Tolerance = 0.161\n",
            "r = 13.766 step done with 387020 lattice points. Tolerance = 0.161\n",
            "r = 13.783 step done with 386164 lattice points. Tolerance = 0.161\n",
            "r = 13.799 step done with 387490 lattice points. Tolerance = 0.161\n",
            "r = 13.815 step done with 389002 lattice points. Tolerance = 0.161\n",
            "r = 13.831 step done with 390154 lattice points. Tolerance = 0.161\n",
            "r = 13.847 step done with 390934 lattice points. Tolerance = 0.161\n",
            "r = 13.863 step done with 392680 lattice points. Tolerance = 0.161\n",
            "r = 13.879 step done with 392252 lattice points. Tolerance = 0.161\n",
            "r = 13.895 step done with 392732 lattice points. Tolerance = 0.161\n",
            "r = 13.911 step done with 392804 lattice points. Tolerance = 0.161\n",
            "r = 13.927 step done with 397010 lattice points. Tolerance = 0.161\n",
            "r = 13.944 step done with 394802 lattice points. Tolerance = 0.161\n",
            "r = 13.96 step done with 397250 lattice points. Tolerance = 0.161\n",
            "r = 13.976 step done with 399410 lattice points. Tolerance = 0.161\n",
            "r = 13.992 step done with 399508 lattice points. Tolerance = 0.161\n",
            "r = 14.008 step done with 399508 lattice points. Tolerance = 0.161\n",
            "r = 14.024 step done with 402040 lattice points. Tolerance = 0.161\n",
            "r = 14.04 step done with 401542 lattice points. Tolerance = 0.161\n",
            "r = 14.056 step done with 401194 lattice points. Tolerance = 0.161\n",
            "r = 14.072 step done with 403282 lattice points. Tolerance = 0.161\n",
            "r = 14.088 step done with 405490 lattice points. Tolerance = 0.161\n",
            "r = 14.105 step done with 406562 lattice points. Tolerance = 0.161\n",
            "r = 14.121 step done with 407300 lattice points. Tolerance = 0.161\n",
            "r = 14.137 step done with 407756 lattice points. Tolerance = 0.161\n",
            "r = 14.153 step done with 408476 lattice points. Tolerance = 0.161\n",
            "r = 14.169 step done with 408242 lattice points. Tolerance = 0.161\n",
            "r = 14.185 step done with 409274 lattice points. Tolerance = 0.161\n",
            "r = 14.201 step done with 412382 lattice points. Tolerance = 0.161\n",
            "r = 14.217 step done with 412726 lattice points. Tolerance = 0.161\n",
            "r = 14.233 step done with 412414 lattice points. Tolerance = 0.161\n",
            "r = 14.249 step done with 414100 lattice points. Tolerance = 0.161\n",
            "r = 14.266 step done with 415588 lattice points. Tolerance = 0.161\n",
            "r = 14.282 step done with 416068 lattice points. Tolerance = 0.161\n",
            "r = 14.298 step done with 416746 lattice points. Tolerance = 0.161\n",
            "r = 14.314 step done with 418082 lattice points. Tolerance = 0.161\n",
            "r = 14.33 step done with 417554 lattice points. Tolerance = 0.161\n",
            "r = 14.346 step done with 418226 lattice points. Tolerance = 0.161\n",
            "r = 14.362 step done with 421052 lattice points. Tolerance = 0.161\n",
            "r = 14.378 step done with 423512 lattice points. Tolerance = 0.161\n",
            "r = 14.394 step done with 422120 lattice points. Tolerance = 0.161\n",
            "r = 14.41 step done with 420632 lattice points. Tolerance = 0.161\n",
            "r = 14.427 step done with 423970 lattice points. Tolerance = 0.161\n",
            "r = 14.443 step done with 425194 lattice points. Tolerance = 0.161\n",
            "r = 14.459 step done with 426274 lattice points. Tolerance = 0.161\n",
            "r = 14.475 step done with 426154 lattice points. Tolerance = 0.161\n",
            "r = 14.491 step done with 429340 lattice points. Tolerance = 0.161\n",
            "r = 14.507 step done with 428236 lattice points. Tolerance = 0.161\n",
            "r = 14.523 step done with 430948 lattice points. Tolerance = 0.161\n",
            "r = 14.539 step done with 429716 lattice points. Tolerance = 0.161\n",
            "r = 14.555 step done with 433442 lattice points. Tolerance = 0.161\n",
            "r = 14.571 step done with 431222 lattice points. Tolerance = 0.161\n",
            "r = 14.588 step done with 434342 lattice points. Tolerance = 0.161\n",
            "r = 14.604 step done with 434906 lattice points. Tolerance = 0.161\n",
            "r = 14.62 step done with 434252 lattice points. Tolerance = 0.161\n",
            "r = 14.636 step done with 437396 lattice points. Tolerance = 0.161\n",
            "r = 14.652 step done with 438028 lattice points. Tolerance = 0.161\n",
            "r = 14.668 step done with 439714 lattice points. Tolerance = 0.161\n",
            "r = 14.684 step done with 438610 lattice points. Tolerance = 0.161\n",
            "r = 14.7 step done with 440482 lattice points. Tolerance = 0.161\n",
            "r = 14.716 step done with 441346 lattice points. Tolerance = 0.161\n",
            "r = 14.732 step done with 444346 lattice points. Tolerance = 0.161\n",
            "r = 14.749 step done with 444512 lattice points. Tolerance = 0.161\n",
            "r = 14.765 step done with 444872 lattice points. Tolerance = 0.161\n",
            "r = 14.781 step done with 444380 lattice points. Tolerance = 0.161\n",
            "r = 14.797 step done with 447026 lattice points. Tolerance = 0.161\n",
            "r = 14.813 step done with 447842 lattice points. Tolerance = 0.161\n",
            "r = 14.829 step done with 451082 lattice points. Tolerance = 0.161\n",
            "r = 14.845 step done with 447458 lattice points. Tolerance = 0.161\n",
            "r = 14.861 step done with 450826 lattice points. Tolerance = 0.161\n",
            "r = 14.877 step done with 452668 lattice points. Tolerance = 0.161\n",
            "r = 14.893 step done with 453076 lattice points. Tolerance = 0.161\n",
            "r = 14.91 step done with 453940 lattice points. Tolerance = 0.161\n",
            "r = 14.926 step done with 453550 lattice points. Tolerance = 0.161\n",
            "r = 14.942 step done with 456406 lattice points. Tolerance = 0.161\n",
            "r = 14.958 step done with 456082 lattice points. Tolerance = 0.161\n",
            "r = 14.974 step done with 457994 lattice points. Tolerance = 0.161\n",
            "r = 14.99 step done with 458060 lattice points. Tolerance = 0.161\n",
            "r = 15.006 step done with 459092 lattice points. Tolerance = 0.161\n",
            "r = 15.022 step done with 459956 lattice points. Tolerance = 0.161\n",
            "r = 15.038 step done with 462548 lattice points. Tolerance = 0.161\n",
            "r = 15.054 step done with 461258 lattice points. Tolerance = 0.161\n",
            "r = 15.071 step done with 462122 lattice points. Tolerance = 0.161\n",
            "r = 15.087 step done with 463162 lattice points. Tolerance = 0.161\n",
            "r = 15.103 step done with 466150 lattice points. Tolerance = 0.161\n",
            "r = 15.119 step done with 465160 lattice points. Tolerance = 0.161\n",
            "r = 15.135 step done with 466420 lattice points. Tolerance = 0.161\n",
            "r = 15.151 step done with 467068 lattice points. Tolerance = 0.161\n",
            "r = 15.167 step done with 469324 lattice points. Tolerance = 0.161\n",
            "r = 15.183 step done with 470690 lattice points. Tolerance = 0.161\n",
            "r = 15.199 step done with 470738 lattice points. Tolerance = 0.161\n",
            "r = 15.215 step done with 472226 lattice points. Tolerance = 0.161\n",
            "r = 15.232 step done with 471866 lattice points. Tolerance = 0.161\n",
            "r = 15.248 step done with 475844 lattice points. Tolerance = 0.161\n",
            "r = 15.264 step done with 475988 lattice points. Tolerance = 0.161\n",
            "r = 15.28 step done with 476096 lattice points. Tolerance = 0.161\n",
            "r = 15.296 step done with 475942 lattice points. Tolerance = 0.161\n",
            "r = 15.312 step done with 479170 lattice points. Tolerance = 0.161\n",
            "r = 15.328 step done with 479146 lattice points. Tolerance = 0.161\n",
            "r = 15.344 step done with 481066 lattice points. Tolerance = 0.161\n",
            "r = 15.36 step done with 481546 lattice points. Tolerance = 0.161\n",
            "r = 15.377 step done with 482476 lattice points. Tolerance = 0.161\n",
            "r = 15.393 step done with 483484 lattice points. Tolerance = 0.161\n",
            "r = 15.409 step done with 484916 lattice points. Tolerance = 0.161\n",
            "r = 15.425 step done with 485066 lattice points. Tolerance = 0.161\n",
            "r = 15.441 step done with 487490 lattice points. Tolerance = 0.161\n",
            "r = 15.457 step done with 487790 lattice points. Tolerance = 0.161\n",
            "r = 15.473 step done with 488894 lattice points. Tolerance = 0.161\n",
            "r = 15.489 step done with 490538 lattice points. Tolerance = 0.161\n",
            "r = 15.505 step done with 491156 lattice points. Tolerance = 0.161\n",
            "r = 15.521 step done with 491596 lattice points. Tolerance = 0.161\n",
            "r = 15.538 step done with 493012 lattice points. Tolerance = 0.161\n",
            "r = 15.554 step done with 493954 lattice points. Tolerance = 0.161\n",
            "r = 15.57 step done with 493570 lattice points. Tolerance = 0.161\n",
            "r = 15.586 step done with 494170 lattice points. Tolerance = 0.161\n",
            "r = 15.602 step done with 497842 lattice points. Tolerance = 0.161\n",
            "r = 15.618 step done with 498908 lattice points. Tolerance = 0.161\n",
            "r = 15.634 step done with 497312 lattice points. Tolerance = 0.161\n",
            "r = 15.65 step done with 500864 lattice points. Tolerance = 0.161\n",
            "r = 15.666 step done with 499652 lattice points. Tolerance = 0.161\n",
            "r = 15.682 step done with 499946 lattice points. Tolerance = 0.161\n",
            "r = 15.699 step done with 503282 lattice points. Tolerance = 0.161\n",
            "r = 15.715 step done with 503954 lattice points. Tolerance = 0.161\n",
            "r = 15.731 step done with 504106 lattice points. Tolerance = 0.161\n",
            "r = 15.747 step done with 505900 lattice points. Tolerance = 0.161\n",
            "r = 15.763 step done with 506860 lattice points. Tolerance = 0.161\n",
            "r = 15.779 step done with 508036 lattice points. Tolerance = 0.161\n",
            "r = 15.795 step done with 508180 lattice points. Tolerance = 0.161\n",
            "r = 15.811 step done with 509950 lattice points. Tolerance = 0.161\n",
            "r = 15.827 step done with 509926 lattice points. Tolerance = 0.161\n",
            "r = 15.843 step done with 511082 lattice points. Tolerance = 0.161\n",
            "r = 15.86 step done with 513050 lattice points. Tolerance = 0.161\n",
            "r = 15.876 step done with 513212 lattice points. Tolerance = 0.161\n",
            "r = 15.892 step done with 514676 lattice points. Tolerance = 0.161\n",
            "r = 15.908 step done with 515900 lattice points. Tolerance = 0.161\n",
            "r = 15.924 step done with 513380 lattice points. Tolerance = 0.161\n",
            "r = 15.94 step done with 515915 lattice points. Tolerance = 0.161\n",
            "r = 15.956 step done with 518827 lattice points. Tolerance = 0.161\n",
            "r = 15.972 step done with 518983 lattice points. Tolerance = 0.161\n",
            "r = 15.988 step done with 520807 lattice points. Tolerance = 0.161\n",
            "r = 16.004 step done with 520801 lattice points. Tolerance = 0.161\n",
            "r = 16.021 step done with 521269 lattice points. Tolerance = 0.161\n",
            "r = 16.037 step done with 523285 lattice points. Tolerance = 0.161\n",
            "r = 16.053 step done with 522341 lattice points. Tolerance = 0.161\n",
            "r = 16.069 step done with 522821 lattice points. Tolerance = 0.161\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "X745aG0jZ2YJ",
        "outputId": "5d5c847f-f492-46bf-f03a-b0b5b621119b"
      },
      "source": [
        "plt.figure(figsize = (10,6))\n",
        "plt.plot(k_range[:-1],spec_normalised)\n",
        "plt.loglog()\n",
        "# plt.xlim([0.1,50])\n",
        "plt.xlabel('k')\n",
        "plt.ylabel('$\\Omega_{gw}(t)/\\Omega_{\\eta}$')\n",
        "plt.title('Energy spectrum vs wave number')\n",
        "plt.show()\n",
        "\n",
        "def save_spectrum():\n",
        "# Clean up plot files\n",
        "    import glob, os\n",
        "    name = 'spectrum.png'\n",
        "    if glob.glob(name):\n",
        "      os.remove(name)\n",
        "      plt.savefig(name)\n",
        "save_spectrum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVTu-YmUYbnr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}